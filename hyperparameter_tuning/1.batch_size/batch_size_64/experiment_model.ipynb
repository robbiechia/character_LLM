{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "adc4842c",
      "metadata": {
        "id": "adc4842c"
      },
      "source": [
        "# Hyperparameter Tuning - Batch Size Experiment\n",
        "\n",
        "After completing ablation experiments, we proceed to conduct hyperparameter tuning to further enhance the model's performance. The architecture is defined as per the 'experiment_model.py' file, and we utilise functions created in the 'experiment_utils.py' file to facilitate the training process.\n",
        "\n",
        "The flow of this notebook is similar to that of previous components, but with modifications to accommodate the hyperparameter tuning requirements. The loss values are recorded for upcoming analysis, visualization and cross comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "477b41b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "477b41b4",
        "outputId": "a0ec1a13-8365-4e4f-f481-fd889f7b9920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import optax\n",
        "import sys\n",
        "import jax\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "cwd = Path.cwd()\n",
        "project_root = cwd.parents[0]\n",
        "\n",
        "# Project root for local setup\n",
        "# project_root = cwd.parents[1]\n",
        "# sys.path.append(str(project_root))\n",
        "\n",
        "import hyperparameter_tuning.experiment_setup.experiment_utils as fn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "656e4403",
      "metadata": {
        "id": "656e4403"
      },
      "source": [
        "# Load the Experiment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f18b286",
      "metadata": {
        "id": "1f18b286"
      },
      "source": [
        "## Set the relevant directory paths & update.log file\n",
        "\n",
        "Here, we set the necessary directories and output paths for saving model checkpoints and training logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2168d1a9",
      "metadata": {
        "id": "2168d1a9"
      },
      "outputs": [],
      "source": [
        "# Data directory paths\n",
        "local_dir = project_root / \"data\" / \"text8_train.txt\"\n",
        "online_dir = project_root / \"text8_train.txt\"\n",
        "\n",
        "if local_dir.exists():\n",
        "    data_dir = str(local_dir) # This is for local runs or if repository is cloned directly\n",
        "else:\n",
        "    data_dir = \".\" + str(online_dir) # This is for online GPU platforms\n",
        "\n",
        "config_path = cwd / \"config.json\"\n",
        "training_log_file = cwd / \"training_results.log\"\n",
        "validation_log_file = cwd / \"validation_results.log\"\n",
        "checkpoint_file = cwd / \"checkpoint.pkl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a89050a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a89050a0",
        "outputId": "657a3293-e1ff-4bc2-e12e-354329519676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[initialize_training_log] Initialized training log file at /content/training_results.log\n",
            "[initialize_validation_log] Initialized validation log file at /content/validation_results.log\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(training_log_file):\n",
        "    fn.initialize_training_log(training_log_file)\n",
        "\n",
        "if not os.path.exists(validation_log_file):\n",
        "    fn.initialize_validation_log(validation_log_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da2df4b7",
      "metadata": {
        "id": "da2df4b7"
      },
      "source": [
        "## Load the experiment configurations\n",
        "\n",
        "Prior to running this notebook, the experiment configurations will be set in a 'config.json' file, which will be loaded to set the model hyperparameters and training settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f290991b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f290991b",
        "outputId": "79c733d1-eb8a-46da-d464-a17d0bde67fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[load_config] Loaded configuration from ./config.json\n",
            "We will be conducting  Hyperparameter tuning for Batch Size = 64.\n"
          ]
        }
      ],
      "source": [
        "config = fn.load_config(\"./config.json\")\n",
        "\n",
        "print(f\"We will be conducting {config['description']}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "31bb4815",
      "metadata": {
        "id": "31bb4815"
      },
      "outputs": [],
      "source": [
        "# Load the seed\n",
        "seed = config['seed']\n",
        "\n",
        "# Model parameters\n",
        "vocab_size = config['model']['vocab_size']\n",
        "d_model = config['model']['d_model']\n",
        "n_heads = config['model']['n_heads']\n",
        "n_layers = config['model']['n_layers']\n",
        "mlp_ratio = config['model']['mlp_ratio']\n",
        "seq_len = config['model']['seq_len']\n",
        "\n",
        "# Training parameters\n",
        "loss_type = config['model']['loss_type']\n",
        "dropout_rate = config['model']['dropout']\n",
        "weight_decay = config['model']['weight_decay']\n",
        "label_smoothing = float(config['model']['label_smoothing'])\n",
        "\n",
        "# Mixed precision and other model settings\n",
        "use_mixed_precision = config['model']['mixed_precision']\n",
        "pos_encoding = config['model']['pos_encoding']\n",
        "attention_type = config['model']['attention_type']\n",
        "\n",
        "# Auxiliary loss settings\n",
        "use_auxiliary_loss = config['model']['use_auxiliary_loss']\n",
        "aux_heads = config['model']['aux_heads']\n",
        "aux_weight = config['model']['aux_weight']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cf23122e",
      "metadata": {
        "id": "cf23122e"
      },
      "outputs": [],
      "source": [
        "# Throughput test parameters\n",
        "max_test_iters = config['throughput']['max_test_iters']\n",
        "max_test_time_in_seconds = config['throughput']['max_test_time_in_seconds']\n",
        "compute_budget_hours = config['throughput']['compute_budget_hours']\n",
        "\n",
        "# Training settings\n",
        "val_fraction = config['training']['val_fraction']\n",
        "batch_size = config['training']['batch_size']\n",
        "learning_rate = config['training']['learning_rate']\n",
        "lr_schedule = config['training']['lr_schedule']\n",
        "optimizer_type = config['training']['optimizer']\n",
        "grad_clip = config['training']['grad_clip']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4030d754",
      "metadata": {
        "id": "4030d754"
      },
      "source": [
        "# Loading the Data\n",
        "\n",
        "The same text8 dataset is used, which has 100M characters of text data from Wikipedia articles. It contains only lowercase letters and spaces, and is already pre-split into 90M characters for training and 10M characters for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "75d76b31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75d76b31",
        "outputId": "d55dec4a-92d4-4966-b913-818e03e1a9ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training text loaded. Length: 90,000,000 characters.\n",
            "First 500 characters of training text:\n",
            " anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans culottes of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philoso\n"
          ]
        }
      ],
      "source": [
        "# Read in training text file\n",
        "with open(data_dir, 'r', encoding='utf-8') as f:\n",
        "    train_text = f.read()\n",
        "print(f\"Training text loaded. Length: {len(train_text) :,} characters.\")\n",
        "\n",
        "# Inspect first 500 characters of training text\n",
        "print(\"First 500 characters of training text:\")\n",
        "print(train_text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7fd37a2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fd37a2d",
        "outputId": "3081f7ea-f6f0-4381-b77d-409b2d1b7307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique characters in training text: 27\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(set(train_text)) # unique characters in training text\n",
        "chars_to_int = {ch: i for i, ch in enumerate(chars)} # char to int mapping\n",
        "int_to_chars = {i: ch for i, ch in enumerate(chars)} # int to char mapping\n",
        "\n",
        "print(f\"Unique characters in training text: {len(chars)}\") # should be 27, including space (sanity check)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "032e68f0",
      "metadata": {
        "id": "032e68f0"
      },
      "source": [
        "We further split the training data into a training set and a validation set to monitor the model's performance during training, in accordance to the validation fraction specified in our configuration file (10%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9a969636",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a969636",
        "outputId": "6b7012a0-5eab-41ab-b59b-93cbef2bcd2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training text length: 89,099,996 characters.\n",
            "Validation text length: 900,004 characters.\n"
          ]
        }
      ],
      "source": [
        "train_text, val_text = fn.split_train_val(train_text, val_fraction=val_fraction)\n",
        "\n",
        "print(f\"Training text length: {len(train_text) :,} characters.\")\n",
        "print(f\"Validation text length: {len(val_text) :,} characters.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c28ac68",
      "metadata": {
        "id": "1c28ac68"
      },
      "source": [
        "# Model Initialisation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fe304ec",
      "metadata": {
        "id": "7fe304ec"
      },
      "source": [
        "## Model Setup\n",
        "\n",
        "We intialise our model with the following parameters in accordance to our configuration file.\n",
        "Based on these parameters, our model has approximately ~4.1M parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d19f06bd",
      "metadata": {
        "id": "d19f06bd"
      },
      "outputs": [],
      "source": [
        "# Define the model params\n",
        "rng = jax.random.PRNGKey(seed)\n",
        "\n",
        "model_obj, params, constants = fn.create_train_state(\n",
        "        rng,\n",
        "        vocab_size = vocab_size,\n",
        "        d_model = d_model,\n",
        "        n_heads = n_heads,\n",
        "        n_layers = n_layers,\n",
        "        mlp_ratio = mlp_ratio,\n",
        "        seq_len = seq_len,\n",
        "        dropout = dropout_rate,\n",
        "        aux_loss = use_auxiliary_loss,\n",
        "        num_aux_heads = aux_heads,\n",
        "        mixed_precision = use_mixed_precision,\n",
        "        attention_type = attention_type,\n",
        "        pos_encoding = pos_encoding\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "91839933",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91839933",
        "outputId": "2679b915-509d-4540-bc00-71b869a173e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the model: 4,160,768\n"
          ]
        }
      ],
      "source": [
        "total_params = fn.count_parameters(params)\n",
        "\n",
        "print(f\"Total number of parameters in the model: {total_params :,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e709b510",
      "metadata": {
        "id": "e709b510"
      },
      "source": [
        "We perform a sanity check by running a single forward pass with random input data to ensure the model is functioning as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bdc7a187",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdc7a187",
        "outputId": "8324ac3b-3ba7-4af8-81e5-51387e905a84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape: (2, 8, 27)\n"
          ]
        }
      ],
      "source": [
        "# SANITY CHECK: Test the model forward pass\n",
        "B, T = 2, 8  # Batch size and sequence length\n",
        "batch = jax.random.randint(key = rng, shape = (B, T), minval = 0, maxval = vocab_size)\n",
        "\n",
        "variables = {\"params\": params, \"constants\": constants}\n",
        "output = model_obj.apply(variables, batch, deterministic=False)\n",
        "print(\"Logits shape:\", output[\"logits\"].shape)  # Expected: (B, T, vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec22aeee",
      "metadata": {
        "id": "ec22aeee"
      },
      "source": [
        "## Initialise the optimizer\n",
        "\n",
        "In this section, we set up the optimizer for training our model in accordance to our configuration file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "05d04750",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05d04750",
        "outputId": "c85c9d45-4580-474d-f028-19f3ea4bc4fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer initialized: adam with Learning Rate = 0.001\n"
          ]
        }
      ],
      "source": [
        "# Define the learning rate\n",
        "learning_rate = learning_rate\n",
        "\n",
        "# Create the Optimizer and initialize it\n",
        "if optimizer_type == \"adam\":\n",
        "    optimizer = optax.adam(learning_rate)\n",
        "elif optimizer_type == \"sgd\":\n",
        "    optimizer = optax.sgd(learning_rate)\n",
        "elif optimizer_type == \"adamw\":\n",
        "    optimizer = optax.adamw(\n",
        "        learning_rate = learning_rate,\n",
        "        weight_decay = weight_decay\n",
        "    )\n",
        "\n",
        "# Add gradient clipping if specified\n",
        "if grad_clip is not None and grad_clip != \"none\":\n",
        "    optimizer = optax.chain(\n",
        "        optax.clip_by_global_norm(grad_clip),\n",
        "        optimizer\n",
        "    )\n",
        "\n",
        "\n",
        "opt_state = optimizer.init(params)\n",
        "\n",
        "print(\"Optimizer initialized:\", optimizer_type, \"with Learning Rate =\", learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "233c7fe3",
      "metadata": {
        "id": "233c7fe3"
      },
      "source": [
        "## Text encoding\n",
        "\n",
        "We then encode the text data into integer format for model training. Each unique character is mapped to a unique integer index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "17829ea8",
      "metadata": {
        "id": "17829ea8"
      },
      "outputs": [],
      "source": [
        "# Encode the train, val, test texts\n",
        "train_data = fn.encode(train_text, chars_to_int)\n",
        "val_data = fn.encode(val_text, chars_to_int)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "153631ec",
      "metadata": {
        "id": "153631ec"
      },
      "source": [
        "## Determine maximum permissible training steps\n",
        "\n",
        "Taking into account possible compute limitations, we perform a preliminary calculation to determine the maximum number of training steps we can perform based on the throughput of our model and the total training time available. For this preliminary test, the default maximum training time is 60 seconds, and commpute budget hours is 2 hours.\n",
        "\n",
        "Based on the throughput calculated from the preliminary test, the estimated maximum no. of training steps we can perform within this compute budget is ~270,000. To ensure we keep within the budget, we set the maximum training steps to be 100,000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1312e527",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1312e527",
        "outputId": "85ee6ee0-60a9-4b7a-804c-7530d4c03348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Benchmark completed in 26.70 seconds.\n",
            "Total tokens processed: 16384000\n",
            "Throughput: 613651.75 tokens/second\n",
            "Estimated max steps within compute budget: 269671.0\n"
          ]
        }
      ],
      "source": [
        "# Determining how many steps we can run in a reasonable time\n",
        "max_iters = max_test_iters\n",
        "max_time = max_test_time_in_seconds # in seconds\n",
        "max_compute_time = compute_budget_hours # in hours\n",
        "\n",
        "_ , max_steps = fn.calculate_throughput(\n",
        "    max_test_iters = max_iters,\n",
        "    max_test_time = max_time,\n",
        "    model = model_obj,\n",
        "    params = params,\n",
        "    opt_state = opt_state,\n",
        "    optimizer = optimizer,\n",
        "    rng = rng,\n",
        "    batch_size = batch_size,\n",
        "    seq_len = seq_len,\n",
        "    compute_budget = max_compute_time,\n",
        "    train_data = train_data,\n",
        "    loss_type = loss_type,\n",
        "    aux_loss = use_auxiliary_loss,\n",
        "    aux_weight = aux_weight,\n",
        "    constants = constants,\n",
        "    label_smoothing = label_smoothing\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff66f55f",
      "metadata": {
        "id": "ff66f55f"
      },
      "source": [
        "# Model Training & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b839549c",
      "metadata": {
        "id": "b839549c"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "Now, we proceed to train the model over the determined number of training iterations. During training, we monitor the training loss and periodically evaluate the model on the validation set to track its performance. We also make sure to record the time taken for training to ensure it stays within our compute budget."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "1262eda3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1262eda3",
        "outputId": "ecb4f6bd-0307-4b9f-c573-ab584137a484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[load_checkpoint] No checkpoint found at /content/checkpoint.pkl\n",
            "[load_checkpoint] Starting training as per usual.\n"
          ]
        }
      ],
      "source": [
        "iter_max = 100000\n",
        "\n",
        "# To track training and validation loss, as well as time taken\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "train_step_history = list(range(iter_max))\n",
        "val_step_history = []\n",
        "\n",
        "# Load checkpoint if it exists\n",
        "params, opt_state, constants, start_iter = fn.load_checkpoint(\n",
        "    checkpoint_file,\n",
        "    params,\n",
        "    constants,\n",
        "    opt_state\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd2b91d3",
      "metadata": {
        "id": "cd2b91d3"
      },
      "source": [
        "We then train the model and log the training and validation losses for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c7cbde26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7cbde26",
        "outputId": "f711c07a-7078-49da-a0ed-8ad24e28cf46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training from iteration = 0.\n",
            "[save_checkpoint] Saved checkpoint at step 0 to /content/checkpoint.pkl\n",
            "Iteration 0, time elapsed: 8.26 seconds\n",
            "\t \t Training Loss: 3.7472, Validation Loss: 4.4002\n",
            "\t \t Training Acc: 0.0574, Validation Acc: 0.1673\n",
            "\t \t Last Char Training Acc: 0.0000, Last Char Validation Acc: 0.1406\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 1000 to /content/checkpoint.pkl\n",
            "Iteration 1000, time elapsed: 21.95 seconds\n",
            "\t \t Training Loss: 1.3898, Validation Loss: 1.3875\n",
            "\t \t Training Acc: 0.5701, Validation Acc: 0.5670\n",
            "\t \t Last Char Training Acc: 0.3906, Last Char Validation Acc: 0.6094\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 2000 to /content/checkpoint.pkl\n",
            "Iteration 2000, time elapsed: 35.75 seconds\n",
            "\t \t Training Loss: 1.2907, Validation Loss: 1.2941\n",
            "\t \t Training Acc: 0.5900, Validation Acc: 0.5963\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.6719\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 3000 to /content/checkpoint.pkl\n",
            "Iteration 3000, time elapsed: 49.56 seconds\n",
            "\t \t Training Loss: 1.2950, Validation Loss: 1.2232\n",
            "\t \t Training Acc: 0.5896, Validation Acc: 0.6133\n",
            "\t \t Last Char Training Acc: 0.6406, Last Char Validation Acc: 0.5625\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 4000 to /content/checkpoint.pkl\n",
            "Iteration 4000, time elapsed: 63.00 seconds\n",
            "\t \t Training Loss: 1.2570, Validation Loss: 1.2149\n",
            "\t \t Training Acc: 0.6065, Validation Acc: 0.6156\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.5781\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 5000 to /content/checkpoint.pkl\n",
            "Iteration 5000, time elapsed: 76.77 seconds\n",
            "\t \t Training Loss: 1.1788, Validation Loss: 1.2389\n",
            "\t \t Training Acc: 0.6229, Validation Acc: 0.6064\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.5625\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 6000 to /content/checkpoint.pkl\n",
            "Iteration 6000, time elapsed: 90.13 seconds\n",
            "\t \t Training Loss: 1.1810, Validation Loss: 1.1610\n",
            "\t \t Training Acc: 0.6270, Validation Acc: 0.6343\n",
            "\t \t Last Char Training Acc: 0.7344, Last Char Validation Acc: 0.7656\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 7000 to /content/checkpoint.pkl\n",
            "Iteration 7000, time elapsed: 103.66 seconds\n",
            "\t \t Training Loss: 1.1903, Validation Loss: 1.2117\n",
            "\t \t Training Acc: 0.6255, Validation Acc: 0.6269\n",
            "\t \t Last Char Training Acc: 0.6406, Last Char Validation Acc: 0.7031\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 8000 to /content/checkpoint.pkl\n",
            "Iteration 8000, time elapsed: 117.10 seconds\n",
            "\t \t Training Loss: 1.1744, Validation Loss: 1.1500\n",
            "\t \t Training Acc: 0.6246, Validation Acc: 0.6338\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6406\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 9000 to /content/checkpoint.pkl\n",
            "Iteration 9000, time elapsed: 131.01 seconds\n",
            "\t \t Training Loss: 1.1468, Validation Loss: 1.1992\n",
            "\t \t Training Acc: 0.6364, Validation Acc: 0.6231\n",
            "\t \t Last Char Training Acc: 0.7031, Last Char Validation Acc: 0.6719\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 10000 to /content/checkpoint.pkl\n",
            "Iteration 10000, time elapsed: 144.58 seconds\n",
            "\t \t Training Loss: 1.1465, Validation Loss: 1.1909\n",
            "\t \t Training Acc: 0.6381, Validation Acc: 0.6257\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.5781\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 11000 to /content/checkpoint.pkl\n",
            "Iteration 11000, time elapsed: 158.19 seconds\n",
            "\t \t Training Loss: 1.1465, Validation Loss: 1.1593\n",
            "\t \t Training Acc: 0.6382, Validation Acc: 0.6334\n",
            "\t \t Last Char Training Acc: 0.6719, Last Char Validation Acc: 0.6719\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 12000 to /content/checkpoint.pkl\n",
            "Iteration 12000, time elapsed: 171.60 seconds\n",
            "\t \t Training Loss: 1.1009, Validation Loss: 1.1250\n",
            "\t \t Training Acc: 0.6540, Validation Acc: 0.6419\n",
            "\t \t Last Char Training Acc: 0.6094, Last Char Validation Acc: 0.6719\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 13000 to /content/checkpoint.pkl\n",
            "Iteration 13000, time elapsed: 185.17 seconds\n",
            "\t \t Training Loss: 1.1115, Validation Loss: 1.1579\n",
            "\t \t Training Acc: 0.6486, Validation Acc: 0.6354\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 14000 to /content/checkpoint.pkl\n",
            "Iteration 14000, time elapsed: 198.76 seconds\n",
            "\t \t Training Loss: 1.1559, Validation Loss: 1.1650\n",
            "\t \t Training Acc: 0.6398, Validation Acc: 0.6354\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 15000 to /content/checkpoint.pkl\n",
            "Iteration 15000, time elapsed: 212.20 seconds\n",
            "\t \t Training Loss: 1.1804, Validation Loss: 1.2137\n",
            "\t \t Training Acc: 0.6317, Validation Acc: 0.6213\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.6094\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 16000 to /content/checkpoint.pkl\n",
            "Iteration 16000, time elapsed: 225.79 seconds\n",
            "\t \t Training Loss: 1.1110, Validation Loss: 1.1775\n",
            "\t \t Training Acc: 0.6495, Validation Acc: 0.6357\n",
            "\t \t Last Char Training Acc: 0.7031, Last Char Validation Acc: 0.5625\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 17000 to /content/checkpoint.pkl\n",
            "Iteration 17000, time elapsed: 239.41 seconds\n",
            "\t \t Training Loss: 1.1783, Validation Loss: 1.1459\n",
            "\t \t Training Acc: 0.6355, Validation Acc: 0.6402\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.6406\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 18000 to /content/checkpoint.pkl\n",
            "Iteration 18000, time elapsed: 253.05 seconds\n",
            "\t \t Training Loss: 1.1087, Validation Loss: 1.1239\n",
            "\t \t Training Acc: 0.6507, Validation Acc: 0.6489\n",
            "\t \t Last Char Training Acc: 0.5625, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 19000 to /content/checkpoint.pkl\n",
            "Iteration 19000, time elapsed: 266.59 seconds\n",
            "\t \t Training Loss: 1.0962, Validation Loss: 1.1245\n",
            "\t \t Training Acc: 0.6547, Validation Acc: 0.6506\n",
            "\t \t Last Char Training Acc: 0.7969, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 20000 to /content/checkpoint.pkl\n",
            "Iteration 20000, time elapsed: 280.12 seconds\n",
            "\t \t Training Loss: 1.0901, Validation Loss: 1.1100\n",
            "\t \t Training Acc: 0.6550, Validation Acc: 0.6519\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6719\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 21000 to /content/checkpoint.pkl\n",
            "Iteration 21000, time elapsed: 293.78 seconds\n",
            "\t \t Training Loss: 1.0669, Validation Loss: 1.0918\n",
            "\t \t Training Acc: 0.6634, Validation Acc: 0.6567\n",
            "\t \t Last Char Training Acc: 0.6719, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 22000 to /content/checkpoint.pkl\n",
            "Iteration 22000, time elapsed: 307.47 seconds\n",
            "\t \t Training Loss: 1.1186, Validation Loss: 1.0864\n",
            "\t \t Training Acc: 0.6543, Validation Acc: 0.6558\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.7031\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 23000 to /content/checkpoint.pkl\n",
            "Iteration 23000, time elapsed: 321.08 seconds\n",
            "\t \t Training Loss: 1.0699, Validation Loss: 1.0989\n",
            "\t \t Training Acc: 0.6656, Validation Acc: 0.6566\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 24000 to /content/checkpoint.pkl\n",
            "Iteration 24000, time elapsed: 334.69 seconds\n",
            "\t \t Training Loss: 1.1045, Validation Loss: 1.0791\n",
            "\t \t Training Acc: 0.6531, Validation Acc: 0.6602\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 25000 to /content/checkpoint.pkl\n",
            "Iteration 25000, time elapsed: 348.25 seconds\n",
            "\t \t Training Loss: 1.0492, Validation Loss: 1.0679\n",
            "\t \t Training Acc: 0.6668, Validation Acc: 0.6645\n",
            "\t \t Last Char Training Acc: 0.6719, Last Char Validation Acc: 0.6719\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 26000 to /content/checkpoint.pkl\n",
            "Iteration 26000, time elapsed: 361.92 seconds\n",
            "\t \t Training Loss: 1.0836, Validation Loss: 1.1062\n",
            "\t \t Training Acc: 0.6613, Validation Acc: 0.6544\n",
            "\t \t Last Char Training Acc: 0.7344, Last Char Validation Acc: 0.7656\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 27000 to /content/checkpoint.pkl\n",
            "Iteration 27000, time elapsed: 375.55 seconds\n",
            "\t \t Training Loss: 1.0755, Validation Loss: 1.1186\n",
            "\t \t Training Acc: 0.6671, Validation Acc: 0.6492\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.6719\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 28000 to /content/checkpoint.pkl\n",
            "Iteration 28000, time elapsed: 389.02 seconds\n",
            "\t \t Training Loss: 1.0823, Validation Loss: 1.1281\n",
            "\t \t Training Acc: 0.6589, Validation Acc: 0.6498\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.7344\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 29000 to /content/checkpoint.pkl\n",
            "Iteration 29000, time elapsed: 402.68 seconds\n",
            "\t \t Training Loss: 1.0721, Validation Loss: 1.0559\n",
            "\t \t Training Acc: 0.6655, Validation Acc: 0.6655\n",
            "\t \t Last Char Training Acc: 0.5781, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 30000 to /content/checkpoint.pkl\n",
            "Iteration 30000, time elapsed: 416.35 seconds\n",
            "\t \t Training Loss: 1.0818, Validation Loss: 1.0612\n",
            "\t \t Training Acc: 0.6594, Validation Acc: 0.6666\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 31000 to /content/checkpoint.pkl\n",
            "Iteration 31000, time elapsed: 429.82 seconds\n",
            "\t \t Training Loss: 1.0715, Validation Loss: 1.1178\n",
            "\t \t Training Acc: 0.6626, Validation Acc: 0.6489\n",
            "\t \t Last Char Training Acc: 0.6719, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 32000 to /content/checkpoint.pkl\n",
            "Iteration 32000, time elapsed: 443.69 seconds\n",
            "\t \t Training Loss: 1.0604, Validation Loss: 1.0521\n",
            "\t \t Training Acc: 0.6694, Validation Acc: 0.6716\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 33000 to /content/checkpoint.pkl\n",
            "Iteration 33000, time elapsed: 457.41 seconds\n",
            "\t \t Training Loss: 1.0314, Validation Loss: 1.0448\n",
            "\t \t Training Acc: 0.6738, Validation Acc: 0.6710\n",
            "\t \t Last Char Training Acc: 0.6719, Last Char Validation Acc: 0.8125\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 34000 to /content/checkpoint.pkl\n",
            "Iteration 34000, time elapsed: 471.02 seconds\n",
            "\t \t Training Loss: 1.0698, Validation Loss: 1.0417\n",
            "\t \t Training Acc: 0.6619, Validation Acc: 0.6713\n",
            "\t \t Last Char Training Acc: 0.7344, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 35000 to /content/checkpoint.pkl\n",
            "Iteration 35000, time elapsed: 484.66 seconds\n",
            "\t \t Training Loss: 1.0744, Validation Loss: 1.0931\n",
            "\t \t Training Acc: 0.6595, Validation Acc: 0.6550\n",
            "\t \t Last Char Training Acc: 0.6719, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 36000 to /content/checkpoint.pkl\n",
            "Iteration 36000, time elapsed: 498.65 seconds\n",
            "\t \t Training Loss: 1.0331, Validation Loss: 1.0902\n",
            "\t \t Training Acc: 0.6758, Validation Acc: 0.6586\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.6406\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 37000 to /content/checkpoint.pkl\n",
            "Iteration 37000, time elapsed: 512.10 seconds\n",
            "\t \t Training Loss: 1.0245, Validation Loss: 1.0612\n",
            "\t \t Training Acc: 0.6791, Validation Acc: 0.6656\n",
            "\t \t Last Char Training Acc: 0.7031, Last Char Validation Acc: 0.6406\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 38000 to /content/checkpoint.pkl\n",
            "Iteration 38000, time elapsed: 525.71 seconds\n",
            "\t \t Training Loss: 1.0269, Validation Loss: 1.0667\n",
            "\t \t Training Acc: 0.6735, Validation Acc: 0.6657\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 39000 to /content/checkpoint.pkl\n",
            "Iteration 39000, time elapsed: 539.14 seconds\n",
            "\t \t Training Loss: 1.0433, Validation Loss: 1.0420\n",
            "\t \t Training Acc: 0.6760, Validation Acc: 0.6700\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.6094\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 40000 to /content/checkpoint.pkl\n",
            "Iteration 40000, time elapsed: 552.71 seconds\n",
            "\t \t Training Loss: 1.0291, Validation Loss: 1.0861\n",
            "\t \t Training Acc: 0.6747, Validation Acc: 0.6611\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.6094\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 41000 to /content/checkpoint.pkl\n",
            "Iteration 41000, time elapsed: 566.11 seconds\n",
            "\t \t Training Loss: 1.0531, Validation Loss: 1.0569\n",
            "\t \t Training Acc: 0.6604, Validation Acc: 0.6697\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.6719\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 42000 to /content/checkpoint.pkl\n",
            "Iteration 42000, time elapsed: 579.71 seconds\n",
            "\t \t Training Loss: 1.0738, Validation Loss: 1.0411\n",
            "\t \t Training Acc: 0.6641, Validation Acc: 0.6685\n",
            "\t \t Last Char Training Acc: 0.6406, Last Char Validation Acc: 0.7344\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 43000 to /content/checkpoint.pkl\n",
            "Iteration 43000, time elapsed: 593.04 seconds\n",
            "\t \t Training Loss: 1.0231, Validation Loss: 1.0644\n",
            "\t \t Training Acc: 0.6763, Validation Acc: 0.6661\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 44000 to /content/checkpoint.pkl\n",
            "Iteration 44000, time elapsed: 606.82 seconds\n",
            "\t \t Training Loss: 1.0406, Validation Loss: 1.0620\n",
            "\t \t Training Acc: 0.6736, Validation Acc: 0.6638\n",
            "\t \t Last Char Training Acc: 0.7656, Last Char Validation Acc: 0.7031\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 45000 to /content/checkpoint.pkl\n",
            "Iteration 45000, time elapsed: 620.44 seconds\n",
            "\t \t Training Loss: 1.0189, Validation Loss: 1.1007\n",
            "\t \t Training Acc: 0.6798, Validation Acc: 0.6563\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.5781\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 46000 to /content/checkpoint.pkl\n",
            "Iteration 46000, time elapsed: 633.96 seconds\n",
            "\t \t Training Loss: 1.0429, Validation Loss: 1.0434\n",
            "\t \t Training Acc: 0.6727, Validation Acc: 0.6725\n",
            "\t \t Last Char Training Acc: 0.7031, Last Char Validation Acc: 0.6406\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 47000 to /content/checkpoint.pkl\n",
            "Iteration 47000, time elapsed: 647.63 seconds\n",
            "\t \t Training Loss: 1.0467, Validation Loss: 1.0672\n",
            "\t \t Training Acc: 0.6743, Validation Acc: 0.6616\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 48000 to /content/checkpoint.pkl\n",
            "Iteration 48000, time elapsed: 661.27 seconds\n",
            "\t \t Training Loss: 0.9870, Validation Loss: 1.0700\n",
            "\t \t Training Acc: 0.6877, Validation Acc: 0.6642\n",
            "\t \t Last Char Training Acc: 0.8438, Last Char Validation Acc: 0.7031\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 49000 to /content/checkpoint.pkl\n",
            "Iteration 49000, time elapsed: 674.92 seconds\n",
            "\t \t Training Loss: 1.0157, Validation Loss: 1.0497\n",
            "\t \t Training Acc: 0.6781, Validation Acc: 0.6734\n",
            "\t \t Last Char Training Acc: 0.6719, Last Char Validation Acc: 0.7656\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 50000 to /content/checkpoint.pkl\n",
            "Iteration 50000, time elapsed: 688.79 seconds\n",
            "\t \t Training Loss: 1.0523, Validation Loss: 1.0352\n",
            "\t \t Training Acc: 0.6721, Validation Acc: 0.6782\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 51000 to /content/checkpoint.pkl\n",
            "Iteration 51000, time elapsed: 702.34 seconds\n",
            "\t \t Training Loss: 1.0474, Validation Loss: 1.0913\n",
            "\t \t Training Acc: 0.6730, Validation Acc: 0.6584\n",
            "\t \t Last Char Training Acc: 0.7344, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 52000 to /content/checkpoint.pkl\n",
            "Iteration 52000, time elapsed: 715.91 seconds\n",
            "\t \t Training Loss: 1.0238, Validation Loss: 1.0699\n",
            "\t \t Training Acc: 0.6757, Validation Acc: 0.6661\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 53000 to /content/checkpoint.pkl\n",
            "Iteration 53000, time elapsed: 729.43 seconds\n",
            "\t \t Training Loss: 1.0261, Validation Loss: 1.0269\n",
            "\t \t Training Acc: 0.6839, Validation Acc: 0.6782\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 54000 to /content/checkpoint.pkl\n",
            "Iteration 54000, time elapsed: 743.14 seconds\n",
            "\t \t Training Loss: 1.0093, Validation Loss: 1.0533\n",
            "\t \t Training Acc: 0.6834, Validation Acc: 0.6663\n",
            "\t \t Last Char Training Acc: 0.7031, Last Char Validation Acc: 0.6094\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 55000 to /content/checkpoint.pkl\n",
            "Iteration 55000, time elapsed: 756.72 seconds\n",
            "\t \t Training Loss: 1.0061, Validation Loss: 1.0150\n",
            "\t \t Training Acc: 0.6853, Validation Acc: 0.6805\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.7031\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 56000 to /content/checkpoint.pkl\n",
            "Iteration 56000, time elapsed: 770.60 seconds\n",
            "\t \t Training Loss: 1.0448, Validation Loss: 1.0123\n",
            "\t \t Training Acc: 0.6725, Validation Acc: 0.6842\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 57000 to /content/checkpoint.pkl\n",
            "Iteration 57000, time elapsed: 784.38 seconds\n",
            "\t \t Training Loss: 1.0462, Validation Loss: 1.0582\n",
            "\t \t Training Acc: 0.6686, Validation Acc: 0.6687\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 58000 to /content/checkpoint.pkl\n",
            "Iteration 58000, time elapsed: 798.21 seconds\n",
            "\t \t Training Loss: 0.9912, Validation Loss: 1.0401\n",
            "\t \t Training Acc: 0.6924, Validation Acc: 0.6726\n",
            "\t \t Last Char Training Acc: 0.7344, Last Char Validation Acc: 0.7344\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 59000 to /content/checkpoint.pkl\n",
            "Iteration 59000, time elapsed: 812.01 seconds\n",
            "\t \t Training Loss: 1.0332, Validation Loss: 1.0200\n",
            "\t \t Training Acc: 0.6776, Validation Acc: 0.6805\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 60000 to /content/checkpoint.pkl\n",
            "Iteration 60000, time elapsed: 825.77 seconds\n",
            "\t \t Training Loss: 1.0097, Validation Loss: 1.0821\n",
            "\t \t Training Acc: 0.6837, Validation Acc: 0.6632\n",
            "\t \t Last Char Training Acc: 0.7031, Last Char Validation Acc: 0.6719\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 61000 to /content/checkpoint.pkl\n",
            "Iteration 61000, time elapsed: 839.30 seconds\n",
            "\t \t Training Loss: 0.9756, Validation Loss: 1.0273\n",
            "\t \t Training Acc: 0.6899, Validation Acc: 0.6770\n",
            "\t \t Last Char Training Acc: 0.6406, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 62000 to /content/checkpoint.pkl\n",
            "Iteration 62000, time elapsed: 852.80 seconds\n",
            "\t \t Training Loss: 0.9780, Validation Loss: 1.0430\n",
            "\t \t Training Acc: 0.6908, Validation Acc: 0.6721\n",
            "\t \t Last Char Training Acc: 0.8281, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 63000 to /content/checkpoint.pkl\n",
            "Iteration 63000, time elapsed: 866.44 seconds\n",
            "\t \t Training Loss: 0.9926, Validation Loss: 1.0429\n",
            "\t \t Training Acc: 0.6906, Validation Acc: 0.6738\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 64000 to /content/checkpoint.pkl\n",
            "Iteration 64000, time elapsed: 880.10 seconds\n",
            "\t \t Training Loss: 1.0306, Validation Loss: 1.0477\n",
            "\t \t Training Acc: 0.6783, Validation Acc: 0.6765\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6406\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 65000 to /content/checkpoint.pkl\n",
            "Iteration 65000, time elapsed: 893.64 seconds\n",
            "\t \t Training Loss: 0.9885, Validation Loss: 1.0059\n",
            "\t \t Training Acc: 0.6835, Validation Acc: 0.6870\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 66000 to /content/checkpoint.pkl\n",
            "Iteration 66000, time elapsed: 907.39 seconds\n",
            "\t \t Training Loss: 1.0325, Validation Loss: 1.0452\n",
            "\t \t Training Acc: 0.6758, Validation Acc: 0.6740\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 67000 to /content/checkpoint.pkl\n",
            "Iteration 67000, time elapsed: 921.10 seconds\n",
            "\t \t Training Loss: 1.0033, Validation Loss: 1.0344\n",
            "\t \t Training Acc: 0.6876, Validation Acc: 0.6745\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.7344\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 68000 to /content/checkpoint.pkl\n",
            "Iteration 68000, time elapsed: 934.56 seconds\n",
            "\t \t Training Loss: 0.9900, Validation Loss: 1.0328\n",
            "\t \t Training Acc: 0.6909, Validation Acc: 0.6763\n",
            "\t \t Last Char Training Acc: 0.7031, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 69000 to /content/checkpoint.pkl\n",
            "Iteration 69000, time elapsed: 947.84 seconds\n",
            "\t \t Training Loss: 1.0210, Validation Loss: 1.0307\n",
            "\t \t Training Acc: 0.6806, Validation Acc: 0.6783\n",
            "\t \t Last Char Training Acc: 0.6406, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 70000 to /content/checkpoint.pkl\n",
            "Iteration 70000, time elapsed: 961.46 seconds\n",
            "\t \t Training Loss: 1.0069, Validation Loss: 1.0311\n",
            "\t \t Training Acc: 0.6832, Validation Acc: 0.6779\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.7344\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 71000 to /content/checkpoint.pkl\n",
            "Iteration 71000, time elapsed: 975.03 seconds\n",
            "\t \t Training Loss: 1.0237, Validation Loss: 1.0610\n",
            "\t \t Training Acc: 0.6779, Validation Acc: 0.6707\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 72000 to /content/checkpoint.pkl\n",
            "Iteration 72000, time elapsed: 988.56 seconds\n",
            "\t \t Training Loss: 0.9971, Validation Loss: 1.0282\n",
            "\t \t Training Acc: 0.6863, Validation Acc: 0.6793\n",
            "\t \t Last Char Training Acc: 0.7656, Last Char Validation Acc: 0.7031\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 73000 to /content/checkpoint.pkl\n",
            "Iteration 73000, time elapsed: 1002.29 seconds\n",
            "\t \t Training Loss: 0.9935, Validation Loss: 1.0559\n",
            "\t \t Training Acc: 0.6832, Validation Acc: 0.6718\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.6406\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 74000 to /content/checkpoint.pkl\n",
            "Iteration 74000, time elapsed: 1016.14 seconds\n",
            "\t \t Training Loss: 1.0092, Validation Loss: 1.0537\n",
            "\t \t Training Acc: 0.6826, Validation Acc: 0.6710\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 75000 to /content/checkpoint.pkl\n",
            "Iteration 75000, time elapsed: 1029.93 seconds\n",
            "\t \t Training Loss: 1.0145, Validation Loss: 1.0618\n",
            "\t \t Training Acc: 0.6808, Validation Acc: 0.6667\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 76000 to /content/checkpoint.pkl\n",
            "Iteration 76000, time elapsed: 1043.54 seconds\n",
            "\t \t Training Loss: 1.0171, Validation Loss: 1.0342\n",
            "\t \t Training Acc: 0.6801, Validation Acc: 0.6743\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 77000 to /content/checkpoint.pkl\n",
            "Iteration 77000, time elapsed: 1057.21 seconds\n",
            "\t \t Training Loss: 1.0033, Validation Loss: 1.0363\n",
            "\t \t Training Acc: 0.6845, Validation Acc: 0.6716\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 78000 to /content/checkpoint.pkl\n",
            "Iteration 78000, time elapsed: 1070.93 seconds\n",
            "\t \t Training Loss: 0.9882, Validation Loss: 1.0501\n",
            "\t \t Training Acc: 0.6898, Validation Acc: 0.6710\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 79000 to /content/checkpoint.pkl\n",
            "Iteration 79000, time elapsed: 1084.58 seconds\n",
            "\t \t Training Loss: 0.9819, Validation Loss: 1.0095\n",
            "\t \t Training Acc: 0.6960, Validation Acc: 0.6841\n",
            "\t \t Last Char Training Acc: 0.7344, Last Char Validation Acc: 0.6406\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 80000 to /content/checkpoint.pkl\n",
            "Iteration 80000, time elapsed: 1098.25 seconds\n",
            "\t \t Training Loss: 1.0079, Validation Loss: 1.0519\n",
            "\t \t Training Acc: 0.6817, Validation Acc: 0.6705\n",
            "\t \t Last Char Training Acc: 0.7344, Last Char Validation Acc: 0.8125\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 81000 to /content/checkpoint.pkl\n",
            "Iteration 81000, time elapsed: 1111.86 seconds\n",
            "\t \t Training Loss: 0.9879, Validation Loss: 1.0043\n",
            "\t \t Training Acc: 0.6895, Validation Acc: 0.6863\n",
            "\t \t Last Char Training Acc: 0.6719, Last Char Validation Acc: 0.6406\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 82000 to /content/checkpoint.pkl\n",
            "Iteration 82000, time elapsed: 1125.73 seconds\n",
            "\t \t Training Loss: 0.9702, Validation Loss: 1.0544\n",
            "\t \t Training Acc: 0.6942, Validation Acc: 0.6717\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6406\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 83000 to /content/checkpoint.pkl\n",
            "Iteration 83000, time elapsed: 1139.45 seconds\n",
            "\t \t Training Loss: 1.0080, Validation Loss: 1.0420\n",
            "\t \t Training Acc: 0.6825, Validation Acc: 0.6721\n",
            "\t \t Last Char Training Acc: 0.5312, Last Char Validation Acc: 0.6406\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 84000 to /content/checkpoint.pkl\n",
            "Iteration 84000, time elapsed: 1153.37 seconds\n",
            "\t \t Training Loss: 1.0083, Validation Loss: 1.0354\n",
            "\t \t Training Acc: 0.6825, Validation Acc: 0.6758\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 85000 to /content/checkpoint.pkl\n",
            "Iteration 85000, time elapsed: 1166.78 seconds\n",
            "\t \t Training Loss: 1.0184, Validation Loss: 1.0630\n",
            "\t \t Training Acc: 0.6782, Validation Acc: 0.6719\n",
            "\t \t Last Char Training Acc: 0.7031, Last Char Validation Acc: 0.6719\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 86000 to /content/checkpoint.pkl\n",
            "Iteration 86000, time elapsed: 1180.38 seconds\n",
            "\t \t Training Loss: 0.9850, Validation Loss: 1.0193\n",
            "\t \t Training Acc: 0.6917, Validation Acc: 0.6799\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.7344\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 87000 to /content/checkpoint.pkl\n",
            "Iteration 87000, time elapsed: 1194.17 seconds\n",
            "\t \t Training Loss: 1.0130, Validation Loss: 1.0490\n",
            "\t \t Training Acc: 0.6833, Validation Acc: 0.6735\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6094\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 88000 to /content/checkpoint.pkl\n",
            "Iteration 88000, time elapsed: 1207.86 seconds\n",
            "\t \t Training Loss: 0.9661, Validation Loss: 1.0279\n",
            "\t \t Training Acc: 0.6948, Validation Acc: 0.6774\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 89000 to /content/checkpoint.pkl\n",
            "Iteration 89000, time elapsed: 1221.62 seconds\n",
            "\t \t Training Loss: 1.0132, Validation Loss: 1.0608\n",
            "\t \t Training Acc: 0.6801, Validation Acc: 0.6708\n",
            "\t \t Last Char Training Acc: 0.6094, Last Char Validation Acc: 0.7656\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 90000 to /content/checkpoint.pkl\n",
            "Iteration 90000, time elapsed: 1235.32 seconds\n",
            "\t \t Training Loss: 1.0021, Validation Loss: 1.0276\n",
            "\t \t Training Acc: 0.6903, Validation Acc: 0.6797\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 91000 to /content/checkpoint.pkl\n",
            "Iteration 91000, time elapsed: 1249.02 seconds\n",
            "\t \t Training Loss: 0.9666, Validation Loss: 1.0016\n",
            "\t \t Training Acc: 0.6959, Validation Acc: 0.6866\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 92000 to /content/checkpoint.pkl\n",
            "Iteration 92000, time elapsed: 1262.90 seconds\n",
            "\t \t Training Loss: 0.9887, Validation Loss: 1.0335\n",
            "\t \t Training Acc: 0.6893, Validation Acc: 0.6728\n",
            "\t \t Last Char Training Acc: 0.8594, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 93000 to /content/checkpoint.pkl\n",
            "Iteration 93000, time elapsed: 1276.62 seconds\n",
            "\t \t Training Loss: 1.0115, Validation Loss: 1.0771\n",
            "\t \t Training Acc: 0.6847, Validation Acc: 0.6610\n",
            "\t \t Last Char Training Acc: 0.7344, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 94000 to /content/checkpoint.pkl\n",
            "Iteration 94000, time elapsed: 1290.38 seconds\n",
            "\t \t Training Loss: 1.0227, Validation Loss: 1.0113\n",
            "\t \t Training Acc: 0.6825, Validation Acc: 0.6829\n",
            "\t \t Last Char Training Acc: 0.7344, Last Char Validation Acc: 0.7031\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 95000 to /content/checkpoint.pkl\n",
            "Iteration 95000, time elapsed: 1303.97 seconds\n",
            "\t \t Training Loss: 1.0136, Validation Loss: 1.0423\n",
            "\t \t Training Acc: 0.6833, Validation Acc: 0.6717\n",
            "\t \t Last Char Training Acc: 0.7031, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 96000 to /content/checkpoint.pkl\n",
            "Iteration 96000, time elapsed: 1317.60 seconds\n",
            "\t \t Training Loss: 0.9731, Validation Loss: 1.0697\n",
            "\t \t Training Acc: 0.6981, Validation Acc: 0.6675\n",
            "\t \t Last Char Training Acc: 0.7031, Last Char Validation Acc: 0.6719\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 97000 to /content/checkpoint.pkl\n",
            "Iteration 97000, time elapsed: 1331.22 seconds\n",
            "\t \t Training Loss: 1.0030, Validation Loss: 1.0043\n",
            "\t \t Training Acc: 0.6804, Validation Acc: 0.6835\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 98000 to /content/checkpoint.pkl\n",
            "Iteration 98000, time elapsed: 1344.80 seconds\n",
            "\t \t Training Loss: 1.0339, Validation Loss: 1.1060\n",
            "\t \t Training Acc: 0.6749, Validation Acc: 0.6585\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 99000 to /content/checkpoint.pkl\n",
            "Iteration 99000, time elapsed: 1358.40 seconds\n",
            "\t \t Training Loss: 1.0068, Validation Loss: 1.0059\n",
            "\t \t Training Acc: 0.6802, Validation Acc: 0.6870\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 99999 to /content/checkpoint.pkl\n",
            "Iteration 99999, time elapsed: 1372.00 seconds\n",
            "\t \t Training Loss: 1.0118, Validation Loss: 1.0355\n",
            "\t \t Training Acc: 0.6810, Validation Acc: 0.6796\n",
            "\t \t Last Char Training Acc: 0.5781, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "Training completed in 1372.09 seconds.\n"
          ]
        }
      ],
      "source": [
        "if start_iter > 0:\n",
        "        print(f\"Resuming training from iteration = {start_iter}.\")\n",
        "else:\n",
        "        print(\"Starting training from iteration = 0.\")\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "for it in range(start_iter, iter_max):\n",
        "\n",
        "    # get a batch of data\n",
        "    inputs, targets = fn.get_batch(train_data, batch_size, seq_len)\n",
        "\n",
        "    # Perform a training step\n",
        "    rng, sub = jax.random.split(rng)\n",
        "    new_params, new_opt_state, metrics = fn.train_step(\n",
        "            model = model_obj,\n",
        "            params = params,\n",
        "            constants=constants,\n",
        "            opt_state = opt_state,\n",
        "            x = inputs,\n",
        "            y = targets,\n",
        "            tx = optimizer,\n",
        "            rng = sub,\n",
        "            loss_type = loss_type,\n",
        "            aux_loss = use_auxiliary_loss,\n",
        "            aux_weight = aux_weight,\n",
        "            label_smoothing = label_smoothing\n",
        "    )\n",
        "\n",
        "    # Update parameters and optimizer state\n",
        "    params = new_params\n",
        "    opt_state = new_opt_state\n",
        "\n",
        "    # Record training metrics\n",
        "    acc = metrics['acc']\n",
        "    loss = metrics['loss']\n",
        "    last_char_acc = metrics['acc_last']\n",
        "    train_time = time.time() - time_start\n",
        "\n",
        "    train_loss_history.append(loss)\n",
        "\n",
        "    fn.update_training_log(\n",
        "        log_path = \"training_results.log\",\n",
        "        step = it,\n",
        "        train_loss = loss,\n",
        "        train_time = train_time,\n",
        "        train_acc = acc,\n",
        "        last_char_acc = last_char_acc\n",
        "        )\n",
        "\n",
        "    log_every = max(1, iter_max // 100)\n",
        "\n",
        "    if (it % log_every) == 0 or (it == iter_max - 1): # Print every 1% of iterations\n",
        "\n",
        "        # Compute the loss on validation set\n",
        "        batch_size_val = batch_size\n",
        "        seq_len_val = seq_len\n",
        "        val_inputs, val_targets = fn.get_batch(val_data, batch_size_val, seq_len_val)\n",
        "\n",
        "        val_out = model_obj.apply({\"params\": params, \"constants\": constants}, val_inputs, deterministic=True)\n",
        "        val_logits = val_out[\"logits\"]\n",
        "        val_aux_logits = val_out.get('aux_logits', None)\n",
        "\n",
        "        val_loss, val_metrics = fn.loss_and_metrics(\n",
        "            logits = val_logits,\n",
        "            targets = val_targets,\n",
        "            loss_type = loss_type,\n",
        "            aux_loss = use_auxiliary_loss,\n",
        "            aux_logits = val_aux_logits,\n",
        "            aux_weight = aux_weight,\n",
        "            label_smoothing = label_smoothing\n",
        "        )\n",
        "\n",
        "        # Record validation loss and time\n",
        "        val_acc = val_metrics['acc']\n",
        "        last_char_acc_val = val_metrics['acc_last']\n",
        "        val_loss_history.append(val_loss)\n",
        "        time_elapsed = time.time() - time_start\n",
        "        val_step_history.append(it)\n",
        "\n",
        "        fn.update_validation_log(\n",
        "            log_path = \"validation_results.log\",\n",
        "            step = it,\n",
        "            val_loss = val_loss,\n",
        "            val_time = time_elapsed,\n",
        "            val_acc = val_acc,\n",
        "            last_char_val_acc = last_char_acc_val\n",
        "        )\n",
        "\n",
        "        fn.save_checkpoint(\n",
        "            checkpoint_path = checkpoint_file,\n",
        "            params = params,\n",
        "            constants = constants,\n",
        "            opt_state = opt_state,\n",
        "            step = it,\n",
        "            time_elapsed = time_elapsed\n",
        "        )\n",
        "\n",
        "        # Print training and validation metrics\n",
        "        print(f\"Iteration {it}, time elapsed: {time_elapsed:.2f} seconds\")\n",
        "        print(f\"\\t \\t Training Loss: {loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "        print(f\"\\t \\t Training Acc: {acc:.4f}, Validation Acc: {val_acc:.4f}\")\n",
        "        print(f\"\\t \\t Last Char Training Acc: {last_char_acc:.4f}, Last Char Validation Acc: {last_char_acc_val:.4f}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "print(f\"Training completed in {time.time() - time_start:.2f} seconds.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f22e0a4",
      "metadata": {
        "id": "1f22e0a4"
      },
      "source": [
        "## Plot the training and validation loss curves\n",
        "\n",
        "After training, we plot the training and validation loss curves to visualize the model's learning progress over time. This plot is saved to the specified output directory, and will be useful to identify if the model converges at first glance. Among all the ablation experiments for that category, we can also compare these curves to see how different configurations affect the learning dynamics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f4cd9351",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "f4cd9351",
        "outputId": "70a6a70e-a29d-4891-df85-0e100ecc1f0e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot training and validation loss curves\n",
        "plt.plot(train_step_history, train_loss_history, \"-\",label='Training Loss', color='blue')\n",
        "plt.plot(val_step_history, val_loss_history, \"-\", label='Validation Loss', lw = 2, color='red')\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc = \"upper right\")\n",
        "plt.title(\"Training and Validation Loss over Iterations\")\n",
        "plt.legend()\n",
        "plt.savefig(cwd / \"loss_curve.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11644d30",
      "metadata": {
        "id": "11644d30"
      },
      "source": [
        "## Testing the model on a given prompt\n",
        "\n",
        "We finally test the trained model by generating text based on a given prompt. The model successfully generates a sequence of characters that continue from the prompt, and we save the generated text to a file for review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "3767fd8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3767fd8e",
        "outputId": "709b4ddb-817a-4eca-b909-f7356e089994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated ID Shape: (1, 1000)\n",
            "Generated Text:\n",
            "the meaning of life is told to somewhat by reaction it does not develop the constants in the natural sensory value in romance languages are about one zero zero zero zero zero zero zero zero four zero zero zero zero zero zero zero zero zero zero or available unix like one zero zero zero zero zero zero zero zero zero trucks and all of the two and one seven seven two companions for the ill fatally married spiritual burroughs ex bessona crown prince vincent fran a professor of the name of the church fran aise the project one seven eight four one eight seven five was an american composer and correspondent to a scandal of a darker atmosphere and lug images and cracks many buddhists have subjective individual or profit institutional justice statutes which have on several applications of government there is about six six six three zero single government before the independent presidency of the united states the legal status of the power of the day of empire see also catholic theology protestant dates for most of th\n"
          ]
        }
      ],
      "source": [
        "# Test the model on a given prompt\n",
        "prompt = \"the meaning of life is\"\n",
        "encoded_prompt = fn.encode(prompt, chars_to_int)\n",
        "context = encoded_prompt[None, :]\n",
        "\n",
        "B = 1\n",
        "seed = seed\n",
        "generate_len = 1000\n",
        "rng = jax.random.PRNGKey(seed)\n",
        "\n",
        "output_indices = fn.generate_tokens(\n",
        "    model=model_obj,\n",
        "    params=params,\n",
        "    constants=constants,\n",
        "    rng=rng,\n",
        "    context=context,\n",
        "    length=generate_len,\n",
        "    block_size=64,\n",
        "    temperature=0.8,\n",
        "    sample=True,\n",
        "    pad_id=None,\n",
        "    deterministic=True\n",
        ")\n",
        "\n",
        "output_indices = np.array(output_indices)  # Convert from JAX array to NumPy array\n",
        "generated_text = fn.decode(output_indices, int_to_chars)\n",
        "\n",
        "print(\"Generated ID Shape:\", output_indices.shape)\n",
        "print(\"Generated Text:\")\n",
        "print(prompt + generated_text)\n",
        "\n",
        "generated_text_file = cwd / \"generated_text.txt\"\n",
        "\n",
        "with open(generated_text_file, \"w\") as f:\n",
        "    f.write(prompt + generated_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}