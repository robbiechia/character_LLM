{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "adc4842c",
      "metadata": {
        "id": "adc4842c"
      },
      "source": [
        "# Hyperparameter Tuning - Batch Size Experiment\n",
        "\n",
        "After completing ablation experiments, we proceed to conduct hyperparameter tuning to further enhance the model's performance. The architecture is defined as per the 'experiment_model.py' file, and we utilise functions created in the 'experiment_utils.py' file to facilitate the training process.\n",
        "\n",
        "The flow of this notebook is similar to that of previous components, but with modifications to accommodate the hyperparameter tuning requirements. The loss values are recorded for upcoming analysis, visualization and cross comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "477b41b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "477b41b4",
        "outputId": "3b0674a0-a84e-4045-91a9-eedd31f85b66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import optax\n",
        "import sys\n",
        "import jax\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "cwd = Path.cwd()\n",
        "project_root = cwd.parents[0]\n",
        "\n",
        "# Project root for local setup\n",
        "# project_root = cwd.parents[1]\n",
        "# sys.path.append(str(project_root))\n",
        "\n",
        "import hyperparameter_tuning.experiment_setup.experiment_utils as fn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "656e4403",
      "metadata": {
        "id": "656e4403"
      },
      "source": [
        "# Load the Experiment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f18b286",
      "metadata": {
        "id": "1f18b286"
      },
      "source": [
        "## Set the relevant directory paths & update.log file\n",
        "\n",
        "Here, we set the necessary directories and output paths for saving model checkpoints and training logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2168d1a9",
      "metadata": {
        "id": "2168d1a9"
      },
      "outputs": [],
      "source": [
        "# Data directory paths\n",
        "local_dir = project_root / \"data\" / \"text8_train.txt\"\n",
        "online_dir = project_root / \"text8_train.txt\"\n",
        "\n",
        "if local_dir.exists():\n",
        "    data_dir = str(local_dir) # This is for local runs or if repository is cloned directly\n",
        "else:\n",
        "    data_dir = \".\" + str(online_dir) # This is for online GPU platforms\n",
        "\n",
        "config_path = cwd / \"config.json\"\n",
        "training_log_file = cwd / \"training_results.log\"\n",
        "validation_log_file = cwd / \"validation_results.log\"\n",
        "checkpoint_file = cwd / \"checkpoint.pkl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a89050a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a89050a0",
        "outputId": "bc1aa996-8001-4f7f-b374-71b625c0e4eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[initialize_training_log] Initialized training log file at /content/training_results.log\n",
            "[initialize_validation_log] Initialized validation log file at /content/validation_results.log\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(training_log_file):\n",
        "    fn.initialize_training_log(training_log_file)\n",
        "\n",
        "if not os.path.exists(validation_log_file):\n",
        "    fn.initialize_validation_log(validation_log_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da2df4b7",
      "metadata": {
        "id": "da2df4b7"
      },
      "source": [
        "## Load the experiment configurations\n",
        "\n",
        "Prior to running this notebook, the experiment configurations will be set in a 'config.json' file, which will be loaded to set the model hyperparameters and training settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f290991b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f290991b",
        "outputId": "c99b5a07-d5e2-4077-ec33-187c5c4ff84e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[load_config] Loaded configuration from ./config.json\n",
            "We will be conducting  Hyperparameter tuning for Batch Size = 32.\n"
          ]
        }
      ],
      "source": [
        "config = fn.load_config(\"./config.json\")\n",
        "\n",
        "print(f\"We will be conducting {config['description']}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "31bb4815",
      "metadata": {
        "id": "31bb4815"
      },
      "outputs": [],
      "source": [
        "# Load the seed\n",
        "seed = config['seed']\n",
        "\n",
        "# Model parameters\n",
        "vocab_size = config['model']['vocab_size']\n",
        "d_model = config['model']['d_model']\n",
        "n_heads = config['model']['n_heads']\n",
        "n_layers = config['model']['n_layers']\n",
        "mlp_ratio = config['model']['mlp_ratio']\n",
        "seq_len = config['model']['seq_len']\n",
        "\n",
        "# Training parameters\n",
        "loss_type = config['model']['loss_type']\n",
        "dropout_rate = config['model']['dropout']\n",
        "weight_decay = config['model']['weight_decay']\n",
        "label_smoothing = float(config['model']['label_smoothing'])\n",
        "\n",
        "# Mixed precision and other model settings\n",
        "use_mixed_precision = config['model']['mixed_precision']\n",
        "pos_encoding = config['model']['pos_encoding']\n",
        "attention_type = config['model']['attention_type']\n",
        "\n",
        "# Auxiliary loss settings\n",
        "use_auxiliary_loss = config['model']['use_auxiliary_loss']\n",
        "aux_heads = config['model']['aux_heads']\n",
        "aux_weight = config['model']['aux_weight']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cf23122e",
      "metadata": {
        "id": "cf23122e"
      },
      "outputs": [],
      "source": [
        "# Throughput test parameters\n",
        "max_test_iters = config['throughput']['max_test_iters']\n",
        "max_test_time_in_seconds = config['throughput']['max_test_time_in_seconds']\n",
        "compute_budget_hours = config['throughput']['compute_budget_hours']\n",
        "\n",
        "# Training settings\n",
        "val_fraction = config['training']['val_fraction']\n",
        "batch_size = config['training']['batch_size']\n",
        "learning_rate = config['training']['learning_rate']\n",
        "lr_schedule = config['training']['lr_schedule']\n",
        "optimizer_type = config['training']['optimizer']\n",
        "grad_clip = config['training']['grad_clip']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4030d754",
      "metadata": {
        "id": "4030d754"
      },
      "source": [
        "# Loading the Data\n",
        "\n",
        "The same text8 dataset is used, which has 100M characters of text data from Wikipedia articles. It contains only lowercase letters and spaces, and is already pre-split into 90M characters for training and 10M characters for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "75d76b31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75d76b31",
        "outputId": "3d783ef4-1136-41e8-dd61-ae922499361b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training text loaded. Length: 90,000,000 characters.\n",
            "First 500 characters of training text:\n",
            " anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans culottes of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philoso\n"
          ]
        }
      ],
      "source": [
        "# Read in training text file\n",
        "with open(data_dir, 'r', encoding='utf-8') as f:\n",
        "    train_text = f.read()\n",
        "print(f\"Training text loaded. Length: {len(train_text) :,} characters.\")\n",
        "\n",
        "# Inspect first 500 characters of training text\n",
        "print(\"First 500 characters of training text:\")\n",
        "print(train_text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7fd37a2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fd37a2d",
        "outputId": "ed66070a-4ddc-4f33-89da-fc803c303281"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique characters in training text: 27\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(set(train_text)) # unique characters in training text\n",
        "chars_to_int = {ch: i for i, ch in enumerate(chars)} # char to int mapping\n",
        "int_to_chars = {i: ch for i, ch in enumerate(chars)} # int to char mapping\n",
        "\n",
        "print(f\"Unique characters in training text: {len(chars)}\") # should be 27, including space (sanity check)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "032e68f0",
      "metadata": {
        "id": "032e68f0"
      },
      "source": [
        "We further split the training data into a training set and a validation set to monitor the model's performance during training, in accordance to the validation fraction specified in our configuration file (10%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9a969636",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a969636",
        "outputId": "494a40d9-e168-43eb-bba5-16e3352bd27e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training text length: 89,099,996 characters.\n",
            "Validation text length: 900,004 characters.\n"
          ]
        }
      ],
      "source": [
        "train_text, val_text = fn.split_train_val(train_text, val_fraction=val_fraction)\n",
        "\n",
        "print(f\"Training text length: {len(train_text) :,} characters.\")\n",
        "print(f\"Validation text length: {len(val_text) :,} characters.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c28ac68",
      "metadata": {
        "id": "1c28ac68"
      },
      "source": [
        "# Model Initialisation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fe304ec",
      "metadata": {
        "id": "7fe304ec"
      },
      "source": [
        "## Model Setup\n",
        "\n",
        "We intialise our model with the following parameters in accordance to our configuration file.\n",
        "Based on these parameters, our model has approximately ~4.1M parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d19f06bd",
      "metadata": {
        "id": "d19f06bd"
      },
      "outputs": [],
      "source": [
        "# Define the model params\n",
        "rng = jax.random.PRNGKey(seed)\n",
        "\n",
        "model_obj, params, constants = fn.create_train_state(\n",
        "        rng,\n",
        "        vocab_size = vocab_size,\n",
        "        d_model = d_model,\n",
        "        n_heads = n_heads,\n",
        "        n_layers = n_layers,\n",
        "        mlp_ratio = mlp_ratio,\n",
        "        seq_len = seq_len,\n",
        "        dropout = dropout_rate,\n",
        "        aux_loss = use_auxiliary_loss,\n",
        "        num_aux_heads = aux_heads,\n",
        "        mixed_precision = use_mixed_precision,\n",
        "        attention_type = attention_type,\n",
        "        pos_encoding = pos_encoding\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "91839933",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91839933",
        "outputId": "20cff617-052d-4bbd-8c8e-1407724414f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the model: 4,160,768\n"
          ]
        }
      ],
      "source": [
        "total_params = fn.count_parameters(params)\n",
        "\n",
        "print(f\"Total number of parameters in the model: {total_params :,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e709b510",
      "metadata": {
        "id": "e709b510"
      },
      "source": [
        "We perform a sanity check by running a single forward pass with random input data to ensure the model is functioning as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bdc7a187",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdc7a187",
        "outputId": "3a72efa4-e1a8-4c40-9c7a-7a1ecf33e7dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape: (2, 8, 27)\n"
          ]
        }
      ],
      "source": [
        "# SANITY CHECK: Test the model forward pass\n",
        "B, T = 2, 8  # Batch size and sequence length\n",
        "batch = jax.random.randint(key = rng, shape = (B, T), minval = 0, maxval = vocab_size)\n",
        "\n",
        "variables = {\"params\": params, \"constants\": constants}\n",
        "output = model_obj.apply(variables, batch, deterministic=False)\n",
        "print(\"Logits shape:\", output[\"logits\"].shape)  # Expected: (B, T, vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec22aeee",
      "metadata": {
        "id": "ec22aeee"
      },
      "source": [
        "## Initialise the optimizer\n",
        "\n",
        "In this section, we set up the optimizer for training our model in accordance to our configuration file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "05d04750",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05d04750",
        "outputId": "2105bab5-5c4d-4ed2-aa67-7bc79a688d22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer initialized: adam with Learning Rate = 0.001\n"
          ]
        }
      ],
      "source": [
        "# Define the learning rate\n",
        "learning_rate = learning_rate\n",
        "\n",
        "# Create the Optimizer and initialize it\n",
        "if optimizer_type == \"adam\":\n",
        "    optimizer = optax.adam(learning_rate)\n",
        "elif optimizer_type == \"sgd\":\n",
        "    optimizer = optax.sgd(learning_rate)\n",
        "elif optimizer_type == \"adamw\":\n",
        "    optimizer = optax.adamw(\n",
        "        learning_rate = learning_rate,\n",
        "        weight_decay = weight_decay\n",
        "    )\n",
        "\n",
        "# Add gradient clipping if specified\n",
        "if grad_clip is not None and grad_clip != \"none\":\n",
        "    optimizer = optax.chain(\n",
        "        optax.clip_by_global_norm(grad_clip),\n",
        "        optimizer\n",
        "    )\n",
        "\n",
        "\n",
        "opt_state = optimizer.init(params)\n",
        "\n",
        "print(\"Optimizer initialized:\", optimizer_type, \"with Learning Rate =\", learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "233c7fe3",
      "metadata": {
        "id": "233c7fe3"
      },
      "source": [
        "## Text encoding\n",
        "\n",
        "We then encode the text data into integer format for model training. Each unique character is mapped to a unique integer index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "17829ea8",
      "metadata": {
        "id": "17829ea8"
      },
      "outputs": [],
      "source": [
        "# Encode the train, val, test texts\n",
        "train_data = fn.encode(train_text, chars_to_int)\n",
        "val_data = fn.encode(val_text, chars_to_int)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "153631ec",
      "metadata": {
        "id": "153631ec"
      },
      "source": [
        "## Determine maximum permissible training steps\n",
        "\n",
        "Taking into account possible compute limitations, we perform a preliminary calculation to determine the maximum number of training steps we can perform based on the throughput of our model and the total training time available. For this preliminary test, the default maximum training time is 60 seconds, and commpute budget hours is 2 hours.\n",
        "\n",
        "Based on the throughput calculated from the preliminary test, the estimated maximum no. of training steps we can perform within this compute budget is ~360,000. To ensure we keep within the budget, we set the maximum training steps to be 200,000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1312e527",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1312e527",
        "outputId": "1f37a401-cd11-4c5d-9cb0-7448fa2d2cc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Benchmark completed in 19.96 seconds.\n",
            "Total tokens processed: 8192000\n",
            "Throughput: 410371.21 tokens/second\n",
            "Estimated max steps within compute budget: 360677.0\n"
          ]
        }
      ],
      "source": [
        "# Determining how many steps we can run in a reasonable time\n",
        "max_iters = max_test_iters\n",
        "max_time = max_test_time_in_seconds # in seconds\n",
        "max_compute_time = compute_budget_hours # in hours\n",
        "\n",
        "_ , max_steps = fn.calculate_throughput(\n",
        "    max_test_iters = max_iters,\n",
        "    max_test_time = max_time,\n",
        "    model = model_obj,\n",
        "    params = params,\n",
        "    opt_state = opt_state,\n",
        "    optimizer = optimizer,\n",
        "    rng = rng,\n",
        "    batch_size = batch_size,\n",
        "    seq_len = seq_len,\n",
        "    compute_budget = max_compute_time,\n",
        "    train_data = train_data,\n",
        "    loss_type = loss_type,\n",
        "    aux_loss = use_auxiliary_loss,\n",
        "    aux_weight = aux_weight,\n",
        "    constants = constants,\n",
        "    label_smoothing = label_smoothing\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff66f55f",
      "metadata": {
        "id": "ff66f55f"
      },
      "source": [
        "# Model Training & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b839549c",
      "metadata": {
        "id": "b839549c"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "Now, we proceed to train the model over the determined number of training iterations. During training, we monitor the training loss and periodically evaluate the model on the validation set to track its performance. We also make sure to record the time taken for training to ensure it stays within our compute budget."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1262eda3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1262eda3",
        "outputId": "9db8829d-8e79-43ce-e510-171fb581a4d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[load_checkpoint] No checkpoint found at /content/checkpoint.pkl\n",
            "[load_checkpoint] Starting training as per usual.\n"
          ]
        }
      ],
      "source": [
        "iter_max = 200000\n",
        "\n",
        "# To track training and validation loss, as well as time taken\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "train_step_history = list(range(iter_max))\n",
        "val_step_history = []\n",
        "\n",
        "# Load checkpoint if it exists\n",
        "params, opt_state, constants, start_iter = fn.load_checkpoint(\n",
        "    checkpoint_file,\n",
        "    params,\n",
        "    constants,\n",
        "    opt_state\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd2b91d3",
      "metadata": {
        "id": "cd2b91d3"
      },
      "source": [
        "We then train the model and log the training and validation losses for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c7cbde26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7cbde26",
        "outputId": "f42201ec-0ce5-49ad-ad07-2e511558e024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training from iteration = 0.\n",
            "[save_checkpoint] Saved checkpoint at step 0 to /content/checkpoint.pkl\n",
            "Iteration 0, time elapsed: 6.90 seconds\n",
            "\t \t Training Loss: 3.6841, Validation Loss: 4.4571\n",
            "\t \t Training Acc: 0.0652, Validation Acc: 0.1688\n",
            "\t \t Last Char Training Acc: 0.0625, Last Char Validation Acc: 0.0312\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 2000 to /content/checkpoint.pkl\n",
            "Iteration 2000, time elapsed: 20.18 seconds\n",
            "\t \t Training Loss: 1.4276, Validation Loss: 1.3735\n",
            "\t \t Training Acc: 0.5543, Validation Acc: 0.5684\n",
            "\t \t Last Char Training Acc: 0.5625, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 4000 to /content/checkpoint.pkl\n",
            "Iteration 4000, time elapsed: 33.94 seconds\n",
            "\t \t Training Loss: 1.2993, Validation Loss: 1.2760\n",
            "\t \t Training Acc: 0.5959, Validation Acc: 0.5974\n",
            "\t \t Last Char Training Acc: 0.5625, Last Char Validation Acc: 0.5312\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 6000 to /content/checkpoint.pkl\n",
            "Iteration 6000, time elapsed: 47.11 seconds\n",
            "\t \t Training Loss: 1.3159, Validation Loss: 1.2681\n",
            "\t \t Training Acc: 0.5935, Validation Acc: 0.5967\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.5625\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 8000 to /content/checkpoint.pkl\n",
            "Iteration 8000, time elapsed: 60.77 seconds\n",
            "\t \t Training Loss: 1.2171, Validation Loss: 1.2271\n",
            "\t \t Training Acc: 0.6193, Validation Acc: 0.6089\n",
            "\t \t Last Char Training Acc: 0.5000, Last Char Validation Acc: 0.5312\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 10000 to /content/checkpoint.pkl\n",
            "Iteration 10000, time elapsed: 74.55 seconds\n",
            "\t \t Training Loss: 1.2068, Validation Loss: 1.2250\n",
            "\t \t Training Acc: 0.6195, Validation Acc: 0.6144\n",
            "\t \t Last Char Training Acc: 0.5312, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 12000 to /content/checkpoint.pkl\n",
            "Iteration 12000, time elapsed: 88.55 seconds\n",
            "\t \t Training Loss: 1.1860, Validation Loss: 1.1501\n",
            "\t \t Training Acc: 0.6217, Validation Acc: 0.6328\n",
            "\t \t Last Char Training Acc: 0.5625, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 14000 to /content/checkpoint.pkl\n",
            "Iteration 14000, time elapsed: 102.39 seconds\n",
            "\t \t Training Loss: 1.1783, Validation Loss: 1.2505\n",
            "\t \t Training Acc: 0.6252, Validation Acc: 0.6088\n",
            "\t \t Last Char Training Acc: 0.5000, Last Char Validation Acc: 0.5312\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 16000 to /content/checkpoint.pkl\n",
            "Iteration 16000, time elapsed: 116.00 seconds\n",
            "\t \t Training Loss: 1.1760, Validation Loss: 1.1915\n",
            "\t \t Training Acc: 0.6301, Validation Acc: 0.6299\n",
            "\t \t Last Char Training Acc: 0.4375, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 18000 to /content/checkpoint.pkl\n",
            "Iteration 18000, time elapsed: 129.87 seconds\n",
            "\t \t Training Loss: 1.1675, Validation Loss: 1.1478\n",
            "\t \t Training Acc: 0.6267, Validation Acc: 0.6334\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 20000 to /content/checkpoint.pkl\n",
            "Iteration 20000, time elapsed: 144.06 seconds\n",
            "\t \t Training Loss: 1.1491, Validation Loss: 1.1593\n",
            "\t \t Training Acc: 0.6390, Validation Acc: 0.6387\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 22000 to /content/checkpoint.pkl\n",
            "Iteration 22000, time elapsed: 157.91 seconds\n",
            "\t \t Training Loss: 1.1137, Validation Loss: 1.0720\n",
            "\t \t Training Acc: 0.6494, Validation Acc: 0.6570\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 24000 to /content/checkpoint.pkl\n",
            "Iteration 24000, time elapsed: 172.02 seconds\n",
            "\t \t Training Loss: 1.0914, Validation Loss: 1.1037\n",
            "\t \t Training Acc: 0.6595, Validation Acc: 0.6520\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 26000 to /content/checkpoint.pkl\n",
            "Iteration 26000, time elapsed: 185.91 seconds\n",
            "\t \t Training Loss: 1.0680, Validation Loss: 1.1298\n",
            "\t \t Training Acc: 0.6631, Validation Acc: 0.6458\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 28000 to /content/checkpoint.pkl\n",
            "Iteration 28000, time elapsed: 199.95 seconds\n",
            "\t \t Training Loss: 1.1745, Validation Loss: 1.1117\n",
            "\t \t Training Acc: 0.6331, Validation Acc: 0.6576\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 30000 to /content/checkpoint.pkl\n",
            "Iteration 30000, time elapsed: 214.07 seconds\n",
            "\t \t Training Loss: 1.0502, Validation Loss: 1.0961\n",
            "\t \t Training Acc: 0.6696, Validation Acc: 0.6539\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 32000 to /content/checkpoint.pkl\n",
            "Iteration 32000, time elapsed: 227.88 seconds\n",
            "\t \t Training Loss: 1.0511, Validation Loss: 1.1629\n",
            "\t \t Training Acc: 0.6731, Validation Acc: 0.6434\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 34000 to /content/checkpoint.pkl\n",
            "Iteration 34000, time elapsed: 241.82 seconds\n",
            "\t \t Training Loss: 1.1082, Validation Loss: 1.0467\n",
            "\t \t Training Acc: 0.6544, Validation Acc: 0.6711\n",
            "\t \t Last Char Training Acc: 0.5625, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 36000 to /content/checkpoint.pkl\n",
            "Iteration 36000, time elapsed: 255.86 seconds\n",
            "\t \t Training Loss: 1.0781, Validation Loss: 1.0711\n",
            "\t \t Training Acc: 0.6626, Validation Acc: 0.6613\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 38000 to /content/checkpoint.pkl\n",
            "Iteration 38000, time elapsed: 269.92 seconds\n",
            "\t \t Training Loss: 1.0861, Validation Loss: 1.0908\n",
            "\t \t Training Acc: 0.6592, Validation Acc: 0.6616\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 40000 to /content/checkpoint.pkl\n",
            "Iteration 40000, time elapsed: 284.15 seconds\n",
            "\t \t Training Loss: 1.0907, Validation Loss: 1.0885\n",
            "\t \t Training Acc: 0.6538, Validation Acc: 0.6554\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 42000 to /content/checkpoint.pkl\n",
            "Iteration 42000, time elapsed: 297.69 seconds\n",
            "\t \t Training Loss: 1.0786, Validation Loss: 1.0968\n",
            "\t \t Training Acc: 0.6587, Validation Acc: 0.6622\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 44000 to /content/checkpoint.pkl\n",
            "Iteration 44000, time elapsed: 311.81 seconds\n",
            "\t \t Training Loss: 1.0522, Validation Loss: 1.1312\n",
            "\t \t Training Acc: 0.6710, Validation Acc: 0.6442\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 46000 to /content/checkpoint.pkl\n",
            "Iteration 46000, time elapsed: 325.76 seconds\n",
            "\t \t Training Loss: 1.0660, Validation Loss: 1.0517\n",
            "\t \t Training Acc: 0.6683, Validation Acc: 0.6665\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.5000\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 48000 to /content/checkpoint.pkl\n",
            "Iteration 48000, time elapsed: 339.55 seconds\n",
            "\t \t Training Loss: 1.1061, Validation Loss: 1.0442\n",
            "\t \t Training Acc: 0.6528, Validation Acc: 0.6670\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 50000 to /content/checkpoint.pkl\n",
            "Iteration 50000, time elapsed: 352.97 seconds\n",
            "\t \t Training Loss: 1.0440, Validation Loss: 1.0889\n",
            "\t \t Training Acc: 0.6732, Validation Acc: 0.6626\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 52000 to /content/checkpoint.pkl\n",
            "Iteration 52000, time elapsed: 366.88 seconds\n",
            "\t \t Training Loss: 1.0217, Validation Loss: 1.0532\n",
            "\t \t Training Acc: 0.6830, Validation Acc: 0.6746\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 54000 to /content/checkpoint.pkl\n",
            "Iteration 54000, time elapsed: 380.72 seconds\n",
            "\t \t Training Loss: 1.0128, Validation Loss: 1.0404\n",
            "\t \t Training Acc: 0.6825, Validation Acc: 0.6724\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.8125\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 56000 to /content/checkpoint.pkl\n",
            "Iteration 56000, time elapsed: 394.50 seconds\n",
            "\t \t Training Loss: 1.0964, Validation Loss: 1.0567\n",
            "\t \t Training Acc: 0.6527, Validation Acc: 0.6649\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 58000 to /content/checkpoint.pkl\n",
            "Iteration 58000, time elapsed: 408.43 seconds\n",
            "\t \t Training Loss: 1.0560, Validation Loss: 1.0298\n",
            "\t \t Training Acc: 0.6698, Validation Acc: 0.6772\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.5625\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 60000 to /content/checkpoint.pkl\n",
            "Iteration 60000, time elapsed: 422.21 seconds\n",
            "\t \t Training Loss: 1.0552, Validation Loss: 1.0351\n",
            "\t \t Training Acc: 0.6676, Validation Acc: 0.6674\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.5312\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 62000 to /content/checkpoint.pkl\n",
            "Iteration 62000, time elapsed: 436.14 seconds\n",
            "\t \t Training Loss: 1.0675, Validation Loss: 1.0391\n",
            "\t \t Training Acc: 0.6725, Validation Acc: 0.6718\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 64000 to /content/checkpoint.pkl\n",
            "Iteration 64000, time elapsed: 450.12 seconds\n",
            "\t \t Training Loss: 1.0503, Validation Loss: 1.0875\n",
            "\t \t Training Acc: 0.6719, Validation Acc: 0.6573\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 66000 to /content/checkpoint.pkl\n",
            "Iteration 66000, time elapsed: 464.38 seconds\n",
            "\t \t Training Loss: 1.0190, Validation Loss: 1.0954\n",
            "\t \t Training Acc: 0.6814, Validation Acc: 0.6617\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 68000 to /content/checkpoint.pkl\n",
            "Iteration 68000, time elapsed: 478.38 seconds\n",
            "\t \t Training Loss: 1.0136, Validation Loss: 1.0805\n",
            "\t \t Training Acc: 0.6820, Validation Acc: 0.6626\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 70000 to /content/checkpoint.pkl\n",
            "Iteration 70000, time elapsed: 492.19 seconds\n",
            "\t \t Training Loss: 1.0754, Validation Loss: 1.0234\n",
            "\t \t Training Acc: 0.6633, Validation Acc: 0.6779\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 72000 to /content/checkpoint.pkl\n",
            "Iteration 72000, time elapsed: 506.22 seconds\n",
            "\t \t Training Loss: 1.0769, Validation Loss: 1.0655\n",
            "\t \t Training Acc: 0.6600, Validation Acc: 0.6729\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 74000 to /content/checkpoint.pkl\n",
            "Iteration 74000, time elapsed: 520.43 seconds\n",
            "\t \t Training Loss: 1.0546, Validation Loss: 1.0596\n",
            "\t \t Training Acc: 0.6801, Validation Acc: 0.6616\n",
            "\t \t Last Char Training Acc: 0.8125, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 76000 to /content/checkpoint.pkl\n",
            "Iteration 76000, time elapsed: 534.45 seconds\n",
            "\t \t Training Loss: 1.0210, Validation Loss: 1.0044\n",
            "\t \t Training Acc: 0.6761, Validation Acc: 0.6842\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.8438\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 78000 to /content/checkpoint.pkl\n",
            "Iteration 78000, time elapsed: 548.69 seconds\n",
            "\t \t Training Loss: 1.0198, Validation Loss: 1.0558\n",
            "\t \t Training Acc: 0.6790, Validation Acc: 0.6653\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 80000 to /content/checkpoint.pkl\n",
            "Iteration 80000, time elapsed: 562.73 seconds\n",
            "\t \t Training Loss: 1.0412, Validation Loss: 1.0708\n",
            "\t \t Training Acc: 0.6753, Validation Acc: 0.6592\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 82000 to /content/checkpoint.pkl\n",
            "Iteration 82000, time elapsed: 576.22 seconds\n",
            "\t \t Training Loss: 1.0555, Validation Loss: 1.0438\n",
            "\t \t Training Acc: 0.6663, Validation Acc: 0.6704\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 84000 to /content/checkpoint.pkl\n",
            "Iteration 84000, time elapsed: 589.90 seconds\n",
            "\t \t Training Loss: 0.9930, Validation Loss: 1.0430\n",
            "\t \t Training Acc: 0.6780, Validation Acc: 0.6747\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 86000 to /content/checkpoint.pkl\n",
            "Iteration 86000, time elapsed: 603.59 seconds\n",
            "\t \t Training Loss: 0.9955, Validation Loss: 1.0288\n",
            "\t \t Training Acc: 0.6869, Validation Acc: 0.6821\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.5625\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 88000 to /content/checkpoint.pkl\n",
            "Iteration 88000, time elapsed: 617.42 seconds\n",
            "\t \t Training Loss: 1.0495, Validation Loss: 1.0327\n",
            "\t \t Training Acc: 0.6678, Validation Acc: 0.6808\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 90000 to /content/checkpoint.pkl\n",
            "Iteration 90000, time elapsed: 631.73 seconds\n",
            "\t \t Training Loss: 1.0083, Validation Loss: 1.0398\n",
            "\t \t Training Acc: 0.6809, Validation Acc: 0.6718\n",
            "\t \t Last Char Training Acc: 0.8125, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 92000 to /content/checkpoint.pkl\n",
            "Iteration 92000, time elapsed: 645.41 seconds\n",
            "\t \t Training Loss: 1.0088, Validation Loss: 1.0460\n",
            "\t \t Training Acc: 0.6868, Validation Acc: 0.6726\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 94000 to /content/checkpoint.pkl\n",
            "Iteration 94000, time elapsed: 659.11 seconds\n",
            "\t \t Training Loss: 1.0413, Validation Loss: 1.0618\n",
            "\t \t Training Acc: 0.6755, Validation Acc: 0.6648\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 96000 to /content/checkpoint.pkl\n",
            "Iteration 96000, time elapsed: 673.16 seconds\n",
            "\t \t Training Loss: 0.9929, Validation Loss: 1.0153\n",
            "\t \t Training Acc: 0.6903, Validation Acc: 0.6802\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 98000 to /content/checkpoint.pkl\n",
            "Iteration 98000, time elapsed: 687.52 seconds\n",
            "\t \t Training Loss: 1.0035, Validation Loss: 1.0618\n",
            "\t \t Training Acc: 0.6848, Validation Acc: 0.6699\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 100000 to /content/checkpoint.pkl\n",
            "Iteration 100000, time elapsed: 701.67 seconds\n",
            "\t \t Training Loss: 1.0435, Validation Loss: 1.0328\n",
            "\t \t Training Acc: 0.6720, Validation Acc: 0.6842\n",
            "\t \t Last Char Training Acc: 0.8125, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 102000 to /content/checkpoint.pkl\n",
            "Iteration 102000, time elapsed: 715.34 seconds\n",
            "\t \t Training Loss: 1.0146, Validation Loss: 1.1088\n",
            "\t \t Training Acc: 0.6835, Validation Acc: 0.6564\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 104000 to /content/checkpoint.pkl\n",
            "Iteration 104000, time elapsed: 729.75 seconds\n",
            "\t \t Training Loss: 1.0184, Validation Loss: 1.0228\n",
            "\t \t Training Acc: 0.6818, Validation Acc: 0.6852\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 106000 to /content/checkpoint.pkl\n",
            "Iteration 106000, time elapsed: 744.04 seconds\n",
            "\t \t Training Loss: 1.0099, Validation Loss: 1.0142\n",
            "\t \t Training Acc: 0.6843, Validation Acc: 0.6802\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.8750\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 108000 to /content/checkpoint.pkl\n",
            "Iteration 108000, time elapsed: 758.04 seconds\n",
            "\t \t Training Loss: 0.9576, Validation Loss: 1.0874\n",
            "\t \t Training Acc: 0.6980, Validation Acc: 0.6711\n",
            "\t \t Last Char Training Acc: 0.9062, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 110000 to /content/checkpoint.pkl\n",
            "Iteration 110000, time elapsed: 772.17 seconds\n",
            "\t \t Training Loss: 0.9908, Validation Loss: 1.0232\n",
            "\t \t Training Acc: 0.6798, Validation Acc: 0.6824\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.8125\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 112000 to /content/checkpoint.pkl\n",
            "Iteration 112000, time elapsed: 786.13 seconds\n",
            "\t \t Training Loss: 1.0111, Validation Loss: 1.0158\n",
            "\t \t Training Acc: 0.6854, Validation Acc: 0.6809\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 114000 to /content/checkpoint.pkl\n",
            "Iteration 114000, time elapsed: 800.32 seconds\n",
            "\t \t Training Loss: 1.0279, Validation Loss: 1.0141\n",
            "\t \t Training Acc: 0.6803, Validation Acc: 0.6821\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.5000\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 116000 to /content/checkpoint.pkl\n",
            "Iteration 116000, time elapsed: 814.50 seconds\n",
            "\t \t Training Loss: 1.0020, Validation Loss: 1.0989\n",
            "\t \t Training Acc: 0.6896, Validation Acc: 0.6591\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 118000 to /content/checkpoint.pkl\n",
            "Iteration 118000, time elapsed: 828.31 seconds\n",
            "\t \t Training Loss: 1.0112, Validation Loss: 1.0400\n",
            "\t \t Training Acc: 0.6812, Validation Acc: 0.6732\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 120000 to /content/checkpoint.pkl\n",
            "Iteration 120000, time elapsed: 842.19 seconds\n",
            "\t \t Training Loss: 1.0353, Validation Loss: 1.0341\n",
            "\t \t Training Acc: 0.6753, Validation Acc: 0.6759\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 122000 to /content/checkpoint.pkl\n",
            "Iteration 122000, time elapsed: 856.04 seconds\n",
            "\t \t Training Loss: 1.0056, Validation Loss: 1.0209\n",
            "\t \t Training Acc: 0.6853, Validation Acc: 0.6785\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.5625\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 124000 to /content/checkpoint.pkl\n",
            "Iteration 124000, time elapsed: 870.64 seconds\n",
            "\t \t Training Loss: 1.0005, Validation Loss: 1.0716\n",
            "\t \t Training Acc: 0.6864, Validation Acc: 0.6700\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 126000 to /content/checkpoint.pkl\n",
            "Iteration 126000, time elapsed: 884.55 seconds\n",
            "\t \t Training Loss: 1.0027, Validation Loss: 1.0230\n",
            "\t \t Training Acc: 0.6842, Validation Acc: 0.6803\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.5312\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 128000 to /content/checkpoint.pkl\n",
            "Iteration 128000, time elapsed: 898.50 seconds\n",
            "\t \t Training Loss: 0.9676, Validation Loss: 1.0459\n",
            "\t \t Training Acc: 0.6981, Validation Acc: 0.6792\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 130000 to /content/checkpoint.pkl\n",
            "Iteration 130000, time elapsed: 912.35 seconds\n",
            "\t \t Training Loss: 1.0396, Validation Loss: 1.0425\n",
            "\t \t Training Acc: 0.6742, Validation Acc: 0.6785\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 132000 to /content/checkpoint.pkl\n",
            "Iteration 132000, time elapsed: 926.47 seconds\n",
            "\t \t Training Loss: 0.9820, Validation Loss: 1.0128\n",
            "\t \t Training Acc: 0.6924, Validation Acc: 0.6802\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 134000 to /content/checkpoint.pkl\n",
            "Iteration 134000, time elapsed: 940.16 seconds\n",
            "\t \t Training Loss: 0.9603, Validation Loss: 1.0474\n",
            "\t \t Training Acc: 0.6951, Validation Acc: 0.6738\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 136000 to /content/checkpoint.pkl\n",
            "Iteration 136000, time elapsed: 954.09 seconds\n",
            "\t \t Training Loss: 1.0018, Validation Loss: 1.0038\n",
            "\t \t Training Acc: 0.6887, Validation Acc: 0.6787\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 138000 to /content/checkpoint.pkl\n",
            "Iteration 138000, time elapsed: 968.00 seconds\n",
            "\t \t Training Loss: 1.0276, Validation Loss: 1.0397\n",
            "\t \t Training Acc: 0.6792, Validation Acc: 0.6760\n",
            "\t \t Last Char Training Acc: 0.8750, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 140000 to /content/checkpoint.pkl\n",
            "Iteration 140000, time elapsed: 981.82 seconds\n",
            "\t \t Training Loss: 1.0396, Validation Loss: 1.0503\n",
            "\t \t Training Acc: 0.6748, Validation Acc: 0.6760\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 142000 to /content/checkpoint.pkl\n",
            "Iteration 142000, time elapsed: 996.04 seconds\n",
            "\t \t Training Loss: 0.9904, Validation Loss: 1.0236\n",
            "\t \t Training Acc: 0.6868, Validation Acc: 0.6798\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.8125\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 144000 to /content/checkpoint.pkl\n",
            "Iteration 144000, time elapsed: 1009.91 seconds\n",
            "\t \t Training Loss: 1.0398, Validation Loss: 1.0208\n",
            "\t \t Training Acc: 0.6770, Validation Acc: 0.6775\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 146000 to /content/checkpoint.pkl\n",
            "Iteration 146000, time elapsed: 1023.91 seconds\n",
            "\t \t Training Loss: 0.9597, Validation Loss: 0.9994\n",
            "\t \t Training Acc: 0.6898, Validation Acc: 0.6859\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 148000 to /content/checkpoint.pkl\n",
            "Iteration 148000, time elapsed: 1037.98 seconds\n",
            "\t \t Training Loss: 0.9629, Validation Loss: 1.0082\n",
            "\t \t Training Acc: 0.6963, Validation Acc: 0.6835\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 150000 to /content/checkpoint.pkl\n",
            "Iteration 150000, time elapsed: 1052.12 seconds\n",
            "\t \t Training Loss: 0.9819, Validation Loss: 1.0300\n",
            "\t \t Training Acc: 0.6913, Validation Acc: 0.6782\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 152000 to /content/checkpoint.pkl\n",
            "Iteration 152000, time elapsed: 1066.18 seconds\n",
            "\t \t Training Loss: 1.0523, Validation Loss: 1.0285\n",
            "\t \t Training Acc: 0.6703, Validation Acc: 0.6776\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 154000 to /content/checkpoint.pkl\n",
            "Iteration 154000, time elapsed: 1079.88 seconds\n",
            "\t \t Training Loss: 0.9837, Validation Loss: 0.9852\n",
            "\t \t Training Acc: 0.6932, Validation Acc: 0.6870\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 156000 to /content/checkpoint.pkl\n",
            "Iteration 156000, time elapsed: 1093.70 seconds\n",
            "\t \t Training Loss: 0.9416, Validation Loss: 1.0431\n",
            "\t \t Training Acc: 0.7059, Validation Acc: 0.6683\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 158000 to /content/checkpoint.pkl\n",
            "Iteration 158000, time elapsed: 1107.84 seconds\n",
            "\t \t Training Loss: 0.9634, Validation Loss: 1.0325\n",
            "\t \t Training Acc: 0.6904, Validation Acc: 0.6760\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 160000 to /content/checkpoint.pkl\n",
            "Iteration 160000, time elapsed: 1122.17 seconds\n",
            "\t \t Training Loss: 0.9844, Validation Loss: 1.0341\n",
            "\t \t Training Acc: 0.6898, Validation Acc: 0.6770\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 162000 to /content/checkpoint.pkl\n",
            "Iteration 162000, time elapsed: 1136.72 seconds\n",
            "\t \t Training Loss: 0.9670, Validation Loss: 1.0024\n",
            "\t \t Training Acc: 0.6932, Validation Acc: 0.6830\n",
            "\t \t Last Char Training Acc: 0.5625, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 164000 to /content/checkpoint.pkl\n",
            "Iteration 164000, time elapsed: 1150.87 seconds\n",
            "\t \t Training Loss: 1.0355, Validation Loss: 1.0513\n",
            "\t \t Training Acc: 0.6771, Validation Acc: 0.6632\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.8750\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 166000 to /content/checkpoint.pkl\n",
            "Iteration 166000, time elapsed: 1164.77 seconds\n",
            "\t \t Training Loss: 0.9824, Validation Loss: 1.0296\n",
            "\t \t Training Acc: 0.6875, Validation Acc: 0.6785\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 168000 to /content/checkpoint.pkl\n",
            "Iteration 168000, time elapsed: 1178.56 seconds\n",
            "\t \t Training Loss: 0.9624, Validation Loss: 1.0716\n",
            "\t \t Training Acc: 0.7001, Validation Acc: 0.6652\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.8125\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 170000 to /content/checkpoint.pkl\n",
            "Iteration 170000, time elapsed: 1192.72 seconds\n",
            "\t \t Training Loss: 0.9634, Validation Loss: 1.0718\n",
            "\t \t Training Acc: 0.6971, Validation Acc: 0.6654\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 172000 to /content/checkpoint.pkl\n",
            "Iteration 172000, time elapsed: 1206.35 seconds\n",
            "\t \t Training Loss: 0.9943, Validation Loss: 1.0756\n",
            "\t \t Training Acc: 0.6887, Validation Acc: 0.6696\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 174000 to /content/checkpoint.pkl\n",
            "Iteration 174000, time elapsed: 1220.12 seconds\n",
            "\t \t Training Loss: 0.9752, Validation Loss: 1.0067\n",
            "\t \t Training Acc: 0.6902, Validation Acc: 0.6864\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 176000 to /content/checkpoint.pkl\n",
            "Iteration 176000, time elapsed: 1233.90 seconds\n",
            "\t \t Training Loss: 0.9980, Validation Loss: 1.0191\n",
            "\t \t Training Acc: 0.6882, Validation Acc: 0.6819\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 178000 to /content/checkpoint.pkl\n",
            "Iteration 178000, time elapsed: 1248.32 seconds\n",
            "\t \t Training Loss: 0.9263, Validation Loss: 1.0353\n",
            "\t \t Training Acc: 0.7048, Validation Acc: 0.6810\n",
            "\t \t Last Char Training Acc: 0.8750, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 180000 to /content/checkpoint.pkl\n",
            "Iteration 180000, time elapsed: 1262.21 seconds\n",
            "\t \t Training Loss: 0.9352, Validation Loss: 1.0501\n",
            "\t \t Training Acc: 0.7045, Validation Acc: 0.6741\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 182000 to /content/checkpoint.pkl\n",
            "Iteration 182000, time elapsed: 1276.09 seconds\n",
            "\t \t Training Loss: 0.9446, Validation Loss: 1.0845\n",
            "\t \t Training Acc: 0.7057, Validation Acc: 0.6628\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 184000 to /content/checkpoint.pkl\n",
            "Iteration 184000, time elapsed: 1290.29 seconds\n",
            "\t \t Training Loss: 0.9763, Validation Loss: 1.0553\n",
            "\t \t Training Acc: 0.6949, Validation Acc: 0.6715\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 186000 to /content/checkpoint.pkl\n",
            "Iteration 186000, time elapsed: 1304.30 seconds\n",
            "\t \t Training Loss: 1.0321, Validation Loss: 1.0464\n",
            "\t \t Training Acc: 0.6757, Validation Acc: 0.6698\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 188000 to /content/checkpoint.pkl\n",
            "Iteration 188000, time elapsed: 1318.09 seconds\n",
            "\t \t Training Loss: 0.9449, Validation Loss: 1.0584\n",
            "\t \t Training Acc: 0.7034, Validation Acc: 0.6680\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 190000 to /content/checkpoint.pkl\n",
            "Iteration 190000, time elapsed: 1331.68 seconds\n",
            "\t \t Training Loss: 0.9856, Validation Loss: 1.0376\n",
            "\t \t Training Acc: 0.6884, Validation Acc: 0.6799\n",
            "\t \t Last Char Training Acc: 0.5625, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 192000 to /content/checkpoint.pkl\n",
            "Iteration 192000, time elapsed: 1345.77 seconds\n",
            "\t \t Training Loss: 1.0096, Validation Loss: 1.0136\n",
            "\t \t Training Acc: 0.6841, Validation Acc: 0.6842\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 194000 to /content/checkpoint.pkl\n",
            "Iteration 194000, time elapsed: 1359.94 seconds\n",
            "\t \t Training Loss: 1.0053, Validation Loss: 1.0472\n",
            "\t \t Training Acc: 0.6908, Validation Acc: 0.6741\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.8125\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 196000 to /content/checkpoint.pkl\n",
            "Iteration 196000, time elapsed: 1373.69 seconds\n",
            "\t \t Training Loss: 1.0318, Validation Loss: 1.0299\n",
            "\t \t Training Acc: 0.6769, Validation Acc: 0.6754\n",
            "\t \t Last Char Training Acc: 0.8125, Last Char Validation Acc: 0.5625\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 198000 to /content/checkpoint.pkl\n",
            "Iteration 198000, time elapsed: 1387.94 seconds\n",
            "\t \t Training Loss: 0.9854, Validation Loss: 1.0403\n",
            "\t \t Training Acc: 0.6902, Validation Acc: 0.6785\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 199999 to /content/checkpoint.pkl\n",
            "Iteration 199999, time elapsed: 1402.06 seconds\n",
            "\t \t Training Loss: 0.9995, Validation Loss: 1.0211\n",
            "\t \t Training Acc: 0.6896, Validation Acc: 0.6786\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "Training completed in 1402.15 seconds.\n"
          ]
        }
      ],
      "source": [
        "if start_iter > 0:\n",
        "        print(f\"Resuming training from iteration = {start_iter}.\")\n",
        "else:\n",
        "        print(\"Starting training from iteration = 0.\")\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "for it in range(start_iter, iter_max):\n",
        "\n",
        "    # get a batch of data\n",
        "    inputs, targets = fn.get_batch(train_data, batch_size, seq_len)\n",
        "\n",
        "    # Perform a training step\n",
        "    rng, sub = jax.random.split(rng)\n",
        "    new_params, new_opt_state, metrics = fn.train_step(\n",
        "            model = model_obj,\n",
        "            params = params,\n",
        "            constants=constants,\n",
        "            opt_state = opt_state,\n",
        "            x = inputs,\n",
        "            y = targets,\n",
        "            tx = optimizer,\n",
        "            rng = sub,\n",
        "            loss_type = loss_type,\n",
        "            aux_loss = use_auxiliary_loss,\n",
        "            aux_weight = aux_weight,\n",
        "            label_smoothing = label_smoothing\n",
        "    )\n",
        "\n",
        "    # Update parameters and optimizer state\n",
        "    params = new_params\n",
        "    opt_state = new_opt_state\n",
        "\n",
        "    # Record training metrics\n",
        "    acc = metrics['acc']\n",
        "    loss = metrics['loss']\n",
        "    last_char_acc = metrics['acc_last']\n",
        "    train_time = time.time() - time_start\n",
        "\n",
        "    train_loss_history.append(loss)\n",
        "\n",
        "    fn.update_training_log(\n",
        "        log_path = \"training_results.log\",\n",
        "        step = it,\n",
        "        train_loss = loss,\n",
        "        train_time = train_time,\n",
        "        train_acc = acc,\n",
        "        last_char_acc = last_char_acc\n",
        "        )\n",
        "\n",
        "    log_every = max(1, iter_max // 100)\n",
        "\n",
        "    if (it % log_every) == 0 or (it == iter_max - 1): # Print every 1% of iterations\n",
        "\n",
        "        # Compute the loss on validation set\n",
        "        batch_size_val = batch_size\n",
        "        seq_len_val = seq_len\n",
        "        val_inputs, val_targets = fn.get_batch(val_data, batch_size_val, seq_len_val)\n",
        "\n",
        "        val_out = model_obj.apply({\"params\": params, \"constants\": constants}, val_inputs, deterministic=True)\n",
        "        val_logits = val_out[\"logits\"]\n",
        "        val_aux_logits = val_out.get('aux_logits', None)\n",
        "\n",
        "        val_loss, val_metrics = fn.loss_and_metrics(\n",
        "            logits = val_logits,\n",
        "            targets = val_targets,\n",
        "            loss_type = loss_type,\n",
        "            aux_loss = use_auxiliary_loss,\n",
        "            aux_logits = val_aux_logits,\n",
        "            aux_weight = aux_weight,\n",
        "            label_smoothing = label_smoothing\n",
        "        )\n",
        "\n",
        "        # Record validation loss and time\n",
        "        val_acc = val_metrics['acc']\n",
        "        last_char_acc_val = val_metrics['acc_last']\n",
        "        val_loss_history.append(val_loss)\n",
        "        time_elapsed = time.time() - time_start\n",
        "        val_step_history.append(it)\n",
        "\n",
        "        fn.update_validation_log(\n",
        "            log_path = \"validation_results.log\",\n",
        "            step = it,\n",
        "            val_loss = val_loss,\n",
        "            val_time = time_elapsed,\n",
        "            val_acc = val_acc,\n",
        "            last_char_val_acc = last_char_acc_val\n",
        "        )\n",
        "\n",
        "        fn.save_checkpoint(\n",
        "            checkpoint_path = checkpoint_file,\n",
        "            params = params,\n",
        "            constants = constants,\n",
        "            opt_state = opt_state,\n",
        "            step = it,\n",
        "            time_elapsed = time_elapsed\n",
        "        )\n",
        "\n",
        "        # Print training and validation metrics\n",
        "        print(f\"Iteration {it}, time elapsed: {time_elapsed:.2f} seconds\")\n",
        "        print(f\"\\t \\t Training Loss: {loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "        print(f\"\\t \\t Training Acc: {acc:.4f}, Validation Acc: {val_acc:.4f}\")\n",
        "        print(f\"\\t \\t Last Char Training Acc: {last_char_acc:.4f}, Last Char Validation Acc: {last_char_acc_val:.4f}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "print(f\"Training completed in {time.time() - time_start:.2f} seconds.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f22e0a4",
      "metadata": {
        "id": "1f22e0a4"
      },
      "source": [
        "## Plot the training and validation loss curves\n",
        "\n",
        "After training, we plot the training and validation loss curves to visualize the model's learning progress over time. This plot is saved to the specified output directory, and will be useful to identify if the model converges at first glance. Among all the ablation experiments for that category, we can also compare these curves to see how different configurations affect the learning dynamics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f4cd9351",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "f4cd9351",
        "outputId": "ca418b02-5ea1-4365-8ae5-2c74097c6e91"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAHHCAYAAAC2rPKaAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAe5ZJREFUeJzt3Xd0FNXfBvBnk5BGGiWkQOgtQOhFQIoSpUtAaSJNiiD1VRARpVkCggKCAjaaIk2KP3oHgUgP0kR6ABOQkoQAqft9/xh3kslukk3YZDfh+Zwzh507d2bu7G52H+7cmdWJiICIiIioALKzdgOIiIiIcguDDhERERVYDDpERERUYDHoEBERUYHFoENEREQFFoMOERERFVgMOkRERFRgMegQERFRgcWgQ0RERAUWgw7lqX79+qFs2bI5Wnfy5MnQ6XSWbZCNuXbtGnQ6HRYvXpzn+9bpdJg8ebI6v3jxYuh0Oly7di3LdcuWLYt+/fpZtD1P814helotW7ZEy5Ytrd0MsgAGHQKgfMmZM+3du9faTX3mjRw5EjqdDpcuXcqwzoQJE6DT6fDnn3/mYcuy759//sHkyZMRHh5u7aaoDGFz5syZ1m5KgVG2bFl06NBBnX/8+DEmT55s9c+Tc+fOYfLkyWaFecq/HKzdALINy5Yt08wvXboUO3bsMCoPDAx8qv1899130Ov1OVr3ww8/xPvvv/9U+y8IevXqhblz52L58uWYOHGiyTq//PILgoKCULNmzRzvp3fv3ujRowecnJxyvI2s/PPPP5gyZQrKli2L2rVra5Y9zXuFbNvjx48xZcoUALBqr8m5c+cwZcoUtGzZ0qj3cPv27dZpFFkcgw4BAN544w3N/B9//IEdO3YYlaf3+PFjuLq6mr2fQoUK5ah9AODg4AAHB75lGzVqhIoVK+KXX34xGXTCwsJw9epVTJs27an2Y29vD3t7+6faxtN4mvcK5a3k5GTo9Xo4OjpatR2PHj1C4cKFLbItax8LWQ5PXZHZWrZsiRo1auD48eNo3rw5XF1d8cEHHwAANmzYgPbt28Pf3x9OTk6oUKECPv74Y6SkpGi2kX7cRdrTBN9++y0qVKgAJycnNGjQAEePHtWsa2qMjk6nw/Dhw7F+/XrUqFEDTk5OqF69OrZu3WrU/r1796J+/fpwdnZGhQoVsHDhQrPH/fz+++/o2rUrSpcuDScnJwQEBOD//u//8OTJE6Pjc3Nzw61btxASEgI3Nzd4e3tjzJgxRs9FdHQ0+vXrB09PT3h5eaFv376Ijo7Osi2A0qvz119/4cSJE0bLli9fDp1Oh549eyIxMRETJ05EvXr14OnpicKFC6NZs2bYs2dPlvswNUZHRPDJJ5+gVKlScHV1xQsvvICzZ88arXv//n2MGTMGQUFBcHNzg4eHB9q2bYtTp06pdfbu3YsGDRoAAPr376+eHjWMTzI1RufRo0d49913ERAQACcnJ1SpUgUzZ86EiGjqZed9kVN37tzBgAED4OPjA2dnZ9SqVQtLliwxqrdixQrUq1cP7u7u8PDwQFBQEObMmaMuT0pKwpQpU1CpUiU4OzujWLFieP7557Fjx44s23DlyhV07doVRYsWhaurK5577jls2rRJXX779m04ODiovSdpXbhwATqdDvPmzVPLoqOjMXr0aPX5rVixIqZPn67pWUv7Nzt79mz1b/bcuXNmPW/Xrl2Dt7c3AGDKlCnq6552fNhff/2F1157DUWLFoWzszPq16+P3377TbMdw/tz3759ePvtt1GiRAmUKlUKAHD9+nW8/fbbqFKlClxcXFCsWDF07dpV815evHgxunbtCgB44YUXjE7PmxqjY85rnp3PtKioKPTv3x+lSpWCk5MT/Pz80KlTJ55KszD+95iy5d69e2jbti169OiBN954Az4+PgCUDw03Nze88847cHNzw+7duzFx4kTExsZixowZWW53+fLlePjwId566y3odDp8/vnn6NKlC65cuZLl/+wPHDiAtWvX4u2334a7uzu++uorvPrqq4iIiECxYsUAACdPnkSbNm3g5+eHKVOmICUlBVOnTlU/cLOyevVqPH78GEOHDkWxYsVw5MgRzJ07Fzdv3sTq1as1dVNSUtC6dWs0atQIM2fOxM6dO/HFF1+gQoUKGDp0KAAlMHTq1AkHDhzAkCFDEBgYiHXr1qFv375mtadXr16YMmUKli9fjrp162r2vWrVKjRr1gylS5fG3bt38f3336Nnz54YNGgQHj58iB9++AGtW7fGkSNHjE4XZWXixIn45JNP0K5dO7Rr1w4nTpzAyy+/jMTERE29K1euYP369ejatSvKlSuH27dvY+HChWjRogXOnTsHf39/BAYGYurUqZg4cSIGDx6MZs2aAQCaNGlict8igldeeQV79uzBgAEDULt2bWzbtg1jx47FrVu3MGvWLE19c94XOfXkyRO0bNkSly5dwvDhw1GuXDmsXr0a/fr1Q3R0NEaNGgUA2LFjB3r27IlWrVph+vTpAIDz58/j4MGDap3JkycjNDQUAwcORMOGDREbG4tjx47hxIkTeOmllzJsw+3bt9GkSRM8fvwYI0eORLFixbBkyRK88sorWLNmDTp37gwfHx+0aNECq1atwqRJkzTrr1y5Evb29uqX/ePHj9GiRQvcunULb731FkqXLo1Dhw5h/PjxiIyMxOzZszXrL1q0CPHx8Rg8eDCcnJxQtGhRs547b29vzJ8/H0OHDkXnzp3RpUsXAFBPs549exZNmzZFyZIl8f7776Nw4cJYtWoVQkJC8Ouvv6Jz586a7b399tvw9vbGxIkT8ejRIwDA0aNHcejQIfTo0QOlSpXCtWvXMH/+fLRs2RLnzp2Dq6srmjdvjpEjR+Krr77CBx98oJ6Wz+j0vLmvuYE5n2mvvvoqzp49ixEjRqBs2bK4c+cOduzYgYiICA7EtyQhMmHYsGGS/u3RokULASALFiwwqv/48WOjsrfeektcXV0lPj5eLevbt6+UKVNGnb969aoAkGLFisn9+/fV8g0bNggA+d///qeWTZo0yahNAMTR0VEuXbqklp06dUoAyNy5c9Wyjh07iqurq9y6dUstu3jxojg4OBht0xRTxxcaGio6nU6uX7+uOT4AMnXqVE3dOnXqSL169dT59evXCwD5/PPP1bLk5GRp1qyZAJBFixZl2aYGDRpIqVKlJCUlRS3bunWrAJCFCxeq20xISNCs9+DBA/Hx8ZE333xTUw5AJk2apM4vWrRIAMjVq1dFROTOnTvi6Ogo7du3F71er9b74IMPBID07dtXLYuPj9e0S0R5rZ2cnDTPzdGjRzM83vTvFcNz9sknn2jqvfbaa6LT6TTvAXPfF6YY3pMzZszIsM7s2bMFgPz0009qWWJiojRu3Fjc3NwkNjZWRERGjRolHh4ekpycnOG2atWqJe3bt8+0TaaMHj1aAMjvv/+ulj18+FDKlSsnZcuWVZ//hQsXCgA5ffq0Zv1q1arJiy++qM5//PHHUrhwYfn777819d5//32xt7eXiIgIEUl9fjw8POTOnTtmtbVMmTKaY/z333+N3m8GrVq1kqCgIM3nhl6vlyZNmkilSpXUMsP78/nnnzd6fk39vYaFhQkAWbp0qVq2evVqASB79uwxqt+iRQtp0aKFOm/ua27uZ9qDBw+yfJ+RZfDUFWWLk5MT+vfvb1Tu4uKiPn748CHu3r2LZs2a4fHjx/jrr7+y3G737t1RpEgRdd7wv/srV65kuW5wcDAqVKigztesWRMeHh7quikpKdi5cydCQkLg7++v1qtYsSLatm2b5fYB7fE9evQId+/eRZMmTSAiOHnypFH9IUOGaOabNWumOZbNmzfDwcFB7eEBlDExI0aMMKs9gDKu6ubNm9i/f79atnz5cjg6Oqr/S7e3t1fHGuj1ety/fx/JycmoX7++ydNemdm5cycSExMxYsQIzem+0aNHG9V1cnKCnZ3y8ZKSkoJ79+7Bzc0NVapUyfZ+DTZv3gx7e3uMHDlSU/7uu+9CRLBlyxZNeVbvi6exefNm+Pr6omfPnmpZoUKFMHLkSMTFxWHfvn0AAC8vLzx69CjT01BeXl44e/YsLl68mO02NGzYEM8//7xa5ubmhsGDB+PatWvqqaQuXbrAwcEBK1euVOudOXMG586dQ/fu3dWy1atXo1mzZihSpAju3r2rTsHBwUhJSdG8zwClN8LcHlFz3b9/H7t370a3bt3Uz5G7d+/i3r17aN26NS5evIhbt25p1hk0aJDRWLK0f69JSUm4d+8eKlasCC8vr6d6/5nzmhtk9Znm4uICR0dH7N27Fw8ePMhRm8g8DDqULSVLljQ5SO/s2bPo3LkzPD094eHhAW9vb3Ugc0xMTJbbLV26tGbe8AFhzgdA+nUN6xvWvXPnDp48eYKKFSsa1TNVZkpERAT69euHokWLquNuWrRoAcD4+JydnY2+ANK2B1DGEPj5+cHNzU1Tr0qVKma1BwB69OgBe3t7LF++HAAQHx+PdevWoW3btpoP2CVLlqBmzZrq+A9vb29s2rTJrNclrevXrwMAKlWqpCn39vbW7A9QQtWsWbNQqVIlODk5oXjx4vD29saff/6Z7f2m3b+/vz/c3d015YZTDYb2GWT1vnga169fR6VKldQwl1Fb3n77bVSuXBlt27ZFqVKl8OabbxqNE5o6dSqio6NRuXJlBAUFYezYsWbdFuD69esm3y/p21C8eHG0atUKq1atUuusXLkSDg4O6mkjALh48SK2bt0Kb29vzRQcHAxA+TtKq1y5clm2MbsuXboEEcFHH31k1A7DqTdz2vHkyRNMnDhRHWtkeP9FR0c/1fvPnNfcIKvPNCcnJ0yfPh1btmyBj48Pmjdvjs8//xxRUVE5ah9ljGN0KFvS/k/JIDo6Gi1atICHhwemTp2KChUqwNnZGSdOnMC4cePMukQ4o6t7JN0gU0uva46UlBS89NJLuH//PsaNG4eqVauicOHCuHXrFvr162d0fHl1pVKJEiXw0ksv4ddff8XXX3+N//3vf3j48CF69eql1vnpp5/Qr18/hISEYOzYsShRogTs7e0RGhqKy5cv51rbPvvsM3z00Ud488038fHHH6No0aKws7PD6NGj8+yS8dx+X5ijRIkSCA8Px7Zt27BlyxZs2bIFixYtQp8+fdRBrM2bN8fly5exYcMGbN++Hd9//z1mzZqFBQsWYODAgRZpR48ePdC/f3+Eh4ejdu3aWLVqFVq1aoXixYurdfR6PV566SW89957JrdRuXJlzbypz4KnZXhvjBkzBq1btzZZJ/1/Tky1Y8SIEVi0aBFGjx6Nxo0bw9PTEzqdDj169LCp99/o0aPRsWNHrF+/Htu2bcNHH32E0NBQ7N69G3Xq1MmTdj4LGHToqe3duxf37t3D2rVr0bx5c7X86tWrVmxVqhIlSsDZ2dnkDfYyu+mewenTp/H3339jyZIl6NOnj1puzlUxGSlTpgx27dqFuLg4Ta/OhQsXsrWdXr16YevWrdiyZQuWL18ODw8PdOzYUV2+Zs0alC9fHmvXrtWcbko/MNXcNgPK//zLly+vlv/7779GvSRr1qzBCy+8gB9++EFTHh0drflyzc6drsuUKYOdO3fi4cOHml4dw6lRQ/vyQpkyZfDnn39Cr9dr/odvqi2Ojo7o2LEjOnbsCL1ej7fffhsLFy7ERx99pH5pFy1aFP3790f//v0RFxeH5s2bY/LkyZkGnTJlyph8v5hqQ0hICN566y319NXff/+N8ePHa9arUKEC4uLi1B6c3JTR6254XxUqVOip2rFmzRr07dsXX3zxhVoWHx9vdFVjdt9/5r7m2VGhQgW8++67ePfdd3Hx4kXUrl0bX3zxBX766accbY+M8dQVPTXD/1zS/k8lMTER33zzjbWapGFvb4/g4GCsX78e//zzj1p+6dIlo3EdGa0PaI9PRDSXCGdXu3btkJycjPnz56tlKSkpmDt3bra2ExISAldXV3zzzTfYsmULunTpAmdn50zbfvjwYYSFhWW7zcHBwShUqBDmzp2r2V76q3EM+03fc7J69Wqj8RWGe56Yc1l9u3btkJKSorkcGgBmzZoFnU5n9ngrS2jXrh2ioqI0416Sk5Mxd+5cuLm5qac17927p1nPzs5OvbooISHBZB03NzdUrFhRXZ5ZG44cOaJ5LR89eoRvv/0WZcuWRbVq1dRyLy8vtG7dGqtWrcKKFSvg6OiIkJAQzfa6deuGsLAwbNu2zWhf0dHRSE5OzrQ92WG491b6171EiRJo2bIlFi5ciMjISKP1/v33X7O2b+r9N3fuXKNbPGT3/WfOa26ux48fIz4+XlNWoUIFuLu7Z/naU/awR4eeWpMmTVCkSBH07dtX/XmCZcuW5ekpgqxMnjwZ27dvR9OmTTF06FD1C7NGjRpZ/vxA1apVUaFCBYwZMwa3bt2Ch4cHfv3116ca69GxY0c0bdoU77//Pq5du4Zq1aph7dq12R4/4ObmhpCQEHWcTtrTVgDQoUMHrF27Fp07d0b79u1x9epVLFiwANWqVUNcXFy29mW4H1BoaCg6dOiAdu3a4eTJk9iyZYuml8aw36lTp6J///5o0qQJTp8+jZ9//lnTEwQoH+xeXl5YsGAB3N3dUbhwYTRq1MjkuIuOHTvihRdewIQJE3Dt2jXUqlUL27dvx4YNGzB69GjNwGNL2LVrl9EXEaCEy8GDB2PhwoXo168fjh8/jrJly2LNmjU4ePAgZs+erfY4DRw4EPfv38eLL76IUqVK4fr165g7dy5q166tju2oVq0aWrZsiXr16qFo0aI4duwY1qxZg+HDh2favvfffx+//PIL2rZti5EjR6Jo0aJYsmQJrl69il9//dVoLEn37t3xxhtv4JtvvkHr1q3h5eWlWT527Fj89ttv6NChA/r164d69erh0aNHOH36NNasWYNr164Zvc455eLigmrVqmHlypWoXLkyihYtiho1aqBGjRr4+uuv8fzzzyMoKAiDBg1C+fLlcfv2bYSFheHmzZuaezFlpEOHDli2bBk8PT1RrVo1hIWFYefOnUa3Fahduzbs7e0xffp0xMTEwMnJCS+++CJKlChhtE1zX3Nz/f3332jVqhW6deuGatWqwcHBAevWrcPt27fRo0ePbG2LsmCFK70oH8jo8vLq1aubrH/w4EF57rnnxMXFRfz9/eW9996Tbdu2GV26mdHl5aYusUS6y08zurx82LBhRuuWKVNGc7mziMiuXbukTp064ujoKBUqVJDvv/9e3n33XXF2ds7gWUh17tw5CQ4OFjc3NylevLgMGjRIvVw57aXRffv2lcKFCxutb6rt9+7dk969e4uHh4d4enpK79695eTJk2ZfXm6wadMmASB+fn5Gl3Tr9Xr57LPPpEyZMuLk5CR16tSRjRs3Gr0OIllfXi4ikpKSIlOmTBE/Pz9xcXGRli1bypkzZ4ye7/j4eHn33XfVek2bNpWwsDCjS3ZFlMtuq1Wrpl7qbzh2U218+PCh/N///Z/4+/tLoUKFpFKlSjJjxgzN5e6GYzH3fZGe4T2Z0bRs2TIREbl9+7b0799fihcvLo6OjhIUFGT0uq1Zs0ZefvllKVGihDg6Okrp0qXlrbfeksjISLXOJ598Ig0bNhQvLy9xcXGRqlWryqeffiqJiYmZtlNE5PLly/Laa6+Jl5eXODs7S8OGDWXjxo0m68bGxoqLi4vRJdJpPXz4UMaPHy8VK1YUR0dHKV68uDRp0kRmzpyptsecy+/TS395uYjIoUOHpF69euLo6Gj03rt8+bL06dNHfH19pVChQlKyZEnp0KGDrFmzRq1jeH8ePXrUaH8PHjxQXxs3Nzdp3bq1/PXXXyZf/++++07Kly8v9vb2ms8rU+9Vc15zcz/T7t69K8OGDZOqVatK4cKFxdPTUxo1aiSrVq3K/MmkbNOJ2NB/u4nyWEhISI4u7SUiovyBY3TomZH+5xouXryIzZs3W/VHBYmIKHexR4eeGX5+fujXrx/Kly+P69evY/78+UhISMDJkyeN7g1DREQFAwcj0zOjTZs2+OWXXxAVFQUnJyc0btwYn332GUMOEVEBxh4dIiIiKrA4RoeIiIgKLAYdIiIiKrCeuTE6er0e//zzD9zd3bN1+28iIiKyHhHBw4cP4e/vb3RDzMw8c0Hnn3/+QUBAgLWbQURERDlw48YNlCpVyuz6z1zQMdym+8aNG/Dw8LBya4iIiMgcsbGxCAgIyPbPbTxzQcdwusrDw4NBh4iIKJ/J7rATDkYmIiKiAotBh4iIiAosBh0iIiIqsJ65MTpERPT0UlJSkJSUZO1mUAHj6OiYrUvHzcGgQ0REZhMRREVFITo62tpNoQLIzs4O5cqVg6Ojo8W2yaBDRERmM4ScEiVKwNXVlTdeJYsx3NA3MjISpUuXtth7i0GHiIjMkpKSooacYsWKWbs5VAB5e3vjn3/+QXJyMgoVKmSRbdrMYORp06ZBp9Nh9OjRGdZZvHgxdDqdZnJ2ds67RhIRPcMMY3JcXV2t3BIqqAynrFJSUiy2TZvo0Tl69CgWLlyImjVrZlnXw8MDFy5cUOfZbUpElLf4uUu5JTfeW1bv0YmLi0OvXr3w3XffoUiRIlnW1+l08PX1VScfH588aCURERHlR1YPOsOGDUP79u0RHBxsVv24uDiUKVMGAQEB6NSpE86ePZtp/YSEBMTGxmomIiKip1G2bFnMnj3b7Pp79+6FTqfj1WpWYNWgs2LFCpw4cQKhoaFm1a9SpQp+/PFHbNiwAT/99BP0ej2aNGmCmzdvZrhOaGgoPD091Ym/XE5E9OxIP64z/TR58uQcbffo0aMYPHiw2fWbNGmCyMhIeHp65mh/5mKgMma1MTo3btzAqFGjsGPHDrMHFDdu3BiNGzdW55s0aYLAwEAsXLgQH3/8scl1xo8fj3feeUedN/z6aW548gRwdgZ4+pqIyDZERkaqj1euXImJEydqxnm6ubmpj0UEKSkpcHDI+qvR29s7W+1wdHSEr69vttYhy7Baj87x48dx584d1K1bFw4ODnBwcMC+ffvw1VdfwcHBwawR14UKFUKdOnVw6dKlDOs4OTmpv1Sem79Y/mDZRnzpOgGryo8DMulhIiKivJN2TKenp6dmnOdff/0Fd3d3bNmyBfXq1YOTkxMOHDiAy5cvo1OnTvDx8YGbmxsaNGiAnTt3arab/tSVTqfD999/j86dO8PV1RWVKlXCb7/9pi5P39OyePFieHl5Ydu2bQgMDISbmxvatGmjCWbJyckYOXIkvLy8UKxYMYwbNw59+/ZFSEhIjp+PBw8eoE+fPihSpAhcXV3Rtm1bXLx4UV1+/fp1dOzYEUWKFEHhwoVRvXp1bN68WV23V69e8Pb2houLCypVqoRFixbluC15xWpBp1WrVjh9+jTCw8PVqX79+ujVqxfCw8Nhb2+f5TZSUlJw+vRp+Pn55UGLM3f9u+2YgM/Q/drnQJo3KhFRQSUCPHpknUnEcsfx/vvvY9q0aTh//jxq1qyJuLg4tGvXDrt27cLJkyfRpk0bdOzYEREREZluZ8qUKejWrRv+/PNPtGvXDr169cL9+/czrP/48WPMnDkTy5Ytw/79+xEREYExY8aoy6dPn46ff/4ZixYtwsGDBxEbG4v169c/1bH269cPx44dw2+//YawsDCICNq1a6feOmDYsGFISEjA/v37cfr0aUyfPl3t9froo49w7tw5bNmyBefPn8f8+fNRvHjxp2pPnhAb0qJFCxk1apQ637t3b3n//ffV+SlTpsi2bdvk8uXLcvz4cenRo4c4OzvL2bNnzd5HTEyMAJCYmBhLNl2Ot/g/EeVvT+TQIYtum4jIFjx58kTOnTsnT548ERGRuLjUj728nuList/+RYsWiaenpzq/Z88eASDr16/Pct3q1avL3Llz1fkyZcrIrFmz1HkA8uGHH6rzcXFxAkC2bNmi2deDBw/UtgCQS5cuqet8/fXX4uPjo877+PjIjBkz1Pnk5GQpXbq0dOrUKcN2pt9PWn///bcAkIMHD6pld+/eFRcXF1m1apWIiAQFBcnkyZNNbrtjx47Sv3//DPdtCenfY2nl9Pvb6lddZSYiIkLTjffgwQMMGjQIgYGBaNeuHWJjY3Ho0CFUq1bNiq1U6O3TnNNNTrZeQ4iIKFvq16+vmY+Li8OYMWMQGBgILy8vuLm54fz581n26KS9F1zhwoXh4eGBO3fuZFjf1dUVFSpUUOf9/PzU+jExMbh9+zYaNmyoLre3t0e9evWydWxpnT9/Hg4ODmjUqJFaVqxYMVSpUgXnz58HAIwcORKffPIJmjZtikmTJuHPP/9U6w4dOhQrVqxA7dq18d577+HQoUM5bktesokbBhrs3bs30/lZs2Zh1qxZedegbBA7Bh0iera4ugJxcdbbt6UULlxYMz9mzBjs2LEDM2fORMWKFeHi4oLXXnsNiYmJmW4n/U8W6HQ66PX6bNUXS56Ty4GBAweidevW2LRpE7Zv347Q0FB88cUXGDFiBNq2bYvr169j8+bN2LFjB1q1aoVhw4Zh5syZVm1zVmy6Ryc/0TPoENEzRqcDChe2zpSbV7cePHgQ/fr1Q+fOnREUFARfX19cu3Yt93ZogqenJ3x8fHD06FG1LCUlBSdOnMjxNgMDA5GcnIzDhw+rZffu3cOFCxc0Z0YCAgIwZMgQrF27Fu+++y6+++47dZm3tzf69u2Ln376CbNnz8a3336b4/bkFZvq0cnPGHSIiAqGSpUqYe3atejYsSN0Oh0++uijTHtmcsuIESMQGhqKihUromrVqpg7dy4ePHhg1s8knD59Gu7u7uq8TqdDrVq10KlTJwwaNAgLFy6Eu7s73n//fZQsWRKdOnUCAIwePRpt27ZF5cqV8eDBA+zZsweBgYEAgIkTJ6JevXqoXr06EhISsHHjRnWZLWPQsRDhGB0iogLhyy+/xJtvvokmTZqgePHiGDdunFXuqj9u3DhERUWhT58+sLe3x+DBg9G6dWuzrkpu3ry5Zt7e3h7JyclYtGgRRo0ahQ4dOiAxMRHNmzfH5s2b1dNoKSkpGDZsGG7evAkPDw+0adNGHTLi6OiI8ePH49q1a3BxcUGzZs2wYsUKyx+4henE2icE81hsbCw8PT0RExNj0XvqHHjlczz/v3HKzNq1QOfOFts2EZEtiI+Px9WrV1GuXDmzb/RKlqPX6xEYGIhu3bpleJPc/C6z91hOv7/Zo2Mh7NEhIiJLun79OrZv344WLVogISEB8+bNw9WrV/H6669bu2n5CgcjWwjH6BARkSXZ2dlh8eLFaNCgAZo2bYrTp09j586d+WJcjC1hj46FMOgQEZElBQQE4ODBg9ZuRr7HHh0L4Q0DiYiIbA+DjoXwhoFERES2h0HHQnjqioiIyPYw6FgIgw4REZHtYdCxEF5eTkREZHsYdCyEQYeIiMj2MOhYCE9dEREVXC1btsTo0aPV+bJly2L27NmZrqPT6bB+/fqn3reltvOsYtCxEAYdIiLb07FjR7Rp08bkst9//x06nQ5//vlntrd79OhRDB48+GmbpzF58mTUrl3bqDwyMhJt27a16L7SW7x4Mby8vHJ1H9bCoGMhDDpERLZnwIAB2LFjB27evGm0bNGiRahfvz5q1qyZ7e16e3vD1dXVEk3Mkq+vL5ycnPJkXwURg46FcIwOEZHt6dChA7y9vbF48WJNeVxcHFavXo0BAwbg3r176NmzJ0qWLAlXV1cEBQXhl19+yXS76U9dXbx4Ec2bN4ezszOqVauGHTt2GK0zbtw4VK5cGa6urihfvjw++ugjJCUlAVB6VKZMmYJTp05Bp9NBp9OpbU5/6ur06dN48cUX4eLigmLFimHw4MGIi4tTl/fr1w8hISGYOXMm/Pz8UKxYMQwbNkzdV05ERESgU6dOcHNzg4eHB7p164bbt2+ry0+dOoUXXngB7u7u8PDwQL169XDs2DEAym92dezYEUWKFEHhwoVRvXp1bN68OcdtyS7+BISFsEeHiMj2ODg4oE+fPli8eDEmTJgAnU4HAFi9ejVSUlLQs2dPxMXFoV69ehg3bhw8PDywadMm9O7dGxUqVEDDhg2z3Ider0eXLl3g4+ODw4cPIyYmRjOex8Dd3R2LFy+Gv78/Tp8+jUGDBsHd3R3vvfceunfvjjNnzmDr1q3YuXMnAMDT09NoG48ePULr1q3RuHFjHD16FHfu3MHAgQMxfPhwTZjbs2cP/Pz8sGfPHly6dAndu3dH7dq1MWjQoGw/h3q9Xg05+/btQ3JyMoYNG4bu3btj7969AIBevXqhTp06mD9/Puzt7REeHo5ChQoBAIYNG4bExETs378fhQsXxrlz5+Dm5pbtduQUg46FsEeHiJ5J9esDUVF5v19fX+C/HoOsvPnmm5gxYwb27duHli1bAlBOW7366qvw9PSEp6cnxowZo9YfMWIEtm3bhlWrVpkVdHbu3Im//voL27Ztg7+/PwDgs88+MxpX8+GHH6qPy5YtizFjxmDFihV477334OLiAjc3Nzg4OMDX1zfDfS1fvhzx8fFYunQpChcuDACYN28eOnbsiOnTp8PHxwcAUKRIEcybNw/29vaoWrUq2rdvj127duUo6OzatQunT5/G1atXERAQAABYunQpqlevjqNHj6JBgwaIiIjA2LFjUbVqVQBApUqV1PUjIiLw6quvIigoCABQvnz5bLfhaTDoWAh7dIjomRQVBdy6Ze1WZKpq1apo0qQJfvzxR7Rs2RKXLl3C77//jqlTpwIAUlJS8Nlnn2HVqlW4desWEhMTkZCQYPYYnPPnzyMgIEANOQDQuHFjo3orV67EV199hcuXLyMuLg7Jycnw8PDI1rGcP38etWrVUkMOADRt2hR6vR4XLlxQg0716tVhb2+v1vHz88Pp06ezta+0+wwICFBDDgBUq1YNXl5eOH/+PBo0aIB33nkHAwcOxLJlyxAcHIyuXbuiQoUKAICRI0di6NCh2L59O4KDg/Hqq6/maFxUTnGMjoWwR4eInkm+vkDJknk/ZdLrYcqAAQPw66+/4uHDh1i0aBEqVKiAFi1aAABmzJiBOXPmYNy4cdizZw/Cw8PRunVrJCYmWuxpCgsLQ69evdCuXTts3LgRJ0+exIQJEyy6j7QMp40MdDod9Hp9ruwLUK4YO3v2LNq3b4/du3ejWrVqWLduHQBg4MCBuHLlCnr37o3Tp0+jfv36mDt3bq61JT326FgIe3SI6Jlk5ukja+vWrRtGjRqF5cuXY+nSpRg6dKg6XufgwYPo1KkT3njjDQDKmJS///4b1apVM2vbgYGBuHHjBiIjI+Hn5wcA+OOPPzR1Dh06hDJlymDChAlq2fXr1zV1HB0dkZKSkuW+Fi9ejEePHqm9OgcPHoSdnR2qVKliVnuzy3B8N27cUHt1zp07h+joaM1zVLlyZVSuXBn/93//h549e2LRokXo3LkzACAgIABDhgzBkCFDMH78eHz33XcYMWJErrQ3PfboWAiDDhGR7XJzc0P37t0xfvx4REZGol+/fuqySpUqYceOHTh06BDOnz+Pt956S3NFUVaCg4NRuXJl9O3bF6dOncLvv/+uCTSGfURERGDFihW4fPkyvvrqK7XHw6Bs2bK4evUqwsPDcffuXSQkJBjtq1evXnB2dkbfvn1x5swZ7NmzByNGjEDv3r3V01Y5lZKSgvDwcM10/vx5BAcHIygoCL169cKJEydw5MgR9OnTBy1atED9+vXx5MkTDB8+HHv37sX169dx8OBBHD16FIGBgQCA0aNHY9u2bbh69SpOnDiBPXv2qMvyAoOOhfDUFRGRbRswYAAePHiA1q1ba8bTfPjhh6hbty5at26Nli1bwtfXFyEhIWZv187ODuvWrcOTJ0/QsGFDDBw4EJ9++qmmziuvvIL/+7//w/Dhw1G7dm0cOnQIH330kabOq6++ijZt2uCFF16At7e3yUvcXV1dsW3bNty/fx8NGjTAa6+9hlatWmHevHnZezJMiIuLQ506dTRTx44dodPpsGHDBhQpUgTNmzdHcHAwypcvj5UrVwIA7O3tce/ePfTp0weVK1dGt27d0LZtW0yZMgWAEqCGDRuGwMBAtGnTBpUrV8Y333zz1O01l05EJM/2ZgNiY2Ph6emJmJiYbA8Cy8zSyVfQZ4oy8Aqvvw78/LPFtk1EZAvi4+Nx9epVlCtXDs7OztZuDhVAmb3Hcvr9zR4dC2GPDhERke1h0LEQjtEhIiKyPQw6FsIeHSIiItvDoGMh7NEhIiKyPQw6FsKgQ0TPimfsGhbKQ7nx3mLQsRCeuiKigs5wt93Hjx9buSVUUBnuFJ325yueFu+MbCHs0SGigs7e3h5eXl64c+cOAOWeLoa7CxM9Lb1ej3///Reurq5wcLBcPGHQsRD26BDRs8Dwy9qGsENkSXZ2dihdurRFAzSDjqXY2UEPHewgDDpEVGDpdDr4+fmhRIkSSEpKsnZzqIBxdHSEnZ1lR9Uw6FhQMhzgiCQGHSIq8Ozt7S06joIot9jMYORp06ZBp9Nh9OjRmdZbvXo1qlatCmdnZwQFBWHz5s1500AzJBtyI4MOERGRTbCJoHP06FEsXLgQNWvWzLTeoUOH0LNnTwwYMAAnT55ESEgIQkJCcObMmTxqaeYYdIiIiGyL1YNOXFwcevXqhe+++w5FihTJtO6cOXPQpk0bjB07FoGBgfj4449Rt25di/xqqyWoQYfnrYmIiGyC1YPOsGHD0L59ewQHB2dZNywszKhe69atERYWluE6CQkJiI2N1Uy5hT06REREtsWqg5FXrFiBEydO4OjRo2bVj4qKgo+Pj6bMx8cHUVFRGa4TGhqKKVOmPFU7zaHTMegQERHZGqv16Ny4cQOjRo3Czz//DGdn51zbz/jx4xETE6NON27cyLV9MegQERHZFqv16Bw/fhx37txB3bp11bKUlBTs378f8+bNQ0JCgtGli76+vrh9+7am7Pbt2+oNrExxcnKCk5OTZRufgSQot0dn0CEiIrINVuvRadWqFU6fPo3w8HB1ql+/Pnr16oXw8HCT92do3Lgxdu3apSnbsWMHGjdunFfNzhR7dIiIiGyL1Xp03N3dUaNGDU1Z4cKFUaxYMbW8T58+KFmyJEJDQwEAo0aNQosWLfDFF1+gffv2WLFiBY4dO4Zvv/02z9tvCoMOERGRbbH6VVeZiYiIQGRkpDrfpEkTLF++HN9++y1q1aqFNWvWYP369UaByVoYdIiIiGyLTkTE2o3IS7GxsfD09ERMTAw8PDwstt3584GGb9dDPZwAChUC/vupeSIiInp6Of3+tukenfyEl5cTERHZHgYdC1KDjgig11u3MURERMSgY0nJacd2s1eHiIjI6hh0LIhBh4iIyLYw6FgQgw4REZFtYdCxIAYdIiIi28KgY0EMOkRERLaFQcdCNJeXAww6RERENoBBx4IYdIiIiGwLg44FMegQERHZFgYdC2LQISIisi0MOhbEoENERGRbGHQsiEGHiIjItjDoWBCDDhERkW1h0LEgBh0iIiLbwqBjIbyPDhERke1h0LEgBh0iIiLbwqBjQQw6REREtoVBx4IYdIiIiGwLg44FMegQERHZFgYdC2LQISIisi0MOhbEoENERGRbGHQshJeXExER2R4GHQtxcmLQISIisjUMOhZSpw6DDhERka1h0LEgBh0iIiLbwqBjQQw6REREtoVBx4IYdIiIiGwLg44FMegQERHZFgYdC+Hl5URERLaHQceCGHSIiIhsC4OOBTHoEBER2RYGHQti0CEiIrItDDoWxKBDRERkWxh0LIhBh4iIyLYw6FgQgw4REZFtsWrQmT9/PmrWrAkPDw94eHigcePG2LJlS4b1Fy9eDJ1Op5mcnZ3zsMUZ4+XlREREtsch6yq5p1SpUpg2bRoqVaoEEcGSJUvQqVMnnDx5EtWrVze5joeHBy5cuKDO63S6vGpulhh0iIiIbItVg07Hjh01859++inmz5+PP/74I8Ogo9Pp4OvrmxfNyzYGHSIiIttiM2N0UlJSsGLFCjx69AiNGzfOsF5cXBzKlCmDgIAAdOrUCWfPns10uwkJCYiNjdVMuYVBh4iIyLZYPeicPn0abm5ucHJywpAhQ7Bu3TpUq1bNZN0qVargxx9/xIYNG/DTTz9Br9ejSZMmuHnzZobbDw0NhaenpzoFBATk1qEgCYVSZxh0iIiIrE4nImLNBiQmJiIiIgIxMTFYs2YNvv/+e+zbty/DsJNWUlISAgMD0bNnT3z88ccm6yQkJCAhIUGdj42NRUBAAGJiYuDh4WGx4zh7FuhU4xIuoZJS0Ls3sHSpxbZPRET0LIuNjYWnp2e2v7+tOkYHABwdHVGxYkUAQL169XD06FHMmTMHCxcuzHLdQoUKoU6dOrh06VKGdZycnODk5GSx9mZGc+oqKSlP9klEREQZs/qpq/T0er2mByYzKSkpOH36NPz8/HK5VVnj5eVERES2x6o9OuPHj0fbtm1RunRpPHz4EMuXL8fevXuxbds2AECfPn1QsmRJhIaGAgCmTp2K5557DhUrVkR0dDRmzJiB69evY+DAgdY8DBWDDhERkW2xatC5c+cO+vTpg8jISHh6eqJmzZrYtm0bXnrpJQBAREQE7OxSO50ePHiAQYMGISoqCkWKFEG9evVw6NAhs8bz5AUGHSIiItti9cHIeS2ng5mycu4c0KR6NKJRRClo0wbI5C7PREREZL6cfn/b3Bid/Iw9OkRERLaFQceCGHSIiIhsC4OOBTHoEBER2RYGHQvR6YAU2KcWMOgQERFZHYOORemQbAg7DDpERERWx6BjYerpKwYdIiIiq2PQsTAGHSIiItvBoGNhKToGHSIiIlvBoGNh7NEhIiKyHQw6FsagQ0REZDsYdCxEp1P+TWHQISIishkMOhaWzDE6RERENoNBx8J46oqIiMh2MOhYGIMOERGR7WDQsTCO0SEiIrIdDDoWxjE6REREtoNBx8J46oqIiMh2MOhYmObUlYh1G0NERPSMY9CxEMN9dNQeHQDQ663TGCIiIgLAoGNxmqDD01dERERWxaBjYepgZIBBh4iIyMoYdCyMPTpERES2g0HHwlIYdIiIiGwGg46FsUeHiIjIdjDoWBjH6BAREdkOBh0LMVxezlNXREREtoNBx8KSGHSIiIhsBoOOhbFHh4iIyHYw6FgYByMTERHZDgYdC+NgZCIiItvBoGNh7NEhIiKyHQw6FsYxOkRERLaDQcdCTP56OYMOERGRVTHoWBiDDhERke1g0LEwBh0iIiLbYdWgM3/+fNSsWRMeHh7w8PBA48aNsWXLlkzXWb16NapWrQpnZ2cEBQVh8+bNedRa8zDoEBER2Q6rBp1SpUph2rRpOH78OI4dO4YXX3wRnTp1wtmzZ03WP3ToEHr27IkBAwbg5MmTCAkJQUhICM6cOZPHLc8YLy8nIiKyHVYNOh07dkS7du1QqVIlVK5cGZ9++inc3Nzwxx9/mKw/Z84ctGnTBmPHjkVgYCA+/vhj1K1bF/PmzcvjlmeMV10RERHZDpsZo5OSkoIVK1bg0aNHaNy4sck6YWFhCA4O1pS1bt0aYWFhGW43ISEBsbGxmik3JaFQ6gyDDhERkVVZPeicPn0abm5ucHJywpAhQ7Bu3TpUq1bNZN2oqCj4+Phoynx8fBAVFZXh9kNDQ+Hp6alOAQEBFm2/AS8vJyIisj1WDzpVqlRBeHg4Dh8+jKFDh6Jv3744d+6cxbY/fvx4xMTEqNONGzcstm1TGHSIiIhsh0PWVXKXo6MjKlasCACoV68ejh49ijlz5mDhwoVGdX19fXH79m1N2e3bt+Hr65vh9p2cnODk5GTZRmeCQYeIiMh2WL1HJz29Xo+EhASTyxo3boxdu3Zpynbs2JHhmB5rYNAhIiKyHVbt0Rk/fjzatm2L0qVL4+HDh1i+fDn27t2Lbdu2AQD69OmDkiVLIjQ0FAAwatQotGjRAl988QXat2+PFStW4NixY/j222+teRgaKby8nIiIyGZYNejcuXMHffr0QWRkJDw9PVGzZk1s27YNL730EgAgIiICdnapnU5NmjTB8uXL8eGHH+KDDz5ApUqVsH79etSoUcNah2CEPTpERES2w6pB54cffsh0+d69e43Kunbtiq5du+ZSi54egw4REZHtsLkxOvmVycvLk5Ks0xgiIiICwKBjcezRISIish0MOhbGoENERGQ7GHQsjEGHiIjIdjDoWBiDDhERke1g0LGwZN5Hh4iIyGYw6FhYCnt0iIiIbAaDjoXw18uJiIhsD4OOhSUJgw4REZGtYNCxMPboEBER2Q4GHQvjj3oSERHZDgYdC2OPDhERke1g0LEwBh0iIiLbkaOgc+PGDdy8eVOdP3LkCEaPHo1vv/3WYg3Lrxh0iIiIbEeOgs7rr7+OPXv2AACioqLw0ksv4ciRI5gwYQKmTp1q0QbmF4bLy3nVFRERke3IUdA5c+YMGjZsCABYtWoVatSogUOHDuHnn3/G4sWLLdm+fIeDkYmIiGxHjoJOUlISnJycAAA7d+7EK6+8AgCoWrUqIiMjLde6fIinroiIiGxHjoJO9erVsWDBAvz+++/YsWMH2rRpAwD4559/UKxYMYs2ML9h0CEiIrIdOQo606dPx8KFC9GyZUv07NkTtWrVAgD89ttv6imtZxWDDhERke1wyLqKsZYtW+Lu3buIjY1FkSJF1PLBgwfD1dXVYo3Ljxh0iIiIbEeOenSePHmChIQENeRcv34ds2fPxoULF1CiRAmLNjC/YdAhIiKyHTkKOp06dcLSpUsBANHR0WjUqBG++OILhISEYP78+RZtYH5huLw8RdI8pQw6REREVpWjoHPixAk0a9YMALBmzRr4+Pjg+vXrWLp0Kb766iuLNjDf0ekAh/96dRh0iIiIrCpHQefx48dwd3cHAGzfvh1dunSBnZ0dnnvuOVy/ft2iDcyXGHSIiIhsQo6CTsWKFbF+/XrcuHED27Ztw8svvwwAuHPnDjw8PCzawHyJQYeIiMgm5CjoTJw4EWPGjEHZsmXRsGFDNG7cGIDSu1OnTh2LNjBfYtAhIiKyCTm6vPy1117D888/j8jISPUeOgDQqlUrdO7c2WKNy7cYdIiIiGxCjoIOAPj6+sLX11f9FfNSpUo98zcLVDHoEBER2YQcnbrS6/WYOnUqPD09UaZMGZQpUwZeXl74+OOPodfrLd3GfEUEDDpEREQ2Ikc9OhMmTMAPP/yAadOmoWnTpgCAAwcOYPLkyYiPj8enn35q0UbmB4b76ABg0CEiIrIROQo6S5Yswffff6/+ajkA1KxZEyVLlsTbb7/9TAYdDQYdIiIim5CjU1f3799H1apVjcqrVq2K+/fvP3Wj8j0GHSIiIpuQo6BTq1YtzJs3z6h83rx5qFmz5lM3Kt9j0CEiIrIJOTp19fnnn6N9+/bYuXOneg+dsLAw3LhxA5s3b7ZoA/MlBh0iIiKbkKMenRYtWuDvv/9G586dER0djejoaHTp0gVnz57FsmXLLN3G/IdBh4iIyCboREQstbFTp06hbt26SElJsdQmLS42Nhaenp6IiYmx6M9VXL8OlC0LODkB8XUaA3/8oSzQ69NdkkVERETZldPv7xz16FhKaGgoGjRoAHd3d5QoUQIhISG4cOFCpussXrwYOp1OMzk7O+dRizNm8vJyALDh0EdERFTQWTXo7Nu3D8OGDcMff/yBHTt2ICkpCS+//DIePXqU6XoeHh6IjIxUJ5v7xfRChVIf8/QVERGR1eT4JyAsYevWrZr5xYsXo0SJEjh+/DiaN2+e4Xo6nQ6+vr653bycS9ujw6BDRERkNdkKOl26dMl0eXR09NO0BTExMQCAokWLZlovLi4OZcqUgV6vR926dfHZZ5+hevXqJusmJCQgISFBnY+NjX2qNmYlIQEMOkRERDYiW0HH09Mzy+V9+vTJUUP0ej1Gjx6Npk2bokaNGhnWq1KlCn788UfUrFkTMTExmDlzJpo0aYKzZ8+iVKlSRvVDQ0MxZcqUHLUpO6Ki0sww6BAREdkEi1519TSGDh2KLVu24MCBAyYDS0aSkpIQGBiInj174uOPPzZabqpHJyAgwOJXXa1cCfTooTyWzl2AdeuUmchIwJZPsxEREeUDOb3qyqpjdAyGDx+OjRs3Yv/+/dkKOQBQqFAh1KlTB5cuXTK53MnJCU5OTpZoZqYqVkwzwx4dIiIim2DVq65EBMOHD8e6deuwe/dulCtXLtvbSElJwenTp+Hn55cLLTSfv3+aGQYdIiIim2DVHp1hw4Zh+fLl2LBhA9zd3RH130AXT09PuLi4AAD69OmDkiVLIjQ0FAAwdepUPPfcc6hYsSKio6MxY8YMXL9+HQMHDrTacQCA3X+RUacDgw4REZGNsGrQmT9/PgCgZcuWmvJFixahX79+AICIiAjY2aV2PD148ACDBg1CVFQUihQpgnr16uHQoUOoVq1aXjXbJMMNA0XAoENERGQjrBp0zBkHvXfvXs38rFmzMGvWrFxqUc6lyWIQeweoN0pm0CEiIrIaq47RKUjS/gSEsEeHiIjIJjDoWEjaHh3YM+gQERHZAgYdC9H06DDoEBER2QQGnVyQoksTdJKSrNcQIiKiZxyDjoWk7biJecQeHSIiIlvAoGMhaccfp9gx6BAREdkCBh0L0QQdMOgQERHZAgYdC7G3T32sGaPDoENERGQ1DDoWkjbPPHzCoENERGQLGHQs5L+f5gIAFHJl0CEiIrIFDDoWkvaGgRyjQ0REZBsYdCwk7Q0Dkxl0iIiIbAKDjoUw6BAREdkeBp1cwKBDRERkGxh0cgGDDhERkW1g0MkFDDpERES2gUEnFzDoEBER2QYGnVyQJAw6REREtoBBJxckMugQERHZBAadXJDMoENERGQTGHRyAU9dERER2QYGnVzAoENERGQbGHRyAYMOERGRbWDQyQWJegYdIiIiW8CgkwsYdIiIiGwDg04u4KkrIiIi28CgkwsSUhh0iIiIbAGDTi5gjw4REZFtYNDJBezRISIisg0MOrmAg5GJiIhsA4NOLjh4mEGHiIjIFjDo5IIrNxh0iIiIbAGDTi5IBoMOERGRLWDQyQUMOkRERLaBQScXMOgQERHZBqsGndDQUDRo0ADu7u4oUaIEQkJCcOHChSzXW716NapWrQpnZ2cEBQVh8+bNedBa8yWhUOoMgw4REZHVWDXo7Nu3D8OGDcMff/yBHTt2ICkpCS+//DIePXqU4TqHDh1Cz549MWDAAJw8eRIhISEICQnBmTNn8rDlmWOPDhERkW3QiYhYuxEG//77L0qUKIF9+/ahefPmJut0794djx49wsaNG9Wy5557DrVr18aCBQuy3EdsbCw8PT0RExMDDw8Pi7UdAHS6//6FHnrYKzNNmgAHD1p0P0RERM+anH5/29QYnZiYGABA0aJFM6wTFhaG4OBgTVnr1q0RFhaWq23LDoEdYPffU8seHSIiIqtxyLpK3tDr9Rg9ejSaNm2KGjVqZFgvKioKPj4+mjIfHx9ERUWZrJ+QkICEhAR1PjY21jINzoqDA5CYyKBDRERkRTbTozNs2DCcOXMGK1assOh2Q0ND4enpqU4BAQEW3X6GHP7LkAw6REREVmMTQWf48OHYuHEj9uzZg1KlSmVa19fXF7dv39aU3b59G76+vibrjx8/HjExMep048YNi7U7Uww6REREVmfVoCMiGD58ONatW4fdu3ejXLlyWa7TuHFj7Nq1S1O2Y8cONG7c2GR9JycneHh4aKY8waBDRERkdVYdozNs2DAsX74cGzZsgLu7uzrOxtPTEy4uLgCAPn36oGTJkggNDQUAjBo1Ci1atMAXX3yB9u3bY8WKFTh27Bi+/fZbqx2HSQw6REREVmfVHp358+cjJiYGLVu2hJ+fnzqtXLlSrRMREYHIyEh1vkmTJli+fDm+/fZb1KpVC2vWrMH69eszHcBsFQw6REREVmdT99HJC3lxHx0AkNJlgIgIwN8fuHXLovshIiJ61hSI++gUKOzRISIisjoGndzCoENERGR1DDq5hUGHiIjI6hh0cguDDhERkdUx6OQWBh0iIiKrY9DJLQw6REREVsegk1sMQUevVyYiIiLKcww6ucUhzU2nU1Ks1w4iIqJnGINObkkbdJKSrNcOIiKiZxiDTm5JG3Q4ToeIiMgqGHRyC4MOERGR1THo5BYGHSIiIqtj0MktDDpERERWx6CTWxh0iIiIrI5BJ7cw6BAREVkdg05uYdAhIiKyOgad3MKgQ0REZHUMOrmFQYeIiMjqGHRyC4MOERGR1THo5BYGHSIiIqtj0MktDDpERERWx6CTWxh0iIiIrI5BJ7cw6BAREVkdg05uYdAhIiKyOgadXJKgZ9AhIiKyNgadXHL0BIMOERGRtTHoWNCECamPd+xh0CEiIrI2Bh0LcnZOfRz7hEGHiIjI2hh0LMjePvVxMhh0iIiIrI1Bx4Ls0jybDDpERETWx6CTSxh0iIiIrI9Bx4ICA1MfM+gQERFZH4OOBQUFpT5m0CEiIrI+Bh0L0ulSHyehUOoMgw4REZFVMOhYEAcjExER2RYGHQtK26PDoENERGR9Vg06+/fvR8eOHeHv7w+dTof169dnWn/v3r3Q6XRGU1RUVN40OAve3qmPGXSIiIisz6pB59GjR6hVqxa+/vrrbK134cIFREZGqlOJEiVyqYXZwxsGEhER2RaHrKvknrZt26Jt27bZXq9EiRLw8vKyfIOeEk9dERER2ZZ8OUandu3a8PPzw0svvYSDBw9mWjchIQGxsbGaKS8w6BAREVlfvgo6fn5+WLBgAX799Vf8+uuvCAgIQMuWLXHixIkM1wkNDYWnp6c6BQQE5Fr7eOqKiIjItlj11FV2ValSBVWqVFHnmzRpgsuXL2PWrFlYtmyZyXXGjx+Pd955R52PjY3NtbDDU1dERES2JV8FHVMaNmyIAwcOZLjcyckJTk5OedgiRdqgc/50MgIzqUtERES5I1+dujIlPDwcfn5+1m6GkbRBZ8/OZLRrB4hYsUFERETPIKv26MTFxeHSpUvq/NWrVxEeHo6iRYuidOnSGD9+PG7duoWlS5cCAGbPno1y5cqhevXqiI+Px/fff4/du3dj+/bt1jqEDKUNOg5IxpYtwIYNwN69wKefAoULW69tREREzwqrBp1jx47hhRdeUOcNY2n69u2LxYsXIzIyEhEREeryxMREvPvuu7h16xZcXV1Rs2ZN7Ny5U7MNW5E+6ABA587KvLMzMG2aNVpFRET0bNGJPFsnVGJjY+Hp6YmYmBh4eHhYfPuGAckVcAmXUAkAsBS90RdL1TpdugC//mrxXRMRERVYOf3+zvdjdGyVqR4dg+ho5d+uXYHgYI7dISIiyi35/qorW5VZ0Nm9G9DrgTVrlPm//wbSXDVPREREFsIenVySWdBJT6/P7dYQERE9mxh0LOy995R/sxN0rl3Tzp85A2Rys2ciIiIyE4OOhRkuAEsbdIrivlG9NFfVY/r01McpKUBQEFCvXupYHiIiIsoZBh0La9NG+TcGnriGMgCA53EQdaDtokk7JmffPuDGDaBTJ+C331LLb9/O7dYSEREVbAw6uUaHz/GeOjcRUzOtXbq0EnK6dEkti4wEEhOB+PjcaiMREVHBxqCTi37AANxESQBACDagNk5ma/0XXgCcnIAiRYCkJGD0aGDs2FxoKBERUQHFoJOLEuGEaXhfnc+qVycj8fHAkSPAnDnAzJnA48eWaiEREVHBxqCTy77HQNyCPwCgM9ajJk7laDtHjmjnz54FkpOBf/552hYSEREVXAw6uaBs2dTHCXDGdIxT53Paq/Pfz4ABUH4QtEYNoFAhoGRJ7e9mbd0KrFiRo10QEREVOAw6uSAoSDv/HQYhEr4AgFexFkH406L7Gz9euUJr7FigbVugZ0/lKi4iIqJnHYNOLpg/XzsfDxdNr850jENNnIITLHc5la+vMn7HYMECoGVL4LXXgB07gCdPLLYrIiKifIO/Xp5LJk8GpkxJnXfGE1xBefghSi1LgR2uoDzCURufYgJOoXautadNG2DLFmD7dqBUKaBatVzbFRERkcXx18ttTOvW2vl4uGAqJmrK7KFHJVxCV6zBITRBZ6x9qn3qkPGPZm3dqtyBuXVroHr1p9oNERFRvsGgk0saNzYuW4AhaIWdeB+hWIreOIZ6eARXAIArnmAtXsU4TAOQ/U627zEAj+GKd/BFhnXeT73SHR98oPTwEBERFWQ8dZWr+wI8PTOv44gEfI+B6I2f1LJF6Ie3sBBJcDRrP82wH/vRQp3vilVYg65mt3POHGDkSEBEuWy9UiXlRoUZefxYGYfUsSNQubLZuyEiIsqxnH5/M+jkMp3OnFqCD/AZPsWHakkkfPEvvPEIhREHN/wLb3yKCTgH4/NOW9EarbFdnX8MFzTFQYSjTo7a3KIFsHdvxsvfew+YMeO/lj9T7x4iIrIWBh0z5XXQuXsX8PY2r+5rWI2l6AOXDK7GuoQKqIk/8eS/010AUB9HcRQNAQB66GD332mvCASgAY7iDnxy3PbwcKBWLeXxhQvKL6p7eSnh7eZNpfzGDcDDQ5n+/Re4ehVo2DDHuyQiIjKJg5FtVPHiwA8/mFd3DbqiBfbhAJriXxTHY7hollfEZUzGZE3ZBHyqPh6N2QjDcwCA0riBtegCRyTkuO21ayuXpxcrBlStCjx6BNy6lRpyACAgQDk99+GHys0LGzUC9u9PXX77NvDggfG2Y2KAt97KvOeIiIjoabFHJw8kJQGO5g23MWKHFNTAGRxBQzghESmwQyMcxnHURw2cxmnUBADcRElUwGUUxX0cRQOUwi0AwA94EwPxPQCzzqFZREiIct8eDw9g9WqlbNkyZRzQ6tVAq1bK47lzlWVZvQMvXgSOHQN69DD3VCARERU07NGxYYUK5XxdPezxJ2qpl6bbQ48fMAAOSMIH+EytNwNjkQgnRMEPIViPJ3AGAAzAj1iIt2CP5Kc6huxYvx7Yti015ABA795Kz05wsDJ/5UrqsocPlX/j4pR/r17V9gpVrgy8/jqwcmXW+9ZnfIU9ERE9gxh08onP8R5O/dd7Uwt/YgGGoBtWAQDuwBvfYZBa9zjqoz8WQf9fL85gfIdf8SqcYRu3R96wAdi0KXXew0O5v4+7u9JjU768MiC6fXulN8fgwAFg40blt8Ref10pu3pVuVIMAO7dU7ZRtSqQkqLdpwiwe7cyjign+IvxRET5lDxjYmJiBIDExMTk6X7//FNkwwbl8aefiihfvdmb6uKYJMPOaME4hJqs3w0rJAGF1ILf0VSK4J4AIu6IkZexVSbgY+mGFTlqT3Ymf9yUbXhJfkMHcUOsRbb5yy+pj+/eFfnoI+3ywYOV5/vdd0Xs/nvaPD1FfvxR5JtvtK/P5csiT55oy+LiRMaPF2neXFl3376new+EhYl88IHI48eZ14uMNG4LEdGzLqff3ww6VpLTL/fpGKspuA8vcUdMhvVfxE6Jgbta8DcqynHUMQpMnfFrroUcOyTLPjRTCz7AJxbfx+HD2V/n9m2RwEARJ6fUsn//FdHrlddo3Dht/eeeS10mIvLXXyK//y6SkJD5a/3ttyJz56ZuZ+pU4zqGt+OFC6n10ktJyXgfN26ILFsmkpiYeVvS2rBBpEwZkT59lKBoC86eFdm+XVsWG6sE06go67SJiGwDg46ZbCXotGqVsy90FzySv1FRLZiMiVmuUxsnJBI+mVa6iApSCAm5EnQ+whRNQQRKiT2Sci1YWWISEXFxMb2sShUlEKUt279f+YL+5x+RLl2UsvbtRc6cyXj7BiNHKmV9+mjrTJggsmOHEq6mThVxcxM5elTkp59EoqOVf48dU7bh/l+W/fRT895/CQnafb32mlJ+544SgJKTs/+evnZNZN48kZMntYEwOwztOX1amT95MrUsMDDr9R88SH1ODJKTU4NkfvDVVyJVq4rcvGm8LCZGZPp0pQeS6FnDoGMmWwk6ixfn/Eu4If6QKJSQo6gnnnhg1jrlcFkNSCnQSThqyjy8LYfRQK00ErOz3I47YmQyJspBNJbP8L5UwflM6zfBAZOn20KwNtdCSkP8IUdQX46inpTEjRxt4733cjdIGcKQJaZu3VIfN2umfZ/duyeyerVIfLwSmgw9P61bG29HRKR0aeXxa69l3oNkiqtr6rZmzxZJSkpd9ssvInv3autHRors2qWEopUrRTp2TF1/1SqlTvo2vv125m0oXlypl7ZXqHBhpSwy0vxjefRI6Yn755+ch7acMhxr797Gy/r3V5a5ueVNW65cMS/06vVKQL50Keu60dEiS5Yo/1qaXq+EdSqYGHTMZCtBJyFBpEMHkS++yOkXnD7b67jgkTTGQfHCfbWsDo6rFe6iqGZZ2skR8TISs+UOihstDEMjGYJv1PE/hskL9+UaSqsFW5D67bodwRYPD3ZIlgn4WJJgrxauxysW34+tT0OHisyZI9KgQfbWSxs0AKV3yNNTpG9f5fSRQXKyyJo1IjNmiIwZo/SiXLpkvL2iRZVws3p1aplerwSoGzeybs+TJ6bLK1QQWb9e+/d06ZI2nBoCUbt2qWXff68EvylTsv5CrlIldT1fX5Ft20zXM4SgtKHuaRn227Wr8bJy5VKXm+PePZHXX09tf1yc0uZ790TCw5WyU6dM93gtXZpxO9LbvNm4Xb16ifTrp62XlCTy0ktKvfbts97uw4fZC9zDhinbNgRlWxIfLzJpksgffxgvS0mx7HuooGLQMZOtBJ20/Pys+8W4BL3VmRl4N91yvbyOn+QKyma5oUQ4yBa0lkFYKN64LavwmrpsH5qJAxI1p90q4y+LHUMZXJX9eN7kwo7YYNXnt6BMEyYoYaJ9e215QIB12lOzpoiHh+ne0RIlRL77TqQazsg+NJPZGClff5Ws6UnT60W2bFEeHzyo9CoBIiNGmN6fiMjo0crjkyeVLy7DMp3OuMfq4kXtabTYWKUX49tvtc/Zli3KqaqNG5V6hvJXX9VuLzJS256YGGWg/cGDqXXWrlUG2xsMGpRa3xBGO3YUKfTfNQozZ6Yub9RI297AwNRl7dqZHscVH6/0oHzwgfZ5unVL204R5cs8/XslM4Yw/PzzxstWr1bC1fr1qafxUlJSt1u4sBLU4uMz30dW9u9XeklPncreerduGZeFhqa27+FDZTJo0EDE3z/r8X7pnTmj/D0eO6b0Ph44YP66er3yPk47ru/QIeV5z46PPhL5+OPsrZNTDDpmssWgc+6c8uZ/5RWR4cO1HwRp/weXW1MArstjOIsAEg9HKYfLAoiUxRXZAePBRD+jp9THERmNL+UkapncaAp06uN7KCIBuC6AyP8htQtrNkZm2TZ7JEk1nJHK+Ev8cVM8EC32SJISiJIXsVNGYrZ8i4ESDQ91pWTYyVqEqPNXUUZc8MjM5yP7PWWWnHRIkXK4LB3wm7yHafI1hspwfCWlcc2q7cqPkyPi5QyqqQV9seiptpe2d8jU5O+f+jethCC9zMQ7cs+jrHzecJVZ+1i7Vjt/65bypX7likjt2hmvt2CBdn7ECG1PGqCEMXPa8MUXSugytWz3buULUq/Xjj/r1Sv1sYjI9eup89HRymTqgoHNm5Uv27QePFDC0Zdfptbr00d5Tu/dE6lWzXg7IkroSV8+cGBqeHvyRGnDvHnKwPYRI5RTtDNmKF/2I0aINGmi1DH01KV9bSMilF74nTuVsNqjh+krKKf8NySxf39t+euvG7fP0ItjmA8L0/ZgxcaaHqtlYPhPctrXdv9+0wP39XrlAgrD9g0ht0sXZT7teDhzpQ3fjx6Zv15OMeiYyRaDTlrx8cr/rEaNUt54ad/0PXrk3pfCpxivzqxEVxmOryQOrppKW/Gy1MYJo3VrIlxm4h25ijImN572ii4v3JdHUEb5RsNDCuOh6S8N3JSJmCw3UDJbB3IFZaUJDgig14S0T/BBpqvqkCJT8aHcQxFZhL7igehce65NTZ54ICvRVX1uTE0nUFsmY6JUw5k8bVt+ndIPgr8FP3FFnBnr6mUqPpTDaCDNsC9H+/7gA5G22KQWJKDQf+9L6z8vuT2JKLdiMMx/8432ykZT08KFxmUzZpi/z86dM/98bNYs8/XnzNHOr1yp9Aias++1a5VjTkhQvuzTPxe3b4usWKG0Mf26y5YpASR9+fbtIkFBqfNNmyoBUJKTlYZ99JHIP/9k2q4PPxSpVEnk88+Viyf69VPKK1QwPraUFG1YFkk9zXzlijKW7s4dJXgNG5Z6q43Ll1PXee2/Dvz793Pv+5FBx0y2HnQy8+CBSPfuyviDd96x7IeTO2LkNrxNLryOAGmDzWZsRy91cUw+wQdyHsogB1MB43u8qc4MwkLN+sHYLmsRohlnY86UDDv5Ef00AaUy/lLvI5SAQhkOnLZHkixCX03hJZSX+jhi0ec4o8kTD+QI6pu9Qgp06Z633Jj0UhPhUhfHRIeUPHkeLDlVxTmJh6PRgkmYlOW6PbBcnbmHIjnqTXNAovo3YJiiUELt2czuVBR3pQN+Eyc8sfpz+6xPhfFQuuMXGYqv5W3Mk+H4SkZgjoxDqMzAu7IIfeV/aC970EL64UeL7ff1ZhGyBy3Ugmh4yEjMttgVrGmD2PDhyinDzOovWCDyv/8Zlw8alHvfgQw6ZsrPQSe9+/ct+wc8BN8YFX6NoZnepyfjSZ/hH2DaAdDhqCmAXlpji4ShkVHlZNjJRrSTxegja9BFtuJlOYjGsh3B8iVGy5v4XhrijwxvQvgxJqgzO/GipD815YzHsh6vmDyIRDjIO5hp5hd9zk55eeG+JuTch5f8is7yMSZIT/wszbBPJuBjzdVxAkgS7OUlbDPanhti5Uf0k2OoK+vxiszBCPk/fCEhWCvOeJxpWxyQKC9ip3yF4XIdqYMpjqOOtMRui77XspoCcVaG4ytpjIMZ1nHBI3kT30tz7NWU65CiGa+1HD0kEQ4igDyCS6ZX4pVAlPyLYprCMDTK9q0XRiC1iyDtadwTqG1mr5L2uTBcBHAcdYwG/XPKu6k8LhkF2MymFOhy3CuYduqKlXIfXiYXhqNmlr2FOqRIKUSII+Lz7Lk6etTy33kMOmYqSEFHRDmXvWCByIABSq/mwYMiL76ovNHc3LL3xnRAopxAbREo99VpgT259kdwCM+pM6cQZFThJvxlEibl+PJww+SCR5qB1NPwnryEbRKA6+KJB7IXzdVl8XCUIfhG0zaBcoVYbywRf9zUfHA0xe/yFYbLTfjLbXjLKMzK1hdi+pBzG96Znpbyx035BkPUgmh4SCDOapZnNGZKALmMcuKHWyYXd8avRl/w6acN6Jjl7QRyPumlFk7KVHwo51BVXZAMO+mNJUb1PRAtB9FYLViPV6Qsrggg8hbmq+UXUUGc8VhmYZRathh9MmzHarxqcsGXGG32sRTFXbmHImrBS9gmF1FBnV+F18TcYFwBF+UWtFcrZB52sh+4XRGXrZ6iwngoLbBHuuMX8UFkLr0frDP54Za8g5n/hRPtc/kcDpm86jSr6SrK5PhUeBlcNeptvo4AWYo3jCofQBOZh7dlEBZKQ/whtXFCRmGWrEWI3EVREUD+RTH5DO+b3bPogEQpirs5fj4t/33HoGOWghZ0MvP4cfbfmJ54IC9iZ5b/+3/a6Q0sNbngT9SQrlgpDki02L7aw0T/KrT/046Fm7yAXeofdyjGmVznHKrKT3hdbsLf5PKLqCCvYrUYf+HoxQPRUgEX5Tkcko7YoAk5UShh1tgbOyTLOnRSCy6jnHjjtgThlFnjmU6gtlHvVwf8pvZ4GKYEFJLNaKMGX8OUBHs5iVpyBPXlEJ6T/Xhe1uMVGYE5Uh6XMt29PZKkAi5KW2ySEZgjszBK1uMVOYUgzd27TU2DsUCdLYq7chT1jOo8hrN8hvc1A9MNr2kR3NOEj3o4arSb17BKnbmD4tIaWzSnv8y999McpF62tQh9BVB6ZdIe4zy8La2xRariXIYD5QNwXXN7hrTTMdRNE3b08hK2yS68IEmwl1i4yTWUlhOoLTvQSj7FeJP329IhRcbgc3kMZ7mD4upzZapeF6yRBRgs4aipuS9WHFxlEiZlONYur6ZgbJeNaCdfY6i8gaVSEX9LdkNfBVzU/A0dQX3pgeXigETpgjXqBRsCyFkESh8sll5YJq/jJ+mJn6UzfpXnsV+q4pyUQJTmP1FL0NusNuiQIvVxRKbiQ5P/AfwF3dXXshHC5Djq5OgJS4adrMarJgNd2uc0AqVEoISoofhaiuFfTVsDcVb64UcZiq+lFCKMtmFp+TLo7Nu3Tzp06CB+fn4CQNatW5flOnv27JE6deqIo6OjVKhQQRYtWpStfT5LQUdEZM+enP+2Vm5OTniiGRN0GtXlNazKtfEgP6NnhgvvoLjJL76XsM3of9OmJlNjQQ7hOVmC3rILL8gFVMp0kLG5IccwuSJO8wEXjpqaL9FLKC+BOCslcUOa4nfphWWaXq2teFkNki9glzxB6kjRzWgjXbFSPV1ph2Tpi0UZBrv003lUkS8xWiZhkszFMFmBbrITL8pfqGwUpjKaUqCTfWhm1LsyCrOkBKLkT9TQvHYZvUY/oL+maBRmqTN70VzSfsAXxx3N+9Hw+29vY55a9gCe6hWJGU1VcU4dXxYHV00PWjts1ITrtNM/8JWV6CoD8J2UxjXxxT+aWzH8iRrSBAc0dzg/hrrSEz+bDH2m3mO9sEw9Zn/cNLqiMh6O0hUrNasWw7+yEVlcbvZf+wfi26ceL+KBaBmCbyQU42QSJsk4hMpIzJbeWJLhzVEb4LAmhBimf1FMjqC+nEKQ/I2KEoFSch0B8gX+zyiYlccl9Us9/XQLfprXbSdeNOtGraVxTRO6M/pNQR1SpAkOyCyMyvA/KzFwlzewVNKHEjskyzDMlUson2lj7qKo7EELzW8fGqbf0VSCsV3dtgseacJ62ikRDrIJbWUnXjT6z0ky7OR/aC8dsUF9H1havgw6mzdvlgkTJsjatWvFnKBz5coVcXV1lXfeeUfOnTsnc+fOFXt7e9m6davZ+3zWgo7BpUvKZZYpKcodcvftU+bv3Mn5h9LTTs9jv/yIftINK3J9wKsOKdIIYdIfP8h0jJUN6Ch/obIcwnOZno4phARphn0yBR/JQTRWv8QSUEg2oKP0wjJxR4zUwXHZhRey3bDshhzD5I+bJsNHGBqJN24b1a+C85oejR/RTxohTB6isFr2E17P8HVwRZx8hClyC37yBE7ZHiye2ZSAQvI3KspGtJMh+CbN6RC90W+7RaGE+vgW/CQQZ8UdMTID72qCVBRKGJ3eKYQEuYBKasFGtJNJmCSd8ausQeoNdn5FZ0n9QtHLCqTeevom/GU1XpVP8IG8gaXSBAekJsKlEi5IKUTIZrRR607Ax0aHm/b2CplNaYPxX6isPidVcD7Tn3O5htJyFoESCR+TwXI3WspgLFBPZaSfUqCTEZgjgEgz7DP64k2GnZxELZmPt2QBBhvt4z685G9UlGOoK7vRUlbjVemNJVme0g3AdZmJdzLt2YtAKaO/lZK4If/AN9vvuSsoK62wQwDlNhppx6SdRWCGPSWL0Ddbp6dfx0+a58ZwKr4wHkobbM403AiUv+fx+NSsU/heuC/NsVdGYI58jzflZ/SU4fhKgnBK/bv2QaRMxGST76GDaCz98YPm1HH6vzlzp5vwlyn4KPs35clCvgw6aZkTdN577z2pXr26pqx79+7SunVrs/fzrAadzJw/L1K5snJ54LffZvs9/UxN7oiRBjicwf/o9NIOG+UsAjULouEhZ1BNdqCV/IyeMhsjZQI+lgH47qnOf9fBcc0tANagS6anHJ/Hfk3vTdr/3a3HKzk4XagXByRKDfwp4xAq+/G8yZ/7ECi9GydRS1bhNfkEH0hfLJLnsV9K4obYITnTfUzEZKMF11BaKuCipjgQZ+U3dJALqJThaZhXsD7Tg7qLokbjTtwRowlI5kzXUDrD16ImwmUQFson+EB+wuvyO5rKA3ia3M5VlDE6JVAV54y+qI6jjryGVemeS72UwVVNiEs/3UBJeQnbNFdCCpSevbSv5W14SxesMeoJqYQLmW7fMP0DX/kAn6inPhyQKNVxWl7HT/IzepodnO/DS57HfgGMezb3orm0wg75AJ/Ib+ggd1BcUqCTR3CReygiN+Gvef8LlMCf9rYYZ1Dtv/8o6KUldsv/kHp3zI8wRbI/Bkovy5F63Xs4asoBNMmwdzMBhWQj2slAfCu+yPzy8aeZCiFBemGZ0WdV2ukxnGU4vhIdUiQIp2Q6xmpC2U34y6/oLO9hmkzEZE1YVKf//c+i31XPRNBp1qyZjBo1SlP2448/ioeHh9n7YdDJ2u+/K+/R9HfATTtldV+KZ3myR5LUwkmpinM5vGLN/KkF9sgOtJJxCDWrV6wrVhoV7sSLFrts2Qv3pQN+k7bYJPVxRMriyn9jgp7uRoxjMV2duYgKT3EDRb3Mxkije0QZptfxk8n1quC87EVzk13/pqaMTlNk9p5phDD5EFNlP56XRDjIBVTKcNxTVZyT3Wgpm9BWXsbWLJ/fttgkl6G9++gadEkTtJV7B5laeRdeyPJLtwkOyCa0lcsoJ3dRNMPg8hjOcgpBGT6PT+AkCzBYXsI2aY0t0gnrpAeWa8azPYGTvIrVmoB1CeU140fSvt5p5yvgouYS7bTTWQRKCUQZLSqNa/+N+cn534TJEPDflIBC8j+0lz5YbPZvF1pqskOydMMKzY01BZCjqGeyp9sOyVIdp032MNkhWdpik3p7kAiUsvjvWjwTQadSpUry2Wefaco2bdokAOSxqVtUikh8fLzExMSo040bN3L0RD1r7t5Vbhg1Y4byy9lhYalvaJ1OqZPRbxFxsu3pHaTe9/8QnrP6QFJzpzbYLB9iqslTc9mddEiRCrgonfGrTMIkWY4e//2obeaBwR5JUhF/S3v8T97BTJmNkbIQg2Qp3pBVeE1+QwcZg8+z3E5WkwMSs+jpyv7kgkcyCZPkdzT97/4uxm0ciq/V8SjJsJOPMCWH7dCLMx5LU/wuq/Fqhj19hukOisskTMrwtS2Mh5rTgmmn9FcfmvPav4X5mtNk51A1V68ga4ndmvB3DlXlawyV17Aqw98XzMtJhxR5DatkPV6RcQh96otB/HBLmmGfxb+XGHQyCDqTJk0SAEYTg072Gd7ERYqkliUlKb+xsnOn6Tf8vHkikyeLfP21df+QOaWd9NIHi2UyJub5HaA52f70InbKNxgiTfG7xbZZFlfkC/yfRMNDkmAvZ1BNlqOHjEOotMUms36ixQGJRpdaJ8NOWmNLjtpUChHqWJbcPE1kmGrhpHTGrxne4qEgTpb2TASdnJy6Yo+O5Xz4X8/2Tz+ZXn7lisjVq6m/gp22nl6v/PbLZ5+JtG0r0qaN8kN5af8oBg/O+g9nQur9/6RuXev/IXPixMn8SYeUbN98UTvp5ROk/oKoYeA0J9ucLO2ZCDrvvfee1KhRQ1PWs2dPDkbOQ+b8joler/wmijmOHFF+1+vBg9SyvXtT/1D691f+/fhj5XfAHj8WmThR5Phxpa7hF47T/mGl/2NL/+OGnDhxyt9TbZyQBjhs9XZwynyytHwZdB4+fCgnT56UkydPCgD58ssv5eTJk3L9+nUREXn//feld+/ean3D5eVjx46V8+fPy9dff83LywuoiAjlF5BFsh7PduuWSFxc6vzx4yLFiyu/9nz/vnZ80TvvKL/s+/77qWUNG4pMn276D3XePOXXfdOXL1pk/Q8RTpw4cbLlydLyZdDZs2ePmBo/07dvXxER6du3r7Ro0cJondq1a4ujo6OUL1+eNwwks8ydK5I2D9+9q1xSP2VKapnhj/PCBeWXiNPasMH4j/evv5SxSZs3W+ZDYfZs638wceLEiZOlJkvL6fe3TkQEz5DY2Fh4enoiJiYGHh4e1m4O2ZCkJCA5GXBxMV6m1wNvvQXUr6/8m9bWrUDbtsrjN94Ali9X6gNK/WPHlMdDhwJz5wLx8UDhwsCtW0C1akBsLODvr8xHRwNOTkBKCuDoCJw9C3h6AoMGAbt3Z30MIoC9fer+80rFisClS3m7TyKybZZOFzn9/razbDOI8q9ChUyHHACwswO++8445KS3bJkSUk6dAmJigKNHU5eVLauEkMKFlfmSJZU6KSlKyAEALy+lDW5uStCpUwcoXx7YuVOp9+OPwLp1qdtMTAQePQICA5UwBABxccCoUal17t5Vgk9MDHD+vBKmRo4EihfP+jlp0cK47Ngx4ORJbdn+/Vlvy1znzwO7dgGDB1tum0T07GKPDtFTiogAypRRHpv6a9q0Cdi4EZg9W+mteVoiQHAwULQosHp1aplOp633++/AkyfAyy9nvK3ERCXgPXgAtGkDdOgAhIcDrVop4ahPH+XYDCGpWDHA2zt1/YcPAXd35XH9+sDx40CNGsCZM6l1XF2Bx48zP6bnn1eep/R/kgkJgLNz5utu2wa0bq083rwZqFVLCZGBgUqb04qPV3rJ6tXLfJvpde0KdOum/GuwaRPwv/8BVasCo0crZQsWAEOGGK//3XdK/fXrs7dfovzMVnp0cuEsmm3jGB3KDUePily+bO1W5I74eOXmkFl58EAZy5SQIPLwociQIcrPily+LHLggEidOiJLlqSev9+yReTevcy3mZhofN7/7beVK/sOHlT2IyKyeLHIBx8o5WkNGCDi7y/i4qIdo3XypMicOSKbNin3hQKU2yG8/LLIunXKgPVffhH5+2/tNsPDlTFc6d2+LRIdrTwOCxNpl+Z3MENCUusdPy7SqZPIqlXK/qZPV8Zm9egh0ry5SGho6nqLF4t88omIt7fxc1C9uukxEceOiYwcqS2Lisp6LEVwsMgLLyj3xNq61fpjOzgVjMnS8uVgZGtg0CGyrosXtbcTyMr//ieyZo3yw7Q5vaN8SkrGy9KHI0s5f15k927LbGv3bu0XSGKiyMqVSjg5cCC1PD5eudLQ/b+b/v7wg7L+c8+l1jl/XuTff0W+/17k2jWRQ4eMn4OsvsDWrlWCbEyM8twayr/5RglbsbFKqEu7jqenSLFi2rKgoKz3tW2bdn7/fpE33lCC86pVStvffTd1+YoV2mPo0EE5xoy2b2jTwYPa7Ri+qEeNMl7n9m2RXbuUe3kdPaoERMNr5JPxb66qU6X/fjotMlIkIN2vQ5Qrl/X6TzMtXixy9mzuh5zu3S3z3k+LQcdMDDpElB8dOKD05KQPT2l/isUQ6BITteElNlYJDImJ5u1rzx6Rpk2Vnh7Dtl95JeP/qRvK0/d2FUrzk1Z37ihtevxYubfVnj3KvGH5O++krvfwoUiTJkqPl4jy+3u1a4usX2+6vXFxys1EDffXStsmw/Ol1ytf8NHRSnD28VF6u9I7eFBZLzRUmU9KSi0DMm5DWuvWKT13hnVq1TIOUAYpKSJDh4pMmiTy55/KfwTSBsqSJZXjj4lRnsNLl5SexrTHCIj06qX8B+LgQeV1XrRIpHNnbZ3hw1P3e/Nm5kElPl7pnfz3X+U58/MzrjN/vnKD2K+/VrZnuFksILJjR9bPU3Yx6JiJQYeICpq7d1NPnVmS4Qd+/f2V03aAiJubcb3x40UGDTIuP3xYCUyHD2e8j0WLRFq1Mu9mpNlh+MI9dMiy29uwwfx1nn9eWeebb7RhJyt//ZX1aV0RkTffVH58+dGjjOsYwsc33xgvi41NbdP27amPM+vlPHw4tZ6p/cbFiZw5k3Xbc4KXl5uJg5GJiMx39ixQurQy6PyvvwA/P+WWB7bus8+AixeVKxXTD9TPCcM2rl5VrqA0x5MnwOnTQIMGQLNmwMGDSnlefusmJSmvW40app+H+/eViyQKF1au0HR1VabMfPedchFDv3650uQM5fT7m0GHiIgoCxERwL17yi0fcuLCBaBjR+CDD/I+IBQUOf3+dsjFNhERERUIpUsrU05VqQL8/bfl2kPm4w0DiYiIqMBi0CEiIqICi0GHiIiICiwGHSIiIiqwGHSIiIiowGLQISIiogKLQYeIiIgKLAYdIiIiKrAYdIiIiKjAYtAhIiKiAotBh4iIiAosBh0iIiIqsBh0iIiIqMBi0CEiIqICy8HaDchrIgIAiI2NtXJLiIiIyFyG723D97i5nrmg8/DhQwBAQECAlVtCRERE2fXw4UN4enqaXV8n2Y1G+Zxer8c///wDd3d36HQ6i247NjYWAQEBuHHjBjw8PCy6bVtQ0I8PKPjHyOPL/wr6MfL48r/cOkYRwcOHD+Hv7w87O/NH3jxzPTp2dnYoVapUru7Dw8OjwL6BgYJ/fEDBP0YeX/5X0I+Rx5f/5cYxZqcnx4CDkYmIiKjAYtAhIiKiAotBx4KcnJwwadIkODk5WbspuaKgHx9Q8I+Rx5f/FfRj5PHlf7Z2jM/cYGQiIiJ6drBHh4iIiAosBh0iIiIqsBh0iIiIqMBi0CEiIqICi0HHQr7++muULVsWzs7OaNSoEY4cOWLtJiE0NBQNGjSAu7s7SpQogZCQEFy4cEFTp2XLltDpdJppyJAhmjoRERFo3749XF1dUaJECYwdOxbJycmaOnv37kXdunXh5OSEihUrYvHixUbtyY3naPLkyUbtr1q1qro8Pj4ew4YNQ7FixeDm5oZXX30Vt2/fzjfHV7ZsWaPj0+l0GDZsGID8+frt378fHTt2hL+/P3Q6HdavX69ZLiKYOHEi/Pz84OLiguDgYFy8eFFT5/79++jVqxc8PDzg5eWFAQMGIC4uTlPnzz//RLNmzeDs7IyAgAB8/vnnRm1ZvXo1qlatCmdnZwQFBWHz5s3Zbkt2ji8pKQnjxo1DUFAQChcuDH9/f/Tp0wf//POPZhumXvdp06bZ/PEBQL9+/Yza3qZNG00dW379zDlGU3+TOp0OM2bMUOvY6mtozveCLX1umtOWLAk9tRUrVoijo6P8+OOPcvbsWRk0aJB4eXnJ7du3rdqu1q1by6JFi+TMmTMSHh4u7dq1k9KlS0tcXJxap0WLFjJo0CCJjIxUp5iYGHV5cnKy1KhRQ4KDg+XkyZOyefNmKV68uIwfP16tc+XKFXF1dZV33nlHzp07J3PnzhV7e3vZunWrWie3nqNJkyZJ9erVNe3/999/1eVDhgyRgIAA2bVrlxw7dkyee+45adKkSb45vjt37miObceOHQJA9uzZIyL58/XbvHmzTJgwQdauXSsAZN26dZrl06ZNE09PT1m/fr2cOnVKXnnlFSlXrpw8efJErdOmTRupVauW/PHHH/L7779LxYoVpWfPnurymJgY8fHxkV69esmZM2fkl19+ERcXF1m4cKFa5+DBg2Jvby+ff/65nDt3Tj788EMpVKiQnD59Olttyc7xRUdHS3BwsKxcuVL++usvCQsLk4YNG0q9evU02yhTpoxMnTpV87qm/bu11eMTEenbt6+0adNG0/b79+9r6tjy62fOMaY9tsjISPnxxx9Fp9PJ5cuX1Tq2+hqa871gS5+bWbXFHAw6FtCwYUMZNmyYOp+SkiL+/v4SGhpqxVYZu3PnjgCQffv2qWUtWrSQUaNGZbjO5s2bxc7OTqKiotSy+fPni4eHhyQkJIiIyHvvvSfVq1fXrNe9e3dp3bq1Op9bz9GkSZOkVq1aJpdFR0dLoUKFZPXq1WrZ+fPnBYCEhYXli+NLb9SoUVKhQgXR6/Uikv9fv/RfInq9Xnx9fWXGjBlqWXR0tDg5Ockvv/wiIiLnzp0TAHL06FG1zpYtW0Sn08mtW7dEROSbb76RIkWKqMcoIjJu3DipUqWKOt+tWzdp3769pj2NGjWSt956y+y2ZPf4TDly5IgAkOvXr6tlZcqUkVmzZmW4ji0fX9++faVTp04ZrpOfXr+MjjG9Tp06yYsvvqgpyy+vYfrvBVv63DSnLebgqaunlJiYiOPHjyM4OFgts7OzQ3BwMMLCwqzYMmMxMTEAgKJFi2rKf/75ZxQvXhw1atTA+PHj8fjxY3VZWFgYgoKC4OPjo5a1bt0asbGxOHv2rFon7fEb6hiOP7efo4sXL8Lf3x/ly5dHr169EBERAQA4fvw4kpKSNPutWrUqSpcure43PxyfQWJiIn766Se8+eabmh+kze+vX1pXr15FVFSUZl+enp5o1KiR5jXz8vJC/fr11TrBwcGws7PD4cOH1TrNmzeHo6Oj5pguXLiABw8emHXc5rTFEmJiYqDT6eDl5aUpnzZtGooVK4Y6depgxowZmtMCtn58e/fuRYkSJVClShUMHToU9+7d07S9IL1+t2/fxqZNmzBgwACjZfnhNUz/vWBLn5vmtMUcz9yPelra3bt3kZKSonnBAcDHxwd//fWXlVplTK/XY/To0WjatClq1Kihlr/++usoU6YM/P398eeff2LcuHG4cOEC1q5dCwCIiooyeWyGZZnViY2NxZMnT/DgwYNce44aNWqExYsXo0qVKoiMjMSUKVPQrFkznDlzBlFRUXB0dDT6AvHx8cmy7bZyfGmtX78e0dHR6Nevn1qW31+/9AxtMrWvtO0tUaKEZrmDgwOKFi2qqVOuXDmjbRiWFSlSJMPjTruNrNrytOLj4zFu3Dj07NlT8+OHI0eORN26dVG0aFEcOnQI48ePR2RkJL788kubP742bdqgS5cuKFeuHC5fvowPPvgAbdu2RVhYGOzt7QvU6wcAS5Ysgbu7O7p06aIpzw+voanvBVv63DSnLeZg0HlGDBs2DGfOnMGBAwc05YMHD1YfBwUFwc/PD61atcLly5dRoUKFvG5mtrVt21Z9XLNmTTRq1AhlypTBqlWr4OLiYsWWWd4PP/yAtm3bwt/fXy3L76/fsywpKQndunWDiGD+/PmaZe+88476uGbNmnB0dMRbb72F0NBQm7mtfkZ69OihPg4KCkLNmjVRoUIF7N27F61atbJiy3LHjz/+iF69esHZ2VlTnh9ew4y+Fwoanrp6SsWLF4e9vb3RKPDbt2/D19fXSq3SGj58ODZu3Ig9e/agVKlSmdZt1KgRAODSpUsAAF9fX5PHZliWWR0PDw+4uLjk6XPk5eWFypUr49KlS/D19UViYiKio6Mz3G9+Ob7r169j586dGDhwYKb18vvrZ9heZvvy9fXFnTt3NMuTk5Nx//59i7yuaZdn1ZacMoSc69evY8eOHZreHFMaNWqE5ORkXLt2LdO2p223NY8vrfLly6N48eKa92R+f/0Mfv/9d1y4cCHLv0vA9l7DjL4XbOlz05y2mINB5yk5OjqiXr162LVrl1qm1+uxa9cuNG7c2IotUy47HD58ONatW4fdu3cbdZOaEh4eDgDw8/MDADRu3BinT5/WfDAZPpirVaum1kl7/IY6huPPy+coLi4Oly9fhp+fH+rVq4dChQpp9nvhwgVERESo+80vx7do0SKUKFEC7du3z7Refn/9ypUrB19fX82+YmNjcfjwYc1rFh0djePHj6t1du/eDb1erwa9xo0bY//+/UhKStIcU5UqVVCkSBGzjtuctuSEIeRcvHgRO3fuRLFixbJcJzw8HHZ2duopH1s+vvRu3ryJe/fuad6T+fn1S+uHH35AvXr1UKtWrSzr2sprmNX3gi19bprTFrOYPWyZMrRixQpxcnKSxYsXy7lz52Tw4MHi5eWlGZFuDUOHDhVPT0/Zu3ev5hLHx48fi4jIpUuXZOrUqXLs2DG5evWqbNiwQcqXLy/NmzdXt2G4jPDll1+W8PBw2bp1q3h7e5u8jHDs2LFy/vx5+frrr01eRpgbz9G7774re/fulatXr8rBgwclODhYihcvLnfu3BER5dLE0qVLy+7du+XYsWPSuHFjady4cb45PhHlSoTSpUvLuHHjNOX59fV7+PChnDx5Uk6ePCkA5Msvv5STJ0+qVx1NmzZNvLy8ZMOGDfLnn39Kp06dTF5eXqdOHTl8+LAcOHBAKlWqpLk8OTo6Wnx8fKR3795y5swZWbFihbi6uhpduuvg4CAzZ86U8+fPy6RJk0xeuptVW7JzfImJifLKK69IqVKlJDw8XPN3abha5dChQzJr1iwJDw+Xy5cvy08//STe3t7Sp08fmz++hw8fypgxYyQsLEyuXr0qO3fulLp160qlSpUkPj4+X7x+WR2jQUxMjLi6usr8+fON1rfl1zCr7wUR2/rczKot5mDQsZC5c+dK6dKlxdHRURo2bCh//PGHtZskAExOixYtEhGRiIgIad68uRQtWlScnJykYsWKMnbsWM19WERErl27Jm3bthUXFxcpXry4vPvuu5KUlKSps2fPHqldu7Y4OjpK+fLl1X2klRvPUffu3cXPz08cHR2lZMmS0r17d7l06ZK6/MmTJ/L2229LkSJFxNXVVTp37iyRkZH55vhERLZt2yYA5MKFC5ry/Pr67dmzx+T7sm/fviKiXDL70UcfiY+Pjzg5OUmrVq2Mjv3evXvSs2dPcXNzEw8PD+nfv788fPhQU+fUqVPy/PPPi5OTk5QsWVKmTZtm1JZVq1ZJ5cqVxdHRUapXry6bNm3SLDenLdk5vqtXr2b4d2m4N9Lx48elUaNG4unpKc7OzhIYGCifffaZJijY6vE9fvxYXn75ZfH29pZChQpJmTJlZNCgQUaB2JZfv6yO0WDhwoXi4uIi0dHRRuvb8muY1feCiG19bprTlqzo/jtwIiIiogKHY3SIiIiowGLQISIiogKLQYeIiIgKLAYdIiIiKrAYdIiIiKjAYtAhIiKiAotBh4iIiAosBh0ieuaULVsWs2fPtnYziCgPMOgQUa7q168fQkJCAAAtW7bE6NGj82zfixcvhpeXl1H50aNHNb/8TkQFl4O1G0BElF2JiYlwdHTM8fre3t4WbA0R2TL26BBRnujXrx/27duHOXPmQKfTQafT4dq1awCAM2fOoG3btnBzc4OPjw969+6Nu3fvquu2bNkSw4cPx+jRo1G8eHG0bt0aAPDll18iKCgIhQsXRkBAAN5++23ExcUBAPbu3Yv+/fsjJiZG3d/kyZMBGJ+6ioiIQKdOneDm5gYPDw9069YNt2/fVpdPnjwZtWvXxrJly1C2bFl4enqiR48eePjwYe4+aUT01Bh0iChPzJkzB40bN8agQYMQGRmJyMhIBAQEIDo6Gi+++CLq1KmDY8eOYevWrbh9+za6deumWX/JkiVwdHTEwYMHsWDBAgCAnZ0dvvrqK5w9exZLlizB7t278d577wEAmjRpgtmzZ8PDw0Pd35gxY4zapdfr0alTJ9y/fx/79u3Djh07cOXKFXTv3l1T7/Lly1i/fj02btyIjRs3Yt++fZg2bVouPVtEZCk8dUVEecLT0xOOjo5wdXWFr6+vWj5v3jzUqVMHn332mVr2448/IiAgAH///TcqV64MAKhUqRI+//xzzTbTjvcpW7YsPvnkEwwZMgTffPMNHB0d4enpCZ1Op9lfert27cLp06dx9epVBAQEAACWLl2K6tWr4+jRo2jQoAEAJRAtXrwY7u7uAIDevXtj165d+PTTT5/uiSGiXMUeHSKyqlOnTmHPnj1wc3NTp6pVqwJQelEM6tWrZ7Tuzp070apVK5QsWRLu7u7o3bs37t27h8ePH5u9//PnzyMgIEANOQBQrVo1eHl54fz582pZ2bJl1ZADAH5+frhz5062jpWI8h57dIjIquLi4tCxY0dMnz7daJmfn5/6uHDhwppl165dQ4cOHTB06FB8+umnKFq0KA4cOIABAwYgMTERrq6uFm1noUKFNPM6nQ56vd6i+yAiy2PQIaI84+joiJSUFE1Z3bp18euvv6Js2bJwcDD/I+n48ePQ6/X44osvYGendE6vWrUqy/2lFxgYiBs3buDGjRtqr865c+cQHR2NatWqmd0eIrJNPHVFRHmmbNmyOHz4MK5du4a7d+9Cr9dj2LBhuH//Pnr27ImjR4/i8uXL2LZtG/r3759pSKlYsSKSkpIwd+5cXLlyBcuWLVMHKafdX1xcHHbt2oW7d++aPKUVHByMoKAg9OrVCydOnMCRI0fQp08ftGjRAvXr17f4c0BEeYtBh4jyzJgxY2Bvb49q1arB29sbERER8Pf3x8GDB5GSkoKXX34ZQUFBGD16NLy8vNSeGlNq1aqFL7/8EtOnT0eNGjXw888/IzQ0VFOnSZMmGDJkCLp37w5vb2+jwcyAcgpqw4YNKFKkCJo3b47g4GCUL18eK1eutPjxE1He04mIWLsRRERERLmBPTpERERUYDHoEBERUYHFoENEREQFFoMOERERFVgMOkRERFRgMegQERFRgcWgQ0RERAUWgw4REREVWAw6REREVGAx6BAREVGBxaBDREREBRaDDhERERVY/w85b7paglF0qQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot training and validation loss curves\n",
        "plt.plot(train_step_history, train_loss_history, \"-\",label='Training Loss', color='blue')\n",
        "plt.plot(val_step_history, val_loss_history, \"-\", label='Validation Loss', lw = 2, color='red')\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc = \"upper right\")\n",
        "plt.title(\"Training and Validation Loss over Iterations\")\n",
        "plt.legend()\n",
        "plt.savefig(cwd / \"loss_curve.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11644d30",
      "metadata": {
        "id": "11644d30"
      },
      "source": [
        "## Testing the model on a given prompt\n",
        "\n",
        "We finally test the trained model by generating text based on a given prompt. The model successfully generates a sequence of characters that continue from the prompt, and we save the generated text to a file for review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3767fd8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3767fd8e",
        "outputId": "a1692aba-5316-4486-e6d1-0a98fbb2964f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated ID Shape: (1, 1000)\n",
            "Generated Text:\n",
            "the meaning of life is told to scientists who have complained that the most common trivia were communications with the other and baltic ones but despite involved casualties by the middle of the two zero th century the division of lithuania maintains a cultural conception of lithuania while still a good temporary is true it is also often referred to in this part of the academic relations because the middle of a middle species becomes clear that he who who found the starting point in the population points the composer adds sold members to points to the printed system one zero of these systems are not considered a popular site to be extended for the establishment of the kde ammunition it is quite often deposited in the first excerpt i the summer of five five five miles per season of the cleveland beef library in the library of congress country house of houses in which the present day after the passing of the older themes of the world on the show of life beatty the world of captain sebastian cartoons medicine m\n"
          ]
        }
      ],
      "source": [
        "# Test the model on a given prompt\n",
        "prompt = \"the meaning of life is\"\n",
        "encoded_prompt = fn.encode(prompt, chars_to_int)\n",
        "context = encoded_prompt[None, :]\n",
        "\n",
        "B = 1\n",
        "seed = seed\n",
        "generate_len = 1000\n",
        "rng = jax.random.PRNGKey(seed)\n",
        "\n",
        "output_indices = fn.generate_tokens(\n",
        "    model=model_obj,\n",
        "    params=params,\n",
        "    constants=constants,\n",
        "    rng=rng,\n",
        "    context=context,\n",
        "    length=generate_len,\n",
        "    block_size=64,\n",
        "    temperature=0.8,\n",
        "    sample=True,\n",
        "    pad_id=None,\n",
        "    deterministic=True\n",
        ")\n",
        "\n",
        "output_indices = np.array(output_indices)  # Convert from JAX array to NumPy array\n",
        "generated_text = fn.decode(output_indices, int_to_chars)\n",
        "\n",
        "print(\"Generated ID Shape:\", output_indices.shape)\n",
        "print(\"Generated Text:\")\n",
        "print(prompt + generated_text)\n",
        "\n",
        "generated_text_file = cwd / \"generated_text.txt\"\n",
        "\n",
        "with open(generated_text_file, \"w\") as f:\n",
        "    f.write(prompt + generated_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}