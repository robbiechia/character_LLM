{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "adc4842c",
      "metadata": {
        "id": "adc4842c"
      },
      "source": [
        "# Hyperparameter Tuning - Gradient Clipping Experiment\n",
        "\n",
        "After completing ablation experiments, we proceed to conduct hyperparameter tuning to further enhance the model's performance. The architecture is defined as per the 'experiment_model.py' file, and we utilise functions created in the 'experiment_utils.py' file to facilitate the training process.\n",
        "\n",
        "The flow of this notebook is similar to that of previous components, but with modifications to accommodate the hyperparameter tuning requirements. The loss values are recorded for upcoming analysis, visualization and cross comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "477b41b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "477b41b4",
        "outputId": "aa6e2421-f5dc-4bf8-9403-90a69f6fb724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import optax\n",
        "import sys\n",
        "import jax\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "cwd = Path.cwd()\n",
        "project_root = cwd.parents[0]\n",
        "\n",
        "# Project root for local setup\n",
        "# project_root = cwd.parents[1]\n",
        "# sys.path.append(str(project_root))\n",
        "\n",
        "import hyperparameter_tuning.experiment_setup.experiment_utils as fn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "656e4403",
      "metadata": {
        "id": "656e4403"
      },
      "source": [
        "# Load the Experiment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f18b286",
      "metadata": {
        "id": "1f18b286"
      },
      "source": [
        "## Set the relevant directory paths & update.log file\n",
        "\n",
        "Here, we set the necessary directories and output paths for saving model checkpoints and training logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2168d1a9",
      "metadata": {
        "id": "2168d1a9"
      },
      "outputs": [],
      "source": [
        "# Data directory paths\n",
        "local_dir = project_root / \"data\" / \"text8_train.txt\"\n",
        "online_dir = project_root / \"text8_train.txt\"\n",
        "\n",
        "if local_dir.exists():\n",
        "    data_dir = str(local_dir) # This is for local runs or if repository is cloned directly\n",
        "else:\n",
        "    data_dir = \".\" + str(online_dir) # This is for online GPU platforms\n",
        "\n",
        "config_path = cwd / \"config.json\"\n",
        "training_log_file = cwd / \"training_results.log\"\n",
        "validation_log_file = cwd / \"validation_results.log\"\n",
        "checkpoint_file = cwd / \"checkpoint.pkl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a89050a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a89050a0",
        "outputId": "4922186d-8fe9-4cfa-f291-115fec92dc82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[initialize_training_log] Initialized training log file at /content/training_results.log\n",
            "[initialize_validation_log] Initialized validation log file at /content/validation_results.log\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(training_log_file):\n",
        "    fn.initialize_training_log(training_log_file)\n",
        "\n",
        "if not os.path.exists(validation_log_file):\n",
        "    fn.initialize_validation_log(validation_log_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da2df4b7",
      "metadata": {
        "id": "da2df4b7"
      },
      "source": [
        "## Load the experiment configurations\n",
        "\n",
        "Prior to running this notebook, the experiment configurations will be set in a 'config.json' file, which will be loaded to set the model hyperparameters and training settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f290991b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f290991b",
        "outputId": "4cb7619b-db9d-4835-b642-9bd8312d44cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[load_config] Loaded configuration from ./config.json\n",
            "We will be conducting  Hyperparameter tuning for no gradient clipping.\n"
          ]
        }
      ],
      "source": [
        "config = fn.load_config(\"./config.json\")\n",
        "\n",
        "print(f\"We will be conducting {config['description']}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "31bb4815",
      "metadata": {
        "id": "31bb4815"
      },
      "outputs": [],
      "source": [
        "# Load the seed\n",
        "seed = config['seed']\n",
        "\n",
        "# Model parameters\n",
        "vocab_size = config['model']['vocab_size']\n",
        "d_model = config['model']['d_model']\n",
        "n_heads = config['model']['n_heads']\n",
        "n_layers = config['model']['n_layers']\n",
        "mlp_ratio = config['model']['mlp_ratio']\n",
        "seq_len = config['model']['seq_len']\n",
        "\n",
        "# Training parameters\n",
        "loss_type = config['model']['loss_type']\n",
        "dropout_rate = config['model']['dropout']\n",
        "weight_decay = config['model']['weight_decay']\n",
        "label_smoothing = float(config['model']['label_smoothing'])\n",
        "\n",
        "# Mixed precision and other model settings\n",
        "use_mixed_precision = config['model']['mixed_precision']\n",
        "pos_encoding = config['model']['pos_encoding']\n",
        "attention_type = config['model']['attention_type']\n",
        "\n",
        "# Auxiliary loss settings\n",
        "use_auxiliary_loss = config['model']['use_auxiliary_loss']\n",
        "aux_heads = config['model']['aux_heads']\n",
        "aux_weight = config['model']['aux_weight']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cf23122e",
      "metadata": {
        "id": "cf23122e"
      },
      "outputs": [],
      "source": [
        "# Throughput test parameters\n",
        "max_test_iters = config['throughput']['max_test_iters']\n",
        "max_test_time_in_seconds = config['throughput']['max_test_time_in_seconds']\n",
        "compute_budget_hours = config['throughput']['compute_budget_hours']\n",
        "\n",
        "# Training settings\n",
        "val_fraction = config['training']['val_fraction']\n",
        "batch_size = config['training']['batch_size']\n",
        "learning_rate = config['training']['learning_rate']\n",
        "lr_schedule = config['training']['lr_schedule']\n",
        "optimizer_type = config['training']['optimizer']\n",
        "grad_clip = config['training']['grad_clip']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4030d754",
      "metadata": {
        "id": "4030d754"
      },
      "source": [
        "# Loading the Data\n",
        "\n",
        "The same text8 dataset is used, which has 100M characters of text data from Wikipedia articles. It contains only lowercase letters and spaces, and is already pre-split into 90M characters for training and 10M characters for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "75d76b31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75d76b31",
        "outputId": "2c4c6e8a-ef3f-4a94-c47e-891ee824e491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training text loaded. Length: 90,000,000 characters.\n",
            "First 500 characters of training text:\n",
            " anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans culottes of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philoso\n"
          ]
        }
      ],
      "source": [
        "# Read in training text file\n",
        "with open(data_dir, 'r', encoding='utf-8') as f:\n",
        "    train_text = f.read()\n",
        "print(f\"Training text loaded. Length: {len(train_text) :,} characters.\")\n",
        "\n",
        "# Inspect first 500 characters of training text\n",
        "print(\"First 500 characters of training text:\")\n",
        "print(train_text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7fd37a2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fd37a2d",
        "outputId": "bf1d1140-18da-44bf-a7e3-b8bad299e829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique characters in training text: 27\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(set(train_text)) # unique characters in training text\n",
        "chars_to_int = {ch: i for i, ch in enumerate(chars)} # char to int mapping\n",
        "int_to_chars = {i: ch for i, ch in enumerate(chars)} # int to char mapping\n",
        "\n",
        "print(f\"Unique characters in training text: {len(chars)}\") # should be 27, including space (sanity check)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "032e68f0",
      "metadata": {
        "id": "032e68f0"
      },
      "source": [
        "We further split the training data into a training set and a validation set to monitor the model's performance during training, in accordance to the validation fraction specified in our configuration file (10%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9a969636",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a969636",
        "outputId": "b37b6469-e15b-4aed-e163-b48acabd6dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training text length: 89,099,996 characters.\n",
            "Validation text length: 900,004 characters.\n"
          ]
        }
      ],
      "source": [
        "train_text, val_text = fn.split_train_val(train_text, val_fraction=val_fraction)\n",
        "\n",
        "print(f\"Training text length: {len(train_text) :,} characters.\")\n",
        "print(f\"Validation text length: {len(val_text) :,} characters.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c28ac68",
      "metadata": {
        "id": "1c28ac68"
      },
      "source": [
        "# Model Initialisation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fe304ec",
      "metadata": {
        "id": "7fe304ec"
      },
      "source": [
        "## Model Setup\n",
        "\n",
        "We intialise our model with the following parameters in accordance to our configuration file.\n",
        "Based on these parameters, our model has approximately ~4.1M parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d19f06bd",
      "metadata": {
        "id": "d19f06bd"
      },
      "outputs": [],
      "source": [
        "# Define the model params\n",
        "rng = jax.random.PRNGKey(seed)\n",
        "\n",
        "model_obj, params, constants = fn.create_train_state(\n",
        "        rng,\n",
        "        vocab_size = vocab_size,\n",
        "        d_model = d_model,\n",
        "        n_heads = n_heads,\n",
        "        n_layers = n_layers,\n",
        "        mlp_ratio = mlp_ratio,\n",
        "        seq_len = seq_len,\n",
        "        dropout = dropout_rate,\n",
        "        aux_loss = use_auxiliary_loss,\n",
        "        num_aux_heads = aux_heads,\n",
        "        mixed_precision = use_mixed_precision,\n",
        "        attention_type = attention_type,\n",
        "        pos_encoding = pos_encoding\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "91839933",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91839933",
        "outputId": "6f58065f-e849-4394-8f75-5f3701ceb0d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the model: 4,160,768\n"
          ]
        }
      ],
      "source": [
        "total_params = fn.count_parameters(params)\n",
        "\n",
        "print(f\"Total number of parameters in the model: {total_params :,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e709b510",
      "metadata": {
        "id": "e709b510"
      },
      "source": [
        "We perform a sanity check by running a single forward pass with random input data to ensure the model is functioning as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bdc7a187",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdc7a187",
        "outputId": "cc3b84ec-afc0-4564-9215-db5e8fff9d9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape: (2, 8, 27)\n"
          ]
        }
      ],
      "source": [
        "# SANITY CHECK: Test the model forward pass\n",
        "B, T = 2, 8  # Batch size and sequence length\n",
        "batch = jax.random.randint(key = rng, shape = (B, T), minval = 0, maxval = vocab_size)\n",
        "\n",
        "variables = {\"params\": params, \"constants\": constants}\n",
        "output = model_obj.apply(variables, batch, deterministic=False)\n",
        "print(\"Logits shape:\", output[\"logits\"].shape)  # Expected: (B, T, vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec22aeee",
      "metadata": {
        "id": "ec22aeee"
      },
      "source": [
        "## Initialise the optimizer\n",
        "\n",
        "In this section, we set up the optimizer for training our model in accordance to our configuration file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "05d04750",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05d04750",
        "outputId": "8fe78c0f-32f7-41c9-faef-667c35b30e80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer initialized: adam with Learning Rate = 0.001\n"
          ]
        }
      ],
      "source": [
        "# Define the learning rate\n",
        "learning_rate = learning_rate\n",
        "\n",
        "# Create the Optimizer and initialize it\n",
        "if optimizer_type == \"adam\":\n",
        "    optimizer = optax.adam(learning_rate)\n",
        "elif optimizer_type == \"sgd\":\n",
        "    optimizer = optax.sgd(learning_rate)\n",
        "elif optimizer_type == \"adamw\":\n",
        "    optimizer = optax.adamw(\n",
        "        learning_rate = learning_rate,\n",
        "        weight_decay = weight_decay\n",
        "    )\n",
        "\n",
        "# Add gradient clipping if specified\n",
        "if grad_clip is not None and grad_clip != \"none\":\n",
        "    optimizer = optax.chain(\n",
        "        optax.clip_by_global_norm(grad_clip),\n",
        "        optimizer\n",
        "    )\n",
        "\n",
        "\n",
        "opt_state = optimizer.init(params)\n",
        "\n",
        "print(\"Optimizer initialized:\", optimizer_type, \"with Learning Rate =\", learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "233c7fe3",
      "metadata": {
        "id": "233c7fe3"
      },
      "source": [
        "## Text encoding\n",
        "\n",
        "We then encode the text data into integer format for model training. Each unique character is mapped to a unique integer index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "17829ea8",
      "metadata": {
        "id": "17829ea8"
      },
      "outputs": [],
      "source": [
        "# Encode the train, val, test texts\n",
        "train_data = fn.encode(train_text, chars_to_int)\n",
        "val_data = fn.encode(val_text, chars_to_int)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "153631ec",
      "metadata": {
        "id": "153631ec"
      },
      "source": [
        "## Determine maximum permissible training steps\n",
        "\n",
        "Taking into account possible compute limitations, we perform a preliminary calculation to determine the maximum number of training steps we can perform based on the throughput of our model and the total training time available. For this preliminary test, the default maximum training time is 60 seconds, and commpute budget hours is 2 hours.\n",
        "\n",
        "Based on the throughput calculated from the preliminary test, the estimated maximum no. of training steps we can perform within this compute budget is ~360,000. To ensure we keep within the budget, we set the maximum training steps to be 150,000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1312e527",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1312e527",
        "outputId": "40acda79-9da9-49c4-c381-98a96c216bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Benchmark completed in 19.79 seconds.\n",
            "Total tokens processed: 8192000\n",
            "Throughput: 414027.02 tokens/second\n",
            "Estimated max steps within compute budget: 363890.0\n"
          ]
        }
      ],
      "source": [
        "# Determining how many steps we can run in a reasonable time\n",
        "max_iters = max_test_iters\n",
        "max_time = max_test_time_in_seconds # in seconds\n",
        "max_compute_time = compute_budget_hours # in hours\n",
        "\n",
        "_ , max_steps = fn.calculate_throughput(\n",
        "    max_test_iters = max_iters,\n",
        "    max_test_time = max_time,\n",
        "    model = model_obj,\n",
        "    params = params,\n",
        "    opt_state = opt_state,\n",
        "    optimizer = optimizer,\n",
        "    rng = rng,\n",
        "    batch_size = batch_size,\n",
        "    seq_len = seq_len,\n",
        "    compute_budget = max_compute_time,\n",
        "    train_data = train_data,\n",
        "    loss_type = loss_type,\n",
        "    aux_loss = use_auxiliary_loss,\n",
        "    aux_weight = aux_weight,\n",
        "    constants = constants,\n",
        "    label_smoothing = label_smoothing\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff66f55f",
      "metadata": {
        "id": "ff66f55f"
      },
      "source": [
        "# Model Training & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b839549c",
      "metadata": {
        "id": "b839549c"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "Now, we proceed to train the model over the determined number of training iterations. During training, we monitor the training loss and periodically evaluate the model on the validation set to track its performance. We also make sure to record the time taken for training to ensure it stays within our compute budget."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1262eda3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1262eda3",
        "outputId": "0d0453f8-b5f2-4a84-9b63-8d5bf79aa492"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[load_checkpoint] No checkpoint found at /content/checkpoint.pkl\n",
            "[load_checkpoint] Starting training as per usual.\n"
          ]
        }
      ],
      "source": [
        "iter_max = 150000\n",
        "\n",
        "# To track training and validation loss, as well as time taken\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "train_step_history = list(range(iter_max))\n",
        "val_step_history = []\n",
        "\n",
        "# Load checkpoint if it exists\n",
        "params, opt_state, constants, start_iter = fn.load_checkpoint(\n",
        "    checkpoint_file,\n",
        "    params,\n",
        "    constants,\n",
        "    opt_state\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd2b91d3",
      "metadata": {
        "id": "cd2b91d3"
      },
      "source": [
        "We then train the model and log the training and validation losses for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c7cbde26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7cbde26",
        "outputId": "77f50a60-3d3c-460e-c392-7704a522c7b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training from iteration = 0.\n",
            "[save_checkpoint] Saved checkpoint at step 0 to /content/checkpoint.pkl\n",
            "Iteration 0, time elapsed: 6.61 seconds\n",
            "\t \t Training Loss: 3.7514, Validation Loss: 4.4601\n",
            "\t \t Training Acc: 0.0616, Validation Acc: 0.1697\n",
            "\t \t Last Char Training Acc: 0.0000, Last Char Validation Acc: 0.1875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 1500 to /content/checkpoint.pkl\n",
            "Iteration 1500, time elapsed: 16.89 seconds\n",
            "\t \t Training Loss: 1.4083, Validation Loss: 1.4024\n",
            "\t \t Training Acc: 0.5645, Validation Acc: 0.5669\n",
            "\t \t Last Char Training Acc: 0.3438, Last Char Validation Acc: 0.5312\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 3000 to /content/checkpoint.pkl\n",
            "Iteration 3000, time elapsed: 27.23 seconds\n",
            "\t \t Training Loss: 1.3555, Validation Loss: 1.3605\n",
            "\t \t Training Acc: 0.5797, Validation Acc: 0.5806\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 4500 to /content/checkpoint.pkl\n",
            "Iteration 4500, time elapsed: 37.18 seconds\n",
            "\t \t Training Loss: 1.2281, Validation Loss: 1.2904\n",
            "\t \t Training Acc: 0.6052, Validation Acc: 0.5978\n",
            "\t \t Last Char Training Acc: 0.5312, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 6000 to /content/checkpoint.pkl\n",
            "Iteration 6000, time elapsed: 47.51 seconds\n",
            "\t \t Training Loss: 1.2106, Validation Loss: 1.2943\n",
            "\t \t Training Acc: 0.6136, Validation Acc: 0.5984\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 7500 to /content/checkpoint.pkl\n",
            "Iteration 7500, time elapsed: 57.72 seconds\n",
            "\t \t Training Loss: 1.1891, Validation Loss: 1.2541\n",
            "\t \t Training Acc: 0.6210, Validation Acc: 0.5997\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.5000\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 9000 to /content/checkpoint.pkl\n",
            "Iteration 9000, time elapsed: 68.41 seconds\n",
            "\t \t Training Loss: 1.2054, Validation Loss: 1.2107\n",
            "\t \t Training Acc: 0.6172, Validation Acc: 0.6188\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 10500 to /content/checkpoint.pkl\n",
            "Iteration 10500, time elapsed: 78.87 seconds\n",
            "\t \t Training Loss: 1.1467, Validation Loss: 1.2532\n",
            "\t \t Training Acc: 0.6353, Validation Acc: 0.6071\n",
            "\t \t Last Char Training Acc: 0.5625, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 12000 to /content/checkpoint.pkl\n",
            "Iteration 12000, time elapsed: 88.97 seconds\n",
            "\t \t Training Loss: 1.1984, Validation Loss: 1.2395\n",
            "\t \t Training Acc: 0.6149, Validation Acc: 0.6051\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 13500 to /content/checkpoint.pkl\n",
            "Iteration 13500, time elapsed: 99.01 seconds\n",
            "\t \t Training Loss: 1.1419, Validation Loss: 1.2602\n",
            "\t \t Training Acc: 0.6405, Validation Acc: 0.6060\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 15000 to /content/checkpoint.pkl\n",
            "Iteration 15000, time elapsed: 109.38 seconds\n",
            "\t \t Training Loss: 1.1851, Validation Loss: 1.1998\n",
            "\t \t Training Acc: 0.6289, Validation Acc: 0.6217\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 16500 to /content/checkpoint.pkl\n",
            "Iteration 16500, time elapsed: 119.73 seconds\n",
            "\t \t Training Loss: 1.1426, Validation Loss: 1.1104\n",
            "\t \t Training Acc: 0.6414, Validation Acc: 0.6534\n",
            "\t \t Last Char Training Acc: 0.5625, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 18000 to /content/checkpoint.pkl\n",
            "Iteration 18000, time elapsed: 130.19 seconds\n",
            "\t \t Training Loss: 1.2174, Validation Loss: 1.1483\n",
            "\t \t Training Acc: 0.6155, Validation Acc: 0.6367\n",
            "\t \t Last Char Training Acc: 0.5625, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 19500 to /content/checkpoint.pkl\n",
            "Iteration 19500, time elapsed: 140.77 seconds\n",
            "\t \t Training Loss: 1.1595, Validation Loss: 1.1845\n",
            "\t \t Training Acc: 0.6371, Validation Acc: 0.6306\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.5625\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 21000 to /content/checkpoint.pkl\n",
            "Iteration 21000, time elapsed: 151.44 seconds\n",
            "\t \t Training Loss: 1.1225, Validation Loss: 1.1643\n",
            "\t \t Training Acc: 0.6428, Validation Acc: 0.6315\n",
            "\t \t Last Char Training Acc: 0.5312, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 22500 to /content/checkpoint.pkl\n",
            "Iteration 22500, time elapsed: 161.66 seconds\n",
            "\t \t Training Loss: 1.1316, Validation Loss: 1.1070\n",
            "\t \t Training Acc: 0.6420, Validation Acc: 0.6522\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 24000 to /content/checkpoint.pkl\n",
            "Iteration 24000, time elapsed: 172.04 seconds\n",
            "\t \t Training Loss: 1.0547, Validation Loss: 1.1146\n",
            "\t \t Training Acc: 0.6667, Validation Acc: 0.6492\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 25500 to /content/checkpoint.pkl\n",
            "Iteration 25500, time elapsed: 182.46 seconds\n",
            "\t \t Training Loss: 1.0582, Validation Loss: 1.2485\n",
            "\t \t Training Acc: 0.6682, Validation Acc: 0.6093\n",
            "\t \t Last Char Training Acc: 0.8750, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 27000 to /content/checkpoint.pkl\n",
            "Iteration 27000, time elapsed: 192.54 seconds\n",
            "\t \t Training Loss: 1.1004, Validation Loss: 1.1230\n",
            "\t \t Training Acc: 0.6532, Validation Acc: 0.6478\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.8125\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 28500 to /content/checkpoint.pkl\n",
            "Iteration 28500, time elapsed: 202.99 seconds\n",
            "\t \t Training Loss: 1.0801, Validation Loss: 1.0761\n",
            "\t \t Training Acc: 0.6619, Validation Acc: 0.6613\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 30000 to /content/checkpoint.pkl\n",
            "Iteration 30000, time elapsed: 213.34 seconds\n",
            "\t \t Training Loss: 1.0847, Validation Loss: 1.0700\n",
            "\t \t Training Acc: 0.6603, Validation Acc: 0.6643\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 31500 to /content/checkpoint.pkl\n",
            "Iteration 31500, time elapsed: 223.50 seconds\n",
            "\t \t Training Loss: 1.0347, Validation Loss: 1.0802\n",
            "\t \t Training Acc: 0.6744, Validation Acc: 0.6589\n",
            "\t \t Last Char Training Acc: 0.5625, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 33000 to /content/checkpoint.pkl\n",
            "Iteration 33000, time elapsed: 233.26 seconds\n",
            "\t \t Training Loss: 1.1038, Validation Loss: 1.0754\n",
            "\t \t Training Acc: 0.6562, Validation Acc: 0.6620\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 34500 to /content/checkpoint.pkl\n",
            "Iteration 34500, time elapsed: 243.53 seconds\n",
            "\t \t Training Loss: 1.0812, Validation Loss: 1.1056\n",
            "\t \t Training Acc: 0.6621, Validation Acc: 0.6542\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 36000 to /content/checkpoint.pkl\n",
            "Iteration 36000, time elapsed: 253.95 seconds\n",
            "\t \t Training Loss: 1.0378, Validation Loss: 1.0865\n",
            "\t \t Training Acc: 0.6702, Validation Acc: 0.6604\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 37500 to /content/checkpoint.pkl\n",
            "Iteration 37500, time elapsed: 264.40 seconds\n",
            "\t \t Training Loss: 1.0725, Validation Loss: 1.0982\n",
            "\t \t Training Acc: 0.6663, Validation Acc: 0.6593\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 39000 to /content/checkpoint.pkl\n",
            "Iteration 39000, time elapsed: 274.54 seconds\n",
            "\t \t Training Loss: 1.0452, Validation Loss: 1.0320\n",
            "\t \t Training Acc: 0.6738, Validation Acc: 0.6801\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 40500 to /content/checkpoint.pkl\n",
            "Iteration 40500, time elapsed: 285.05 seconds\n",
            "\t \t Training Loss: 1.0567, Validation Loss: 1.1159\n",
            "\t \t Training Acc: 0.6713, Validation Acc: 0.6475\n",
            "\t \t Last Char Training Acc: 0.5312, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 42000 to /content/checkpoint.pkl\n",
            "Iteration 42000, time elapsed: 295.22 seconds\n",
            "\t \t Training Loss: 1.0501, Validation Loss: 1.0653\n",
            "\t \t Training Acc: 0.6759, Validation Acc: 0.6648\n",
            "\t \t Last Char Training Acc: 0.8125, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 43500 to /content/checkpoint.pkl\n",
            "Iteration 43500, time elapsed: 305.50 seconds\n",
            "\t \t Training Loss: 1.0325, Validation Loss: 1.0836\n",
            "\t \t Training Acc: 0.6758, Validation Acc: 0.6531\n",
            "\t \t Last Char Training Acc: 0.5625, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 45000 to /content/checkpoint.pkl\n",
            "Iteration 45000, time elapsed: 315.88 seconds\n",
            "\t \t Training Loss: 1.0608, Validation Loss: 1.0282\n",
            "\t \t Training Acc: 0.6636, Validation Acc: 0.6803\n",
            "\t \t Last Char Training Acc: 0.5000, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 46500 to /content/checkpoint.pkl\n",
            "Iteration 46500, time elapsed: 326.51 seconds\n",
            "\t \t Training Loss: 1.0120, Validation Loss: 1.0814\n",
            "\t \t Training Acc: 0.6863, Validation Acc: 0.6622\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 48000 to /content/checkpoint.pkl\n",
            "Iteration 48000, time elapsed: 337.00 seconds\n",
            "\t \t Training Loss: 1.0726, Validation Loss: 1.0952\n",
            "\t \t Training Acc: 0.6606, Validation Acc: 0.6556\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 49500 to /content/checkpoint.pkl\n",
            "Iteration 49500, time elapsed: 347.73 seconds\n",
            "\t \t Training Loss: 1.0896, Validation Loss: 1.0776\n",
            "\t \t Training Acc: 0.6593, Validation Acc: 0.6656\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 51000 to /content/checkpoint.pkl\n",
            "Iteration 51000, time elapsed: 358.20 seconds\n",
            "\t \t Training Loss: 1.0694, Validation Loss: 1.0933\n",
            "\t \t Training Acc: 0.6672, Validation Acc: 0.6604\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.5625\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 52500 to /content/checkpoint.pkl\n",
            "Iteration 52500, time elapsed: 368.65 seconds\n",
            "\t \t Training Loss: 1.0012, Validation Loss: 1.0675\n",
            "\t \t Training Acc: 0.6869, Validation Acc: 0.6646\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 54000 to /content/checkpoint.pkl\n",
            "Iteration 54000, time elapsed: 378.66 seconds\n",
            "\t \t Training Loss: 1.0274, Validation Loss: 1.1094\n",
            "\t \t Training Acc: 0.6775, Validation Acc: 0.6482\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 55500 to /content/checkpoint.pkl\n",
            "Iteration 55500, time elapsed: 388.83 seconds\n",
            "\t \t Training Loss: 1.0204, Validation Loss: 1.0737\n",
            "\t \t Training Acc: 0.6798, Validation Acc: 0.6636\n",
            "\t \t Last Char Training Acc: 0.5000, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 57000 to /content/checkpoint.pkl\n",
            "Iteration 57000, time elapsed: 399.03 seconds\n",
            "\t \t Training Loss: 1.0415, Validation Loss: 1.0834\n",
            "\t \t Training Acc: 0.6705, Validation Acc: 0.6605\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 58500 to /content/checkpoint.pkl\n",
            "Iteration 58500, time elapsed: 409.12 seconds\n",
            "\t \t Training Loss: 1.0309, Validation Loss: 1.0056\n",
            "\t \t Training Acc: 0.6777, Validation Acc: 0.6855\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 60000 to /content/checkpoint.pkl\n",
            "Iteration 60000, time elapsed: 419.49 seconds\n",
            "\t \t Training Loss: 1.0284, Validation Loss: 1.0194\n",
            "\t \t Training Acc: 0.6824, Validation Acc: 0.6764\n",
            "\t \t Last Char Training Acc: 0.8125, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 61500 to /content/checkpoint.pkl\n",
            "Iteration 61500, time elapsed: 429.94 seconds\n",
            "\t \t Training Loss: 1.0531, Validation Loss: 1.0523\n",
            "\t \t Training Acc: 0.6735, Validation Acc: 0.6724\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 63000 to /content/checkpoint.pkl\n",
            "Iteration 63000, time elapsed: 440.67 seconds\n",
            "\t \t Training Loss: 1.0676, Validation Loss: 1.1029\n",
            "\t \t Training Acc: 0.6648, Validation Acc: 0.6533\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 64500 to /content/checkpoint.pkl\n",
            "Iteration 64500, time elapsed: 450.92 seconds\n",
            "\t \t Training Loss: 1.0423, Validation Loss: 1.0715\n",
            "\t \t Training Acc: 0.6765, Validation Acc: 0.6720\n",
            "\t \t Last Char Training Acc: 0.5312, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 66000 to /content/checkpoint.pkl\n",
            "Iteration 66000, time elapsed: 461.25 seconds\n",
            "\t \t Training Loss: 1.0836, Validation Loss: 1.0576\n",
            "\t \t Training Acc: 0.6561, Validation Acc: 0.6682\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.5312\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 67500 to /content/checkpoint.pkl\n",
            "Iteration 67500, time elapsed: 471.45 seconds\n",
            "\t \t Training Loss: 1.0418, Validation Loss: 1.0275\n",
            "\t \t Training Acc: 0.6748, Validation Acc: 0.6780\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 69000 to /content/checkpoint.pkl\n",
            "Iteration 69000, time elapsed: 481.17 seconds\n",
            "\t \t Training Loss: 1.0893, Validation Loss: 1.1061\n",
            "\t \t Training Acc: 0.6573, Validation Acc: 0.6638\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.8438\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 70500 to /content/checkpoint.pkl\n",
            "Iteration 70500, time elapsed: 491.56 seconds\n",
            "\t \t Training Loss: 1.0299, Validation Loss: 1.0635\n",
            "\t \t Training Acc: 0.6777, Validation Acc: 0.6656\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 72000 to /content/checkpoint.pkl\n",
            "Iteration 72000, time elapsed: 502.12 seconds\n",
            "\t \t Training Loss: 1.1094, Validation Loss: 1.0612\n",
            "\t \t Training Acc: 0.6536, Validation Acc: 0.6682\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 73500 to /content/checkpoint.pkl\n",
            "Iteration 73500, time elapsed: 512.61 seconds\n",
            "\t \t Training Loss: 0.9888, Validation Loss: 1.0505\n",
            "\t \t Training Acc: 0.6829, Validation Acc: 0.6697\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 75000 to /content/checkpoint.pkl\n",
            "Iteration 75000, time elapsed: 522.73 seconds\n",
            "\t \t Training Loss: 1.0010, Validation Loss: 1.0796\n",
            "\t \t Training Acc: 0.6837, Validation Acc: 0.6683\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 76500 to /content/checkpoint.pkl\n",
            "Iteration 76500, time elapsed: 533.28 seconds\n",
            "\t \t Training Loss: 1.0465, Validation Loss: 1.0278\n",
            "\t \t Training Acc: 0.6721, Validation Acc: 0.6797\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.5625\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 78000 to /content/checkpoint.pkl\n",
            "Iteration 78000, time elapsed: 543.69 seconds\n",
            "\t \t Training Loss: 0.9771, Validation Loss: 1.0835\n",
            "\t \t Training Acc: 0.6895, Validation Acc: 0.6628\n",
            "\t \t Last Char Training Acc: 0.5625, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 79500 to /content/checkpoint.pkl\n",
            "Iteration 79500, time elapsed: 554.25 seconds\n",
            "\t \t Training Loss: 1.0232, Validation Loss: 1.0545\n",
            "\t \t Training Acc: 0.6777, Validation Acc: 0.6671\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.5625\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 81000 to /content/checkpoint.pkl\n",
            "Iteration 81000, time elapsed: 564.82 seconds\n",
            "\t \t Training Loss: 1.0256, Validation Loss: 1.0437\n",
            "\t \t Training Acc: 0.6809, Validation Acc: 0.6760\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.8750\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 82500 to /content/checkpoint.pkl\n",
            "Iteration 82500, time elapsed: 575.23 seconds\n",
            "\t \t Training Loss: 0.9801, Validation Loss: 1.0567\n",
            "\t \t Training Acc: 0.6904, Validation Acc: 0.6713\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 84000 to /content/checkpoint.pkl\n",
            "Iteration 84000, time elapsed: 585.79 seconds\n",
            "\t \t Training Loss: 1.0249, Validation Loss: 1.0615\n",
            "\t \t Training Acc: 0.6769, Validation Acc: 0.6626\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 85500 to /content/checkpoint.pkl\n",
            "Iteration 85500, time elapsed: 596.23 seconds\n",
            "\t \t Training Loss: 0.9811, Validation Loss: 1.0647\n",
            "\t \t Training Acc: 0.6947, Validation Acc: 0.6663\n",
            "\t \t Last Char Training Acc: 0.5625, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 87000 to /content/checkpoint.pkl\n",
            "Iteration 87000, time elapsed: 606.40 seconds\n",
            "\t \t Training Loss: 1.0503, Validation Loss: 1.0490\n",
            "\t \t Training Acc: 0.6626, Validation Acc: 0.6692\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.8750\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 88500 to /content/checkpoint.pkl\n",
            "Iteration 88500, time elapsed: 616.62 seconds\n",
            "\t \t Training Loss: 1.0321, Validation Loss: 0.9487\n",
            "\t \t Training Acc: 0.6797, Validation Acc: 0.6998\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 90000 to /content/checkpoint.pkl\n",
            "Iteration 90000, time elapsed: 627.09 seconds\n",
            "\t \t Training Loss: 1.0890, Validation Loss: 1.0668\n",
            "\t \t Training Acc: 0.6614, Validation Acc: 0.6665\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 91500 to /content/checkpoint.pkl\n",
            "Iteration 91500, time elapsed: 637.27 seconds\n",
            "\t \t Training Loss: 1.0829, Validation Loss: 1.0554\n",
            "\t \t Training Acc: 0.6637, Validation Acc: 0.6736\n",
            "\t \t Last Char Training Acc: 0.5312, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 93000 to /content/checkpoint.pkl\n",
            "Iteration 93000, time elapsed: 647.63 seconds\n",
            "\t \t Training Loss: 1.0294, Validation Loss: 1.0642\n",
            "\t \t Training Acc: 0.6788, Validation Acc: 0.6709\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 94500 to /content/checkpoint.pkl\n",
            "Iteration 94500, time elapsed: 658.30 seconds\n",
            "\t \t Training Loss: 1.0232, Validation Loss: 1.0251\n",
            "\t \t Training Acc: 0.6715, Validation Acc: 0.6764\n",
            "\t \t Last Char Training Acc: 0.8750, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 96000 to /content/checkpoint.pkl\n",
            "Iteration 96000, time elapsed: 668.83 seconds\n",
            "\t \t Training Loss: 1.0376, Validation Loss: 1.0320\n",
            "\t \t Training Acc: 0.6775, Validation Acc: 0.6757\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 97500 to /content/checkpoint.pkl\n",
            "Iteration 97500, time elapsed: 679.21 seconds\n",
            "\t \t Training Loss: 0.9842, Validation Loss: 1.0572\n",
            "\t \t Training Acc: 0.6952, Validation Acc: 0.6652\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 99000 to /content/checkpoint.pkl\n",
            "Iteration 99000, time elapsed: 689.40 seconds\n",
            "\t \t Training Loss: 0.9817, Validation Loss: 1.0080\n",
            "\t \t Training Acc: 0.6918, Validation Acc: 0.6827\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 100500 to /content/checkpoint.pkl\n",
            "Iteration 100500, time elapsed: 699.80 seconds\n",
            "\t \t Training Loss: 1.0094, Validation Loss: 1.0278\n",
            "\t \t Training Acc: 0.6876, Validation Acc: 0.6769\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 102000 to /content/checkpoint.pkl\n",
            "Iteration 102000, time elapsed: 710.06 seconds\n",
            "\t \t Training Loss: 0.9905, Validation Loss: 1.0064\n",
            "\t \t Training Acc: 0.6921, Validation Acc: 0.6899\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.8125\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 103500 to /content/checkpoint.pkl\n",
            "Iteration 103500, time elapsed: 720.57 seconds\n",
            "\t \t Training Loss: 0.9938, Validation Loss: 1.0382\n",
            "\t \t Training Acc: 0.6868, Validation Acc: 0.6791\n",
            "\t \t Last Char Training Acc: 0.8125, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 105000 to /content/checkpoint.pkl\n",
            "Iteration 105000, time elapsed: 731.23 seconds\n",
            "\t \t Training Loss: 1.0310, Validation Loss: 1.0060\n",
            "\t \t Training Acc: 0.6794, Validation Acc: 0.6874\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 106500 to /content/checkpoint.pkl\n",
            "Iteration 106500, time elapsed: 741.51 seconds\n",
            "\t \t Training Loss: 1.0009, Validation Loss: 1.0535\n",
            "\t \t Training Acc: 0.6881, Validation Acc: 0.6708\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 108000 to /content/checkpoint.pkl\n",
            "Iteration 108000, time elapsed: 751.88 seconds\n",
            "\t \t Training Loss: 0.9940, Validation Loss: 0.9895\n",
            "\t \t Training Acc: 0.6904, Validation Acc: 0.6887\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.5625\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 109500 to /content/checkpoint.pkl\n",
            "Iteration 109500, time elapsed: 762.65 seconds\n",
            "\t \t Training Loss: 0.9895, Validation Loss: 1.0226\n",
            "\t \t Training Acc: 0.6941, Validation Acc: 0.6724\n",
            "\t \t Last Char Training Acc: 0.8125, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 111000 to /content/checkpoint.pkl\n",
            "Iteration 111000, time elapsed: 773.00 seconds\n",
            "\t \t Training Loss: 0.9791, Validation Loss: 0.9761\n",
            "\t \t Training Acc: 0.6924, Validation Acc: 0.6995\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 112500 to /content/checkpoint.pkl\n",
            "Iteration 112500, time elapsed: 783.62 seconds\n",
            "\t \t Training Loss: 1.0355, Validation Loss: 1.0023\n",
            "\t \t Training Acc: 0.6754, Validation Acc: 0.6942\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 114000 to /content/checkpoint.pkl\n",
            "Iteration 114000, time elapsed: 794.17 seconds\n",
            "\t \t Training Loss: 1.0231, Validation Loss: 1.0536\n",
            "\t \t Training Acc: 0.6764, Validation Acc: 0.6671\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.8438\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 115500 to /content/checkpoint.pkl\n",
            "Iteration 115500, time elapsed: 804.49 seconds\n",
            "\t \t Training Loss: 1.0634, Validation Loss: 1.0259\n",
            "\t \t Training Acc: 0.6671, Validation Acc: 0.6768\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 117000 to /content/checkpoint.pkl\n",
            "Iteration 117000, time elapsed: 815.07 seconds\n",
            "\t \t Training Loss: 1.0110, Validation Loss: 1.0669\n",
            "\t \t Training Acc: 0.6874, Validation Acc: 0.6655\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 118500 to /content/checkpoint.pkl\n",
            "Iteration 118500, time elapsed: 825.80 seconds\n",
            "\t \t Training Loss: 0.9606, Validation Loss: 0.9909\n",
            "\t \t Training Acc: 0.6975, Validation Acc: 0.6879\n",
            "\t \t Last Char Training Acc: 0.5625, Last Char Validation Acc: 0.5000\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 120000 to /content/checkpoint.pkl\n",
            "Iteration 120000, time elapsed: 836.80 seconds\n",
            "\t \t Training Loss: 1.0764, Validation Loss: 1.0736\n",
            "\t \t Training Acc: 0.6613, Validation Acc: 0.6636\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 121500 to /content/checkpoint.pkl\n",
            "Iteration 121500, time elapsed: 847.33 seconds\n",
            "\t \t Training Loss: 0.9871, Validation Loss: 1.0072\n",
            "\t \t Training Acc: 0.6935, Validation Acc: 0.6863\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 123000 to /content/checkpoint.pkl\n",
            "Iteration 123000, time elapsed: 857.76 seconds\n",
            "\t \t Training Loss: 1.0051, Validation Loss: 0.9977\n",
            "\t \t Training Acc: 0.6860, Validation Acc: 0.6858\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 124500 to /content/checkpoint.pkl\n",
            "Iteration 124500, time elapsed: 867.98 seconds\n",
            "\t \t Training Loss: 0.9936, Validation Loss: 0.9753\n",
            "\t \t Training Acc: 0.6832, Validation Acc: 0.6852\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 126000 to /content/checkpoint.pkl\n",
            "Iteration 126000, time elapsed: 878.16 seconds\n",
            "\t \t Training Loss: 0.9940, Validation Loss: 0.9959\n",
            "\t \t Training Acc: 0.6874, Validation Acc: 0.6830\n",
            "\t \t Last Char Training Acc: 0.7812, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 127500 to /content/checkpoint.pkl\n",
            "Iteration 127500, time elapsed: 888.12 seconds\n",
            "\t \t Training Loss: 1.0078, Validation Loss: 1.0178\n",
            "\t \t Training Acc: 0.6846, Validation Acc: 0.6768\n",
            "\t \t Last Char Training Acc: 0.6250, Last Char Validation Acc: 0.5625\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 129000 to /content/checkpoint.pkl\n",
            "Iteration 129000, time elapsed: 898.57 seconds\n",
            "\t \t Training Loss: 1.0103, Validation Loss: 1.0021\n",
            "\t \t Training Acc: 0.6821, Validation Acc: 0.6853\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 130500 to /content/checkpoint.pkl\n",
            "Iteration 130500, time elapsed: 909.34 seconds\n",
            "\t \t Training Loss: 1.0124, Validation Loss: 0.9914\n",
            "\t \t Training Acc: 0.6833, Validation Acc: 0.6855\n",
            "\t \t Last Char Training Acc: 0.6562, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 132000 to /content/checkpoint.pkl\n",
            "Iteration 132000, time elapsed: 919.71 seconds\n",
            "\t \t Training Loss: 1.0608, Validation Loss: 1.0522\n",
            "\t \t Training Acc: 0.6670, Validation Acc: 0.6699\n",
            "\t \t Last Char Training Acc: 0.5625, Last Char Validation Acc: 0.6875\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 133500 to /content/checkpoint.pkl\n",
            "Iteration 133500, time elapsed: 930.34 seconds\n",
            "\t \t Training Loss: 0.9814, Validation Loss: 1.0226\n",
            "\t \t Training Acc: 0.6904, Validation Acc: 0.6813\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.8438\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 135000 to /content/checkpoint.pkl\n",
            "Iteration 135000, time elapsed: 940.72 seconds\n",
            "\t \t Training Loss: 0.9375, Validation Loss: 1.0290\n",
            "\t \t Training Acc: 0.7097, Validation Acc: 0.6815\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.7812\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 136500 to /content/checkpoint.pkl\n",
            "Iteration 136500, time elapsed: 950.89 seconds\n",
            "\t \t Training Loss: 1.0346, Validation Loss: 1.0006\n",
            "\t \t Training Acc: 0.6781, Validation Acc: 0.6825\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.7188\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 138000 to /content/checkpoint.pkl\n",
            "Iteration 138000, time elapsed: 961.61 seconds\n",
            "\t \t Training Loss: 1.0113, Validation Loss: 1.0740\n",
            "\t \t Training Acc: 0.6812, Validation Acc: 0.6691\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 139500 to /content/checkpoint.pkl\n",
            "Iteration 139500, time elapsed: 972.29 seconds\n",
            "\t \t Training Loss: 1.0336, Validation Loss: 0.9780\n",
            "\t \t Training Acc: 0.6699, Validation Acc: 0.6915\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 141000 to /content/checkpoint.pkl\n",
            "Iteration 141000, time elapsed: 982.92 seconds\n",
            "\t \t Training Loss: 0.9993, Validation Loss: 1.1225\n",
            "\t \t Training Acc: 0.6838, Validation Acc: 0.6487\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.6562\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 142500 to /content/checkpoint.pkl\n",
            "Iteration 142500, time elapsed: 993.56 seconds\n",
            "\t \t Training Loss: 1.0194, Validation Loss: 1.0084\n",
            "\t \t Training Acc: 0.6803, Validation Acc: 0.6841\n",
            "\t \t Last Char Training Acc: 0.6875, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 144000 to /content/checkpoint.pkl\n",
            "Iteration 144000, time elapsed: 1004.14 seconds\n",
            "\t \t Training Loss: 1.0235, Validation Loss: 1.0358\n",
            "\t \t Training Acc: 0.6813, Validation Acc: 0.6770\n",
            "\t \t Last Char Training Acc: 0.7188, Last Char Validation Acc: 0.7500\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 145500 to /content/checkpoint.pkl\n",
            "Iteration 145500, time elapsed: 1014.46 seconds\n",
            "\t \t Training Loss: 0.9892, Validation Loss: 1.0313\n",
            "\t \t Training Acc: 0.6899, Validation Acc: 0.6807\n",
            "\t \t Last Char Training Acc: 0.8125, Last Char Validation Acc: 0.5938\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 147000 to /content/checkpoint.pkl\n",
            "Iteration 147000, time elapsed: 1025.02 seconds\n",
            "\t \t Training Loss: 1.0451, Validation Loss: 1.0436\n",
            "\t \t Training Acc: 0.6694, Validation Acc: 0.6752\n",
            "\t \t Last Char Training Acc: 0.8125, Last Char Validation Acc: 0.5625\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 148500 to /content/checkpoint.pkl\n",
            "Iteration 148500, time elapsed: 1035.59 seconds\n",
            "\t \t Training Loss: 0.9944, Validation Loss: 1.0421\n",
            "\t \t Training Acc: 0.6869, Validation Acc: 0.6770\n",
            "\t \t Last Char Training Acc: 0.5938, Last Char Validation Acc: 0.8438\n",
            "--------------------------------------------------\n",
            "[save_checkpoint] Saved checkpoint at step 149999 to /content/checkpoint.pkl\n",
            "Iteration 149999, time elapsed: 1046.14 seconds\n",
            "\t \t Training Loss: 0.9984, Validation Loss: 1.0083\n",
            "\t \t Training Acc: 0.6849, Validation Acc: 0.6866\n",
            "\t \t Last Char Training Acc: 0.7500, Last Char Validation Acc: 0.6250\n",
            "--------------------------------------------------\n",
            "Training completed in 1046.23 seconds.\n"
          ]
        }
      ],
      "source": [
        "if start_iter > 0:\n",
        "        print(f\"Resuming training from iteration = {start_iter}.\")\n",
        "else:\n",
        "        print(\"Starting training from iteration = 0.\")\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "for it in range(start_iter, iter_max):\n",
        "\n",
        "    # get a batch of data\n",
        "    inputs, targets = fn.get_batch(train_data, batch_size, seq_len)\n",
        "\n",
        "    # Perform a training step\n",
        "    rng, sub = jax.random.split(rng)\n",
        "    new_params, new_opt_state, metrics = fn.train_step(\n",
        "            model = model_obj,\n",
        "            params = params,\n",
        "            constants=constants,\n",
        "            opt_state = opt_state,\n",
        "            x = inputs,\n",
        "            y = targets,\n",
        "            tx = optimizer,\n",
        "            rng = sub,\n",
        "            loss_type = loss_type,\n",
        "            aux_loss = use_auxiliary_loss,\n",
        "            aux_weight = aux_weight,\n",
        "            label_smoothing = label_smoothing\n",
        "    )\n",
        "\n",
        "    # Update parameters and optimizer state\n",
        "    params = new_params\n",
        "    opt_state = new_opt_state\n",
        "\n",
        "    # Record training metrics\n",
        "    acc = metrics['acc']\n",
        "    loss = metrics['loss']\n",
        "    last_char_acc = metrics['acc_last']\n",
        "    train_time = time.time() - time_start\n",
        "\n",
        "    train_loss_history.append(loss)\n",
        "\n",
        "    fn.update_training_log(\n",
        "        log_path = \"training_results.log\",\n",
        "        step = it,\n",
        "        train_loss = loss,\n",
        "        train_time = train_time,\n",
        "        train_acc = acc,\n",
        "        last_char_acc = last_char_acc\n",
        "        )\n",
        "\n",
        "    log_every = max(1, iter_max // 100)\n",
        "\n",
        "    if (it % log_every) == 0 or (it == iter_max - 1): # Print every 1% of iterations\n",
        "\n",
        "        # Compute the loss on validation set\n",
        "        batch_size_val = batch_size\n",
        "        seq_len_val = seq_len\n",
        "        val_inputs, val_targets = fn.get_batch(val_data, batch_size_val, seq_len_val)\n",
        "\n",
        "        val_out = model_obj.apply({\"params\": params, \"constants\": constants}, val_inputs, deterministic=True)\n",
        "        val_logits = val_out[\"logits\"]\n",
        "        val_aux_logits = val_out.get('aux_logits', None)\n",
        "\n",
        "        val_loss, val_metrics = fn.loss_and_metrics(\n",
        "            logits = val_logits,\n",
        "            targets = val_targets,\n",
        "            loss_type = loss_type,\n",
        "            aux_loss = use_auxiliary_loss,\n",
        "            aux_logits = val_aux_logits,\n",
        "            aux_weight = aux_weight,\n",
        "            label_smoothing = label_smoothing\n",
        "        )\n",
        "\n",
        "        # Record validation loss and time\n",
        "        val_acc = val_metrics['acc']\n",
        "        last_char_acc_val = val_metrics['acc_last']\n",
        "        val_loss_history.append(val_loss)\n",
        "        time_elapsed = time.time() - time_start\n",
        "        val_step_history.append(it)\n",
        "\n",
        "        fn.update_validation_log(\n",
        "            log_path = \"validation_results.log\",\n",
        "            step = it,\n",
        "            val_loss = val_loss,\n",
        "            val_time = time_elapsed,\n",
        "            val_acc = val_acc,\n",
        "            last_char_val_acc = last_char_acc_val\n",
        "        )\n",
        "\n",
        "        fn.save_checkpoint(\n",
        "            checkpoint_path = checkpoint_file,\n",
        "            params = params,\n",
        "            constants = constants,\n",
        "            opt_state = opt_state,\n",
        "            step = it,\n",
        "            time_elapsed = time_elapsed\n",
        "        )\n",
        "\n",
        "        # Print training and validation metrics\n",
        "        print(f\"Iteration {it}, time elapsed: {time_elapsed:.2f} seconds\")\n",
        "        print(f\"\\t \\t Training Loss: {loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "        print(f\"\\t \\t Training Acc: {acc:.4f}, Validation Acc: {val_acc:.4f}\")\n",
        "        print(f\"\\t \\t Last Char Training Acc: {last_char_acc:.4f}, Last Char Validation Acc: {last_char_acc_val:.4f}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "print(f\"Training completed in {time.time() - time_start:.2f} seconds.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f22e0a4",
      "metadata": {
        "id": "1f22e0a4"
      },
      "source": [
        "## Plot the training and validation loss curves\n",
        "\n",
        "After training, we plot the training and validation loss curves to visualize the model's learning progress over time. This plot is saved to the specified output directory, and will be useful to identify if the model converges at first glance. Among all the ablation experiments for that category, we can also compare these curves to see how different configurations affect the learning dynamics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f4cd9351",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "f4cd9351",
        "outputId": "14d3673b-84e4-4142-adc9-d4da824d8391"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot training and validation loss curves\n",
        "plt.plot(train_step_history, train_loss_history, \"-\",label='Training Loss', color='blue')\n",
        "plt.plot(val_step_history, val_loss_history, \"-\", label='Validation Loss', lw = 2, color='red')\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc = \"upper right\")\n",
        "plt.title(\"Training and Validation Loss over Iterations\")\n",
        "plt.legend()\n",
        "plt.savefig(cwd / \"loss_curve.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11644d30",
      "metadata": {
        "id": "11644d30"
      },
      "source": [
        "## Testing the model on a given prompt\n",
        "\n",
        "We finally test the trained model by generating text based on a given prompt. The model successfully generates a sequence of characters that continue from the prompt, and we save the generated text to a file for review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3767fd8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3767fd8e",
        "outputId": "13409ac0-cae9-4145-dc3f-6befdeda4e7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated ID Shape: (1, 1000)\n",
            "Generated Text:\n",
            "the meaning of life is told that the angular coronation and the devil of the people s vilifications were long to the skorpiche mouth the post operation controversy and natural engineering the flaws was published in a twenty year old premiership of a archetyle in the early sixties of chicago s assassination the writings of amin l a one three and one three a pair of communication cryptically a task format is a real hero or in an additional format for complete and constant storage the rest of the following methods or to design the method of changing low prices power in the one nine five zero s and one nine seven zero s and see also hercules dell times references one nine seven three births one nine six four deaths american physicians american writers american scientists two zero seven one eight eight two cold warspico de santa bartolomeo one eight six three cold war one seven eight three he died two zero years old the player with the old brother of life beach the emperor of lithuania s father james joseph smit\n"
          ]
        }
      ],
      "source": [
        "# Test the model on a given prompt\n",
        "prompt = \"the meaning of life is\"\n",
        "encoded_prompt = fn.encode(prompt, chars_to_int)\n",
        "context = encoded_prompt[None, :]\n",
        "\n",
        "B = 1\n",
        "seed = seed\n",
        "generate_len = 1000\n",
        "rng = jax.random.PRNGKey(seed)\n",
        "\n",
        "output_indices = fn.generate_tokens(\n",
        "    model=model_obj,\n",
        "    params=params,\n",
        "    constants=constants,\n",
        "    rng=rng,\n",
        "    context=context,\n",
        "    length=generate_len,\n",
        "    block_size=64,\n",
        "    temperature=0.8,\n",
        "    sample=True,\n",
        "    pad_id=None,\n",
        "    deterministic=True\n",
        ")\n",
        "\n",
        "output_indices = np.array(output_indices)  # Convert from JAX array to NumPy array\n",
        "generated_text = fn.decode(output_indices, int_to_chars)\n",
        "\n",
        "print(\"Generated ID Shape:\", output_indices.shape)\n",
        "print(\"Generated Text:\")\n",
        "print(prompt + generated_text)\n",
        "\n",
        "generated_text_file = cwd / \"generated_text.txt\"\n",
        "\n",
        "with open(generated_text_file, \"w\") as f:\n",
        "    f.write(prompt + generated_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}